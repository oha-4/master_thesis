\documentclass[a4paper,11pt,oneside,openany,report,dvipdfmx]{jsbook}

\usepackage[left=30mm,right=30mm,top=25mm,bottom=25mm]{geometry}
\usepackage{cscover}
\usepackage{graphicx}
\usepackage[nobreak]{cite}
\usepackage[a4paper,dvipdfmx,pdfdisplaydoctitle=true,%
	bookmarks=true,bookmarksnumbered=true,bookmarkstype=toc,bookmarksopen=true%
]{hyperref}
\usepackage{pxjahyper}

\hypersetup{
  pdftitle={Pre-Markingアクションを用いたDirected Controller Synthesisの探索ヒューリスティック改善},
  pdfauthor={大畑允人}
}

\renewcommand{\headfont}{\bfseries}
\renewcommand{\bibname}{参考文献}
\setcounter{tocdepth}{2}
\pagestyle{plain}

\thesistype{修士論文}
\title{Pre-Markingアクションを用いた\\Directed Controller Synthesisの\\探索ヒューリスティック改善}
\author{大畑 允人}
\studentid{24M30552}
\affiliation{%
	東京科学大学\\
	情報理工学院\\
	情報工学コース
}
\date{2026年1月}

\supervisorname{指導教員}
\supervisor{鄭 顕志}

\usepackage{algorithm}
\usepackage[italicComments=false,indLines=false]{algpseudocodex}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{comment}
\usepackage{mathtools}
\usepackage{tabularray}
\UseTblrLibrary{booktabs}
\UseTblrLibrary{siunitx}
\usepackage{thmtools}
\usepackage{tikz}
\usepackage{todonotes}
\usepackage{prettyref}

\declaretheoremstyle[
	notefont=\mdseries, notebraces={（}{）},
	headpunct=．,
]{jstyle}
\declaretheorem[name=定義,style=jstyle]{definition}

\newcommand{\descitem}[1]{\item[#1]\mbox{}\\}

\sisetup{
  group-separator = {,},
  group-minimum-digits = 4
}

\NewTblrColumnType{N}{Q[r, si={table-alignment-mode=none, table-number-alignment=right, table-text-alignment=right}]}

\newcommand*{\resultheader}[1]{#1 & 手法 & $|S|$ & & & & $M$ [MiB] & & & & $T$ [ms] & & & & $T_\mathit{eval}$ [ms] & & & \\}
\newcommand*{\resultheadernk}{\resultheader{$(N, K)$}}
\newcommand*{\resultheadern}{\resultheader{$N$}}
\NewTblrEnviron{rtblr}
\SetTblrOuter[rtblr]{expand=\resultheadernk\resultheadern\resultheader}
\SetTblrInner[rtblr]{
  colspec = {
    cc
    N@{~}r@{}N@{}l
    N@{~}r@{}N@{}l
    N@{~}r@{}N@{}l
    N@{~}r@{}N@{}l
  },
  row{1} = {c, guard},
  cell{1}{3,7,11,15} = {c=4}{c},
}
\NewTblrContentCommand{\NA}{-}
\NewTblrContentCommand{\TO}{T.O.}

\newcommand*{\pmaheader}[1]{#1 & $|A|$ & $|A^\mathit{PP}|$ & $|A^\mathit{SP}|$ & $\rho$ [\%]\\}
\newcommand*{\pmaheadernk}{\pmaheader{$(N, K)$}}
\newcommand*{\pmaheadern}{\pmaheader{$N$}}
\NewTblrEnviron{ptblr}
\SetTblrOuter[ptblr]{expand=\pmaheadernk\pmaheadern\pmaheader}
\SetTblrInner[ptblr]{
  width = .6\linewidth,
  colspec = {Q[c, 1]Q[r, 1]Q[r, 1]Q[r, 1]Q[r, 1]},
  row{1} = {c, guard},
}

\usetikzlibrary{arrows.meta,automata,positioning}

\newrefformat{chap}{第\ref*{#1}章}
\newrefformat{sec}{第\ref*{#1}節}
\newrefformat{subsec}{第\ref*{#1}項}
\newrefformat{subsubsec}{第\ref*{#1}目}
\newrefformat{fig}{図\ref*{#1}}
\newrefformat{tab}{表\ref*{#1}}
\newrefformat{alg}{アルゴリズム\ref*{#1}}
\newcommand\aref[1]{\hyperref[#1]{\prettyref{#1}}}

\setuptodonotes{inline,backgroundcolor=red!15,bordercolor=red}
\newcommand{\memo}[1]{\todo[inline,backgroundcolor=green!15,bordercolor=green]{#1}}

\makeatletter

\renewcommand{\fps@table}{htbp}
\renewcommand{\fps@algorithm}{H}
\renewcommand{\ALG@name}{アルゴリズム}
\renewcommand{\algorithmicrequire}{\textbf{入力：}}
\renewcommand{\algorithmicensure}{\textbf{出力：}}
\algrenewcommand\Return{\State\textbf{return} }
\algnewcommand\Break{\State\textbf{break}}
\algnewcommand\Continue{\State\textbf{continue}}

\makeatother

\begin{document}

\frontmatter

\maketitle

\chapter{概要}

\tableofcontents
\listoffigures
\listoftables

\mainmatter

\chapter{序論}

現代の社会インフラや産業システムにおいて，ソフトウェアが担う役割は拡大の一途をたどっている．
これらのシステムの多くは，離散的な状態と，その状態を遷移させる事象（アクション）の列によって振る舞いが記述される離散事象システム（Discrete Event System, DES）としてモデル化できる．
システムの高機能化・複雑化に伴い，システムが安全性や活性といった要求仕様を確実に満たすことを保証するのはますます困難になっており，設計段階における支援技術の重要性が高まっている．

本章では，離散事象システムとその制御に関する背景を述べ，本研究が取り組む課題と目的，および本論文の構成について概説する．

\section{離散事象システムと離散制御器合成}

離散事象システム（Discrete Event System, DES）は，離散的な状態空間を持ち，非同期に発生する事象によって状態遷移が引き起こされる動的システムである~\cite{DiscreteEventSystem}．
製造ラインの工程管理，ロボットの動作計画，通信プロトコル，組み込みシステムなど，その適用範囲は多岐にわたる．
こうしたシステムにおいて，危険な状態に到達しないというSafetyや，目的とするタスクを無限回完了できるというNon-Blockingを保証することは，システムの信頼性を確保する上で不可欠である．

従来，これらの要求を満たす制御ロジック（動作仕様）の設計は，熟練した設計者の経験則や，試行錯誤的な検証に依存していた．
しかし，並行して動作する複数のコンポーネントが複雑に相互作用するシステムにおいて，人間の直感だけで全ての境界条件や例外ケースを網羅し，デッドロックや禁止状態への到達を防ぐことは極めて困難である．
設計ミスは再設計のコストを増大させるだけでなく，運用時の重大な事故につながるリスクも孕んでいる．

この課題に対する解決策として，形式手法に基づき，与えられた環境モデルと要求仕様から正しい制御器を自動生成する離散制御器合成（Discrete Controller Synthesis）の研究が進められている~\cite{DiscreteControllerSynthesis}．
離散制御器合成は，環境の可能な振る舞いをすべて考慮した上で，制御可能なアクションを適切に許可・禁止することで，システムが常に仕様を満たすことを数学的に保証する．
特に，システム自身が能動的にアクションを選択してタスクを遂行する場合には，各状態で高々1つの制御アクションのみを選択するDirected Controllerの合成が有効である~\cite{DirectedController}．
このDirected Controllerを合成する技術をDirected Controller Synthesis（DCS）と呼ぶ~\cite{DirectedControllerSynthesis}．

しかし，DCSの実適用における最大の障壁は状態空間爆発問題である．
システムを構成するコンポーネント数が増加すると，合成後の状態空間は指数関数的に増大する．
これに対処するため，状態空間全体を事前に構築せず，初期状態から必要な部分のみを探索するOn-The-Fly探索手法や，探索を効率化するためのヒューリスティック技術が提案されてきた~\cite{Heuristic}．
特に，Ciolekらが提案したReady Abstraction（RA）~\cite{ReadyAbstraction}は，並列合成の構造を利用して目標までの距離を効率的に推定する有効なヒューリスティックであり，DCSの適用範囲を拡大させてきた．

\section{本論文の目的}

本論文の目的は，DCSにおけるOn-The-Fly探索の効率をさらに向上させるため，従来のReady Abstraction（RA）が抱える構造的な課題を解決する新たな探索指針であるLandmark Ready Abstractionを提案することである．

従来のRAは，各コンポーネントにおいて局所的に発火可能なアクション（Readyアクション）の情報に基づいて目標までの距離を推定する．
しかし，この推定手法には以下の構造的な課題が存在する．

\begin{description}
  \descitem{同期構造を無視した到達可能性評価の限界}
  RAは，Readyアクションのみをノードとするグラフ上で距離を推定する．
  しかし，目標達成に特定のコンポーネント間の同期が不可欠な場合，現在はReadyアクションではないが将来的に同期を解放するために必要な予備アクションが評価から漏れる．
  その結果，同期ボトルネックを考慮しない局所的な経路選択が行われ，探索空間が不必要に拡大する．
  \descitem{網羅的な距離推定による計算資源の浪費}
  RAはヒューリスティック値を算出する際，現在の状態遷移に関与しないコンポーネントを含めた全てに対し，一律に距離推定を実行する．
  この網羅的な評価プロセスは，システム規模（コンポーネント数）に比例して冗長な計算を繰り返すことを意味し，大規模なシステムにおいて1ステップごとの計算コストを不必要に増大させる要因となる．
\end{description}

そこで本研究では，従来のRAの枠組みに，目標アクションの発火に不可欠なアクション（Pre-Markingアクション）を中間目標（ランドマーク）として組み込む新たな距離推定手法を提案する．
具体的には，以下の項目に取り組む．

\begin{description}
  \descitem{Ready Abstractionの探索特性と課題の分析}
  Readyアクションを用いた距離推定が，同期を要するシステムにおいて局所的な挙動を示す原因と，それによって探索空間が不必要に拡大するメカニズムについて，具体的なモデルを用いて分析する．
  \descitem{Landmark Ready Abstractionの提案}
  目標アクションの発火に不可欠なアクションをPre-Markingアクション（PMA）として定義し，これを探索の指針（ランドマーク）とする新たなヒューリスティック手法Landmark Ready Abstraction（LRA）を提案する．
  LRAは，RAが持つ遷移コストの精密な見積もり能力と，PMAによる大域的な方向付けを統合することで，同期ボトルネックを考慮した適切な経路選択を可能にする．
  さらに，距離推定を行う目標を，その時点で解決すべきPMAのみに厳選することで，1ステップあたりの計算コストの効率化も図る．
  これにより，局所的な評価に基づく冗長な経路探索を抑制し，探索状態数および計算時間を大幅に削減することで，システム全体の合成効率を向上させる．
  \descitem{評価実験による有効性の検証}
  提案手法を実装し，ベンチマーク問題を用いて従来手法と比較することで，探索状態数や計算時間の削減効果を定量的に評価する．
\end{description}

本研究の成果は，より大規模で複雑なシステムの制御器合成を現実的な時間・メモリリソースで可能にし，高信頼なシステム開発の自動化に貢献するものである．

\section{本論文の構成}

本論文の構成は以下の通りである．

\aref{chap:background}「背景技術」では，本研究の基礎となる離散制御器合成およびDCSの理論的枠組み，On-The-Fly探索アルゴリズム，および既存のヒューリスティック手法であるReady Abstractionについて詳説する．

\aref{chap:ready_abstraction_limitations}「Ready Abstractionの課題」では，既存のRAが抱える構造的な限界について述べる．特に，Markingアクションの発火にコンポーネント間の同期が必要な状況において，現状態のReadyアクションのみに基づくRAの推定が，大域的な同期制約を考慮できずに局所解への停留や探索空間の拡大を招くメカニズムについて分析する．

\aref{chap:landmark_ready_abstraction}「Landmark Ready Abstraction」では，本研究の中核となる提案手法について述べる．目標アクションの発火に不可欠なアクション（Pre-Markingアクション）の定義と抽出アルゴリズム，およびそれを用いたヒューリスティック関数について詳述する．また，具体的なモデルを用いた動作例を通じ，提案手法がいかにして同期ボトルネックを考慮した適切な経路選択を行うか，その動作原理を明らかにする．

\aref{chap:evaluation}「評価」では，提案手法の有効性を検証するための評価実験について述べる．ベンチマーク問題を用いた実験により，従来手法との探索状態数および計算時間の比較を行う．さらに，実験結果に基づき，提案手法が有効に機能する条件や計算コストに関する考察を行い，実用的な適用指針について議論する．

\aref{chap:related_works}「関連研究」では，DCSの効率化やヒューリスティック探索に関する先行研究を概観し，本研究の位置づけを明確にする．

\aref{chap:conclusion}「結論」では，本論文の成果を総括し，今後の展望について述べる．

\chapter{背景技術}
\label{chap:background}

本章では，本研究の基盤となる離散制御器合成の概要，Directed Controller Synthesis（DCS）の定式化とOn-The-Fly探索アルゴリズム，およびReady Abstraction（RA）に基づくヒューリスティック関数について述べる．

\section{離散制御器合成}

離散制御器合成（Discrete Controller Synthesis）は，離散事象システム（Discrete Event System, DES）に対して，与えられた安全性などの制約を満たす制御器を自動的に構築する技術である~\cite{DiscreteControllerSynthesis}．
DESは有限状態オートマトン（あるいはLTS）の並列合成によってモデル化されるが，並列合成により得られる状態空間はコンポーネント数に対して指数的に増大しうる．
この指数的爆発は離散制御問題の解決を困難にし，現在も研究上の課題となっている．

制御器は，制御可能なアクションを動的に無効化しながら，制御不能なアクションを監視することで，システムの振る舞いを制限する．
一般のスーパバイザ制御では可能な限り多くの制御可能アクションを有効にする（最大許容）ことが求められることが多い．
しかし，制御器自身がアクションを能動的に実行するアクティブなコンポーネントとして振る舞う場合には，任意の時点で高々1つの制御可能アクションのみを選択する制御が適切となる．
このような制御器はDirected Controllerと呼ばれる~\cite{DirectedController}．

\subsection{ラベル付き遷移系}

本論文における離散制御器合成の定式化として，システムを構成する各コンポーネントをラベル付き遷移系（Labeled Transition System, LTS）としてモデル化する．
なお，本研究ではMarkingアクション（アクションベースの目標）を主に用いるが，既存研究ではMarked状態（状態ベースの目標）を用いることもある．
この両者を扱えるよう，LTSにはMarked状態集合とMarkingアクション集合の両方を持たせる（必要に応じて片方を空集合または全体集合として扱う）．

\begin{definition}[LTS]
  LTSは
  $E = (S_E, s_{E,0}, S^I_E, S^M_E, A_E, A^M_E, \Delta_E)$
  で表現される．
  $S_E$は有限の状態集合であり，$s_{E,0} \in S_E$は初期状態を表す．
  $S^I_E \subseteq S_E$は違反状態の集合であり，システムが到達してはならない状態を表す．
  $S^M_E \subseteq S_E$はMarked状態の集合である（RAや既存のDCS定式化で用いる）．
  $A_E = A^C_E \cup A^U_E$はアクション集合であり，$A^C_E$は制御可能アクション，$A^U_E$は制御不能アクションを表す．
  $A^M_E \subseteq A_E$はMarkingアクション集合である（本研究の定式化で用いる）．
  $\Delta_E \subseteq S_E \times A_E \times S_E$は遷移関係を表す．
\end{definition}

\begin{definition}[決定性]
  LTS $E$が決定的であるとは，任意の状態$s\in S_E$とアクション$a\in A_E$について，
  $(s,a,s_1)\in\Delta_E$かつ$(s,a,s_2)\in\Delta_E$ならば$s_1=s_2$が成り立つことをいう．
\end{definition}

本研究では，全てのLTSは決定的であると仮定する．

\begin{definition}[トレース]
  $\Delta_E$に従う状態とアクションの有限または無限の交互列
  $t = s_0, a_0, s_1, a_1, \ldots$
  をトレースと呼ぶ．
  ただし，各$i$について$(s_i, a_i, s_{i+1}) \in \Delta_E$が成り立つ．
  $E$上のトレースの集合を$T_E$で表す．
\end{definition}

\begin{definition}[有効トレース集合]
  LTS $E$ において，状態 $s \in S_E$ を始点とし，アクション集合 $A \subseteq A_E$ のいずれかの発火をもって終了する有限トレースのうち，途中で違反状態 $S^I_E$ を経由しないものの集合を $T_{s \to A}$ と定義する．
  $$
    T_{s \to A} = \left\{
    (s_0, a_0, \dots, s_n) \in T_E \;\middle|\;
    s_0 = s \land a_{n-1} \in A \land \bigwedge_{i = 0}^n s_i \notin S^I_E
    \right\}
  $$
  この集合が空でない（$T_{s \to A} \neq \emptyset$）とき，状態 $s$ から $A$ へ安全に到達可能である．
\end{definition}

\subsection{同期アクションと並列合成}

\begin{definition}[同期アクション]
  複数のLTS $E_1, \ldots, E_n$において，アクション$a$が2つ以上のコンポーネントのアクション集合に含まれるとき，
  $a$を同期アクションと呼ぶ．同期アクション集合$A^S$は
  $$
    A^S = \left\{a \in \bigcup_{i=1}^{n} A_{E_i} \;\middle|\; |\{i \mid a \in A_{E_i}\}| \geq 2\right\}
  $$
  と定義する．
\end{definition}

\begin{definition}[並列合成]
  LTS集合$\mathcal{E} = \{E_1,\ldots,E_n\}$の並列合成$E_\parallel = E_1 \parallel E_2 \parallel \cdots \parallel E_n$を$E_\parallel = (S_{E_\parallel}, s_{E_\parallel ,0}, S^I_{E_\parallel}, S^M_{E_\parallel}, A_{E_\parallel}, A^M_{E_\parallel}, \Delta_{E_\parallel})$
  として定義する．
  状態集合$S_{E_\parallel}=\prod_{i=1}^{n}S_{E_i}$は各コンポーネントの状態の直積であり，初期状態は$s_{E_\parallel,0}=(s_{E_1,0},\ldots,s_{E_n,0})$である．
  違反状態集合$S^I_{E_\parallel}$は，いずれかのコンポーネントが違反状態にある状態の集合$\{(s_1, \ldots, s_n) \in S_{E_\parallel} \mid \exists i . s_i \in S^I_{E_i}\}$として定義される．
  Marked状態集合は$S^M_{E_\parallel}=\prod_{i=1}^{n}S^M_{E_i}$，
  アクション集合$A_{E_\parallel}=\bigcup_{i=1}^{n}A_{E_i}$，
  Markingアクション集合$A^M_{E_\parallel}=\bigcup_{i=1}^{n}A^M_{E_i}$である．
  遷移関係$\Delta_{E_\parallel}$については，同期アクション$a \in A^S$は$a$を持つ全てのLTSで同時に発火し，非同期アクション$a \notin A^S$は$a$を持つLTSのみで発火する．
\end{definition}

並列合成には以下の特徴がある：
\begin{itemize}
  \item 同期アクションによりコンポーネント間の協調動作を実現できる
  \item 状態数$|S_{E_\parallel}|$はLTS数に対して指数的に増大しうる
\end{itemize}

\section{Directed Controller Synthesis}

本節では，Directed Controller Synthesis（DCS）の形式的定義と，On-The-Fly探索によるアルゴリズムについて述べる．

\subsection{制御可能性とDirected Controller}

アクションには制御可能なものと制御不能なものがある．
制御可能アクションは，制御器によって有効化・無効化が可能である．
一方，制御不能なアクションは環境によって発火されるため，発火し得る場合は全ての発火を考慮しなければならない．
各状態の制御可能なアクションのうち高々1つのみを有効にする制御器を合成することで，システム全体の振る舞いを制御する．
このような制御器をDirected Controllerと呼ぶ．

\begin{definition}[Directed Controller]
  並列合成LTS $E_\parallel$に対する制御器が以下の条件を満たすとき，Directed Controllerと呼ぶ：
  \begin{description}
    \item[Controllable]
          すべての制御不能アクションを常に有効化する
    \item[Directed]
          各状態で高々1つの制御可能アクションのみを有効化する
    \item[Eager]
          Marked状態，またはMarkingアクション発火後の状態において，制御可能アクションのみ存在する場合，必ず1つを選択する
  \end{description}
\end{definition}

\subsection{制御問題}

既存のDCSでは，タスク完了などを表すMarked状態への到達可能性に基づいてNon-Blocking性を定義することがある．
本研究のMarkingアクションベース定式化との関係は\aref{subsec:marking_to_marked}で述べる．
また，本研究では，目標を状態ではなくMarkingアクション$A^M$の発火として与える．

\begin{definition}[Directed Controllerの制御問題]
  LTSの組$\bm{E}=(E_1,\ldots,E_n)$に対し，解は以下を満たすDirected Controllerである：
  \begin{description}
    \item[Safety]
          制御下のシステムが違反状態に到達しない
    \item[Non-Blocking]
          Marked状態への到達，またはMarkingアクションの発火を無限回行える
  \end{description}
\end{definition}

\subsection{MarkingアクションからMarked状態への変換}
\label{subsec:marking_to_marked}

本研究では，目標をMarkingアクション集合 $A^M$ の発火として定義する．
一方，RAはMarked状態への到達可能性に基づくヒューリスティックである．
そのため，本研究の定式化をRAの枠組みに適用するにあたり，アクションの発火イベントを状態として保持するMarking判定LTS $E_M$ を用いて，アクションベースの目標を等価な状態ベースの目標へと帰着させる．

合成対象のコンポーネント集合を $\mathcal{E} = \{E_1, \dots, E_n\}$ とし，全コンポーネントのアクション集合の和を $A = \bigcup_{i=1}^n A_{E_i}$ とする．
このとき，$E_M = (S_{E_M}, s_{E_M,0}, S^I_{E_M}, S^M_{E_M}, A_{E_M}, A^M_{E_M}, \Delta_{E_M})$ は以下のように定義される：

\begin{itemize}
  \item $S_{E_M} = \{0, 1\}$, $s_{E_M,0} = 0$, $S^I_{E_M} = \emptyset$, $S^M_{E_M} = \{1\}$
  \item $A_{E_M} = A$ （同期のために全アクションをアルファベットに含める）
  \item 遷移関係 $\Delta_{E_M}$：
        \begin{itemize}
          \item 任意の $a \in A^M$ に対し，$(0, a, 1) \in \Delta_{E_M}$ および $(1, a, 1) \in \Delta_{E_M}$
          \item 任意の $a \notin A^M$ に対し，$(0, a, 0) \in \Delta_{E_M}$ および $(1, a, 0) \in \Delta_{E_M}$
        \end{itemize}
\end{itemize}

さらに，並列合成 $E_\parallel = E_1 \parallel \dots \parallel E_n \parallel E_M$ において目標達成の判定を $E_M$ に一任するため，他のすべてのコンポーネント $E_i \in \{E_1, \dots, E_n\}$ について，そのMarked状態集合を $S^M_{E_i} = S_{E_i}$ （全状態をMarkedとする）へ再定義する．

この変換により，合成システム $E_\parallel$ がMarked状態にあることは，$E_M$ が状態 $1$ にあることと等価になる．$E_M$ は直前に実行されたアクションが $A^M$ に属する場合のみ状態 $1$ に遷移するため，このMarked状態を無限回訪問することは，元のシステムにおいてMarkingアクションを無限回発火し続けるNon-blockingな振る舞いと完全に一致する．

\subsection{On-The-Fly探索アルゴリズム}

従来のアプローチでは，まずオートマトンを完全に合成し，その後で制御問題を解く．
しかし，この方法は指数的な状態空間爆発を引き起こす可能性がある．
Ciolekらは，この課題に対し，ヒューリスティック関数に導かれたOn-The-Fly探索により，状態空間の一部のみを探索してDirected Controllerを発見するアルゴリズムを提案した~\cite{DirectedControllerSynthesis}．
ヒューリスティック関数は，各状態から目標までの推定距離を計算することで，有望な探索経路を優先的に選択する手法であり~\cite{Heuristic}，DCSにおいても探索効率の向上に重要な役割を果たす．

On-The-Fly探索は，状態空間全体を事前に構築することなく，初期状態から到達可能な必要な部分のみを段階的に展開しながら制御器を合成する手法である．
この手法は，主に以下の3つのプロセスから構成される．

\begin{enumerate}
  \item \textbf{展開（Expansion）}:
        現在の探索フロンティアから，ヒューリスティック関数（例えばRA）を用いて最も有望な未探索の遷移を選択し，探索グラフに追加する（\textsc{ExpandNext}）．これにより，Marked状態への到達可能性が高い経路を優先的に探索する．
  \item \textbf{伝播（Propagation）}:
        ある状態が\textit{Goals}（勝利状態）または\textit{Errors}（敗北状態）であることが確定した場合，その情報を探索グラフの逆方向（親状態）へ伝播させる（\textsc{PropagateGoal}, \textsc{PropagateError}）．
        状態の分類は以下の論理に基づき決定される：
        \begin{itemize}
          \item \textbf{Goalsへの伝播}：
                ある状態から制御可能な遷移によって少なくとも1つの\textit{Goals}状態へ到達可能であるか，あるいはその状態から発生しうる全ての制御不能な遷移の先が\textit{Goals}である場合，その状態は\textit{Goals}となる．
          \item \textbf{Errorsへの伝播}：
                ある状態から発生しうる全ての制御可能な遷移の先が\textit{Errors}かつ制御不能な遷移によって少なくとも1つの\textit{Errors}状態へ到達可能である場合，その状態は\textit{Errors}となる．
        \end{itemize}
  \item \textbf{閉路検出と判定（Loop Detection）}:
        探索中に新たな閉路が形成された場合，その閉路がNon-Blockingを満たすか否かを判定する．
        Markingアクションを含む閉路などの「勝利閉路」が見つかれば，その閉路上の状態は\textit{Goals}となり，逆にMarkingアクションを含まず脱出不可能な閉路は\textit{Errors}となる．
\end{enumerate}

探索は初期状態が\textit{Goals}または\textit{Errors}に分類されるまで継続される．初期状態が\textit{Goals}に分類された場合，探索グラフから有効な部分グラフを抽出することで制御器が得られる．逆に\textit{Errors}に分類された場合は，制御器の合成は不可能であると結論付けられる．

\begin{algorithm}
  \caption{On-The-Fly探索によるDirected Controller Synthesis}
  \label{alg:dcs}
  \begin{algorithmic}[1]
    \Require{全てのLTSの組 $\bm{E} = (E_1, \ldots, E_n)$，ヒューリスティック関数 $H$}
    \Ensure{Directed Controller $C$ または 合成不可能}

    \Function{DirectedControllerSynthesis}{$\bm{E}, H$}

    \State $\mathit{ES} \gets$初期状態$\bm{s}_0$のみを持つ部分探索グラフ
    \State $\mathit{Goals} \gets \emptyset, \mathit{Errors} \gets \emptyset, \mathit{None} \gets \{\bm{s}_0\}$

    \Statex

    \LComment{探索ループ：初期状態が未分類状態でなくなるまで}
    \While{$\bm{s}_0 \notin (\mathit{Goals} \cup \mathit{Errors})$}
      \State $(\bm{s}, a, \bm{s}') \gets \textsc{ExpandNext}(\mathit{ES}, H)$ \Comment{ヒューリスティックによる次遷移の選択}
      \State $\mathit{ES} \gets \mathit{ES} \cup \{(\bm{s}, a, \bm{s}')\}$ \Comment{探索グラフの更新}

      \Statex
      \If{$\bm{s}' \in \mathit{Errors}$}
        \State $\mathit{Errors} \gets \mathit{Errors} \cup \{\bm{s}'\}$
        \State $\textsc{PropagateError}(\bm{s}')$ \Comment{敗北状態の伝播}
      \ElsIf{$\bm{s}' \in \mathit{Goals}$}
        \State $\mathit{Goals} \gets \mathit{Goals} \cup \{\bm{s}'\}$
        \State $\textsc{PropagateGoal}(\bm{s}')$ \Comment{勝利状態の伝播}
      \ElsIf{$\bm{s}'$ が新しいループを形成する}
        \State $\mathit{Loop} \gets \textsc{GetLoop}(\bm{s}, \bm{s}')$
        \If{$\mathit{Loop}$ が勝利条件を満たす}
          \State $\mathit{newGoals} \gets \textsc{FindNewGoals}(\mathit{Loop})$
          \State $\mathit{Goals} \gets \mathit{Goals} \cup \mathit{newGoals}$
          \State $\textsc{PropagateGoal}(\mathit{newGoals})$
        \Else
          \State $\mathit{newErrors} \gets \textsc{FindNewErrors}(\mathit{Loop})$
          \State $\mathit{Errors} \gets \mathit{Errors} \cup \mathit{newErrors}$
          \State $\textsc{PropagateError}(\mathit{newErrors})$
        \EndIf
      \EndIf
    \EndWhile

    \Statex

    \If{$s_0 \in \mathit{Goals}$}
      \State $C \gets \textsc{ExtractController}(\mathit{ES}, \mathit{Goals})$
      \Return $C$
    \Else
      \Return 合成不可能
    \EndIf

    \EndFunction

  \end{algorithmic}
\end{algorithm}

\section{Ready Abstraction}

Ready Abstraction（RA）~\cite{ReadyAbstraction}は，並列合成構造を活用して，Marked状態への到達に必要なステップ数を多項式時間で推定するヒューリスティック手法である．
各コンポーネントの局所情報のみを用いて距離を推定することで状態空間爆発を回避しつつ，On-The-Fly探索における次遷移選択（\textsc{ExpandNext}）を導く．

RAの基本的な着想は，合成状態 $\bm{s} = (s_{E_1}, s_{E_2}, \ldots, s_{E_n})$ の周辺で局所的に発火可能なアクション（Readyアクション）を集め，それらの間に，あるアクションの実行が別のアクションの実行可能性を高めるという関係を仮想的に張ったグラフ上で最短路を解くことで，目標（Marked状態）までの距離を見積もる点にある．
この手法は，プランニング問題におけるヒューリスティック探索の一般的な枠組み~\cite{Heuristic}を，並列合成されたDESの構造に適合させたものと位置づけられる．
同期制約のため，局所的に発火可能（Ready）であっても合成状態全体では直ちに発火できない場合があるが，RAはこの差を局所到達可能性とグラフ探索に基づいて保守的に見積もる．

\subsection{展開対象のアクションの評価}

\aref{alg:ra_heuristic}は，現在の合成状態 $\bm{s}$ において展開対象のアクション $\hat{a}$ を選ぶことがどれだけ目標に近いかを評価するためのヒューリスティック関数である．
評価は各コンポーネント $E_i$ ごとに $(\mathrm{rank}, d)$ の形で返され，rank は距離推定に用いる目標集合の優先度を表す．

本章で示すRAの記述では，探索中にすでに到達したMarked状態集合 $\bm{S}^M$ を基準にした距離（Rank 0）を優先する．
これは，探索が進むほど既知の到達済み領域へ近づく選択を上位に扱うことで，任意のMarked状態を一様に目指す場合に比べて探索が過度に広がることを避け，探索空間を抑制できるという見込みに基づく．
Rank 0での推定が不可能な場合に限り，任意のMarked状態への距離（Rank 1）を用いる．
どちらも不可能と推定された場合は $(2,\infty)$ を返す．

\begin{algorithm}
  \caption{Ready Abstractionによるヒューリスティック関数}
  \label{alg:ra_heuristic}
  \begin{algorithmic}[1]
    \Require{%
      全てのLTSの組 $\bm{E} = (E_1, E_2, \ldots, E_n)$， \\
      探索到達済みのMarked状態の集合 $\bm{S}^M \subseteq S^M_{E_1} \times S^M_{E_2} \times \cdots \times S^M_{E_n}$， \\
      各LTSにおける状態の組 $\bm{s} = (s_{E_1}, s_{E_2}, \ldots, s_{E_n})$， \\
      展開対象のアクション $\hat{a}$
    }
    \Ensure{%
      各LTSにおける距離の降順の組 $\bm{d} = (\bm{d}_1, \bm{d}_2, \ldots, \bm{d}_n)$ \\
      ただし，$\bm{d}_i \in \{(0, d), (1, d), (2, \infty) \mid d \in \mathbb{N}\}$ \\
      各LTSにおける距離の意味は以下の通り： \\
      $(0, d)$：次にアクション$\hat{a}$を発火して$d$ステップで探索到達済みのMarked状態に到達可能 \\
      $(1, d)$：次にアクション$\hat{a}$を発火して$d$ステップでMarked状態に到達可能 \\
      $(2, \infty)$：Marked状態に到達不可能
    }

    \Function{ReadyAbstractionHeuristic}{$\bm{E}, \bm{S}^M, \bm{s}, \hat{a}$}

    \For{$i = 1, 2, \ldots, n$}
      \State $\mathit{minSteps} \gets \infty$

      \Statex

      \LComment{Rank 0: 探索到達済みのMarked状態への到達可能性確認}
      \ForAll{$(s^*_{E_1}, s^*_{E_2}, \ldots, s^*_{E_n}) \in \bm{S}^M$}
        \State $\mathit{steps} \gets \textsc{EstimateDistToState}(\bm{s}, \hat{a}, s^*_{E_i})$
        \If{$\mathit{steps} < \mathit{minSteps}$}
          $\mathit{minSteps} \gets \mathit{steps}$
        \EndIf
      \EndFor
      \If{$\mathit{minSteps} \ne \infty$} \Comment{いずれかの探索到達済みのMarked状態に到達可能な場合}
        \State $\bm{d}_{E_i} \gets (0, minSteps)$
        \Continue
      \EndIf

      \Statex

      \LComment{Rank 1: 任意のMarked状態への到達可能性確認}
      \ForAll{$s^*_{E_i} \in S^M_{E_i}$}
        \State $\mathit{steps} \gets \textsc{EstimateDistToState}(\bm{s}, \hat{a}, s^*_{E_i})$
        \If{$\mathit{steps} < \mathit{minSteps}$}
          $\mathit{minSteps} \gets \mathit{steps}$
        \EndIf
      \EndFor

      \If{$\mathit{minSteps} \ne \infty$} \Comment{いずれかのMarked状態に到達可能な場合}
        \State $\bm{d}_{E_i} \gets (1, minSteps)$
      \Else
        \State $\bm{d}_{E_i} \gets (2, \infty)$
      \EndIf
    \EndFor

    \Statex

    \Return $\textsc{SortDescending}((\bm{d}_{E_1}, \bm{d}_{E_2}, \ldots, \bm{d}_{E_n}))$
    \Comment{距離を辞書式降順でソートして返す}

    \EndFunction
  \end{algorithmic}
\end{algorithm}

\aref{alg:ra_heuristic}の戻り値は各コンポーネントの距離推定の組であるが，実際の探索（\textsc{ExpandNext}）においてアクション $\hat{a}$ を選択する際は，以下の優先順位に従って順位付けを行う：

\begin{enumerate}
  \item \textbf{制御不能アクションの優先}：$\hat{a} \in A^U$ であるアクションを，全ての制御可能アクション $\hat{a} \in A^C$ よりも優先する．
  \item \textbf{辞書式順序による比較}：アクションの属性が同じ（共に制御可能，あるいは共に制御不能）である場合，\aref{alg:ra_heuristic}が返す距離の組 $\bm{d}$ を辞書式に比較し，値が小さい（より目標に近いと推定される）ものを優先する．
\end{enumerate}

制御不能アクションを最優先するのは，環境側で発生しうる全ての振る舞いを早期に探索し，反例（違反状態やデッドロック）を迅速に検出するためである．

\subsection{距離推定の中核}

Ready Abstractionにおける距離推定の手続きを\aref{alg:estimate_dist_to_state}に示す．
この関数 $\textsc{EstimateDistToState}$ は，現在の合成状態 $\bm{s}$，評価対象のアクション $\hat{a}$，および目標状態 $s^*_{E_i}$ を入力とし，推定距離 $d$ を算出する．

本アルゴリズムでは，推定のために以下の2つの補助関数を利用する．

\begin{description}
  \descitem{\textnormal{$\textsc{CalculateDist}(s, a)$}}
  LTS単体において，状態 $s$ からアクション $a$ へ到達するための最短ステップ数．
  この値は探索中頻繁に参照されるため，効率化の観点から，探索開始前にすべての状態とアクションの組について幅優先探索により算出されている．

  \descitem{\textnormal{$\textsc{CalculateGap}(\bm{s}, \hat{a}, a)$}}
  現在の合成状態 $\bm{s}$ において，アクション $\hat{a}$ の実行後に別のアクション $a$ を実行可能にするために必要な最小ステップ数（切り替えコスト）．
  これは動的な状態に依存するため，探索中に都度計算される．
\end{description}

RAは，現在の状態で発火可能なReadyアクション集合 $A^R$ を対象に，そこへ至る遷移コスト（Gap）とその先の局所距離（Dist）の和が最小となる経路を探索する．
これにより，単なる最短距離ではなく，同期のための待機やアクションの切り替えコストを含んだ，より実質的な到達距離を推定している．

\begin{algorithm}
  \caption{Ready Abstractionにおける距離推定関数}
  \label{alg:estimate_dist_to_state}
  \begin{algorithmic}[1]
    \Require{%
      現在の状態 $\bm{s} = (s_{E_1}, \ldots, s_{E_n})$， \\
      評価対象のアクション $\hat{a}$， \\
      距離を推定する対象の状態 $s^*_{E_i}$
    }
    \Ensure{推定距離 $d \in \mathbb{N} \cup \{\infty\}$}

    \Function{EstimateDistToState}{$\bm{s}, \hat{a}, s^*_{E_i}$}

    \If{$\hat{a} \in A_{E_i}$} \Comment{$\hat{a}$ がLTS $E_i$ に存在している場合}
      \State $s'_{E_i} \gets s' \text{ where } (s_{E_i}, \hat{a}, s') \in \Delta_{E_i}$ \Comment{$\hat{a}$ を発火した後の状態}
      \If{$s'_{E_i} = s^*_{E_i}$} \Comment{対象の状態に到達する場合}
        \Return $1$
      \ElsIf{$s'_{E_i} \in S^I_{E_i}$} \Comment{違反状態に到達する場合}
        \Return $\infty$
        \Comment{距離を無限と推定し，Marked状態に到達不可能であることを表す}
      \ElsIf{$s'_{E_i} \ne s_{E_i}$} \Comment{他の状態に遷移する場合}
        \Return $\textsc{CalculateDist}(s'_{E_i}, s^*_{E_i}) + 1$
      \EndIf
    \EndIf

    \Statex
    \LComment{各LTS上で，現在の状態から発火可能なアクション（Readyアクション）を収集}
    \State $A^R \gets \bigcup_{i=1}^{n} \{a \mid \exists s, (s_{E_i}, a, s) \in \Delta_{E_i}, s \neq s_{E_i}, s \notin S^I_{E_i}\}$

    \Statex
    \LComment{候補アクション $\hat{a}$ から構造的に到達可能なアクション集合 $A^*$ を構築}
    \State $A^* \gets \emptyset$
    \For{$i = 1, \ldots, n$}
      \State $s'_{E_i} \gets s' \text{ where } (s_{E_i}, \hat{a}, s') \in \Delta_{E_i}$
      \If{$s'_{E_i} \neq \bot \land s'_{E_i} \notin S^I_{E_i}$}
        \State $A^* \gets A^* \cup \{ a^* \in A^R \mid T_{s'_{E_i} \to \{a^*\}} \neq \emptyset \}$
      \EndIf
    \EndFor

    \Statex
    \LComment{Gapを加味した最短経路探索}
    \State $d \gets \min_{a^* \in A^*}\{\textsc{CalculateGap}(\bm{s}, \hat{a}, a^*) + \textsc{EstimateDistToState}(\bm{s}, a^*, s^*_{E_i})\}$
    \LComment{この再帰的な最小値問題は，実装上はダイクストラ法により効率的に解かれる}

    \Return $d$

    \EndFunction
  \end{algorithmic}
\end{algorithm}

ここで用いられる \textsc{CalculateGap}$(\hat{a}, a)$ は，アクション間の切り替えのしやすさを表すコストであり，既存研究における定義に従い，あるコンポーネント内でアクション $\hat{a}$ を経て $a$ へ至る最短パスの長さ（から1を引いた値）として計算される．

\subsection{Markingアクションまでの距離推定}

前述の通り，RAはMarked状態への到達距離を推定する枠組みである．
しかし，\aref{subsec:marking_to_marked}で導入したアクションベースから状態ベースへの変換を用いる場合，判定用LTS $E_M$ を除くすべてのコンポーネントにおいて，ほぼ全状態がMarked状態として定義される．
この状況下では，任意のMarked状態への距離を計算するRAのRank 1評価は，常に $1$ を返すことになり，探索の指針として機能しない．

そこで本研究では，探索履歴である到達済みMarked状態集合 $\bm{S}^M$ に依存せず，システムのアクション構造のみに基づいて目標までの距離を推定する手法として，Markingアクション集合 $A^M$ を直接のターゲットとする距離推定関数 \textsc{EstimateDistToMarking} を定義する．
本関数は，探索の進行に伴って更新される $\bm{S}^M$ を参照しないため，探索の全期間を通じて一貫した静的な評価値を提供する．

\textsc{EstimateDistToMarking}は，候補アクション$\hat{a}$がMarkingアクションであれば距離1を返し，そうでなければ，合成状態$\bm{s}$から，同期を無視した場合に状態を変化させ得るアクション集合$A^R$を介して，Gapとその先での推定距離の和の最小値を再帰的に求める．
その構造は\aref{alg:estimate_dist_to_state}に示す \textsc{EstimateDistToState} と同型であり，終端条件がMarked状態ではなくMarkingアクションになっている点が相違である．

\begin{algorithm}
  \caption{Ready AbstractionにおけるMarkingアクションまでの距離推定}
  \begin{algorithmic}[1]
    \Require{%
      現在の状態 $\bm{s} = (s_{E_1}, \ldots, s_{E_n})$， \\
      候補のアクション $\hat{a}$
    }
    \Ensure{推定距離 $d \in \mathbb{N} \cup \{\infty\}$}

    \Function{EstimateDistToMarking}{$\bm{s}, \hat{a}$}

    \If{$\hat{a} \in A^M$}
      \Return $1$
    \EndIf

    \LComment{各LTS上で，現在の状態から発火可能なアクション（Readyアクション）を収集}
    \State $A^R \gets \bigcup_{i=1}^{n} \{a \mid \exists s, (s_{E_i}, a, s) \in \Delta_{E_i}, s \neq s_{E_i}, s \notin S^I_{E_i}\}$

    \LComment{候補アクション $\hat{a}$ から構造的に到達可能なアクション集合 $A^*$ を構築}
    \State $A^* \gets \emptyset$
    \For{$i = 1, \ldots, n$}
      \State $s'_{E_i} \gets s' \text{ where } (s_{E_i}, \hat{a}, s') \in \Delta_{E_i}$
      \If{$s'_{E_i} \neq \bot \land s'_{E_i} \notin S^I_{E_i}$}
        \State $A^* \gets A^* \cup \{ a^* \in A^R \mid T_{s'_{E_i} \to \{a^*\}} \neq \emptyset \}$
      \EndIf
    \EndFor

    \Return $\min_{a^* \in A^* \cup A^M}\{\textsc{CalculateGap}(\bm{s}, \hat{a}, a^*) + \textsc{EstimateDistToMarking}(\bm{s}, a^*)\}$

    \EndFunction
  \end{algorithmic}
\end{algorithm}

以上により，RAは局所情報から，次にどのアクションを展開するのが有望かを推定する枠組みを提供する．
On-The-Fly探索側では，これらの推定値を用いて展開順序を制御することで，合成状態空間の全探索を避けつつ，目的を満たす制御器の発見を狙う．

\chapter{Ready Abstractionの課題}
\label{chap:ready_abstraction_limitations}

前章で述べたように，Ready Abstraction（RA）は局所的に発火可能なアクション（Readyアクション）間の関係性を利用して，目標までの距離を推定するヒューリスティック手法である．
RAは，コンポーネント間の結合が疎であり，各コンポーネントが比較的自律的に目標へ遷移できるシステムにおいては強力なガイドとなる．

しかし，本研究が対象とするような，Markingアクションの発火に複数のコンポーネントによる厳密な同期が必要となるシステムにおいては，RAの推定精度と計算効率の両面で深刻な課題が生じる．
本章では，RAが抱える構造的な限界について，同期構造の無視による探索効率の低下と，Readyアクション探索に伴う計算コストの増大という2つの観点から分析する．

\section{同期構造の看過に起因する局所的な探索}

RAの最大の特徴は，現在の合成状態において直ちに発火可能なアクション（Readyアクション）のみをノードとするグラフ上で距離計算を行う点にある．
この特性は，将来的に発生する同期イベントを適切に評価できず，大域的な最適性を損なうという欠点につながる．

\subsection{同期待ち時間の無視}

Markingアクション $a_m$ が同期アクションである場合，その発火には関与する全てのコンポーネントが $a_m$ を発火可能な状態に到達していなければならない．
しかし，あるコンポーネント $E_i$ が既に $a_m$ の直前状態に到達していても，他のコンポーネント $E_j$ がまだ準備できていなければ，システム全体として $a_m$ は実行できない．

RAの距離推定アルゴリズム（\aref{alg:estimate_dist_to_state}）は，現在のReadyアクション集合 $A^R$ を起点として，目標までの最短パスを探索する．
このとき，同期が必要なアクションへのパスは，パートナーの到着を待つための遷移（同期待ち）を含める必要があるため，RAのグラフ上では遠い，あるいは到達困難と判定されやすい．
対照的に，同期を必要とせず単独で進行でき，かつ局所的に目標に近い場所へ遷移できるアクションが存在する場合，RAはその局所的な遷移コストの低さを優先して評価する．

RAはこの他者の同期待ちという大域的な制約を考慮できず，各コンポーネントが局所的な最短経路を選択し続けるような局所最適化に基づいた評価を下すため，結果として合流不可能な経路や，効率の悪い状態を優先的に探索する結果となる．

\subsection{具体的な不適合例：金属加工システム}
\label{subsec:ra_metal_processing_example}

RAが不適切な誘導を行う具体的なシナリオとして，\aref{fig:metal_processing_model}に示す金属加工システムのモデルを用いて説明する．

本システムは，加工プロセスを表す環境モデル（$E_\mathit{env}$）と，工程管理を行う要求モデル（$E_\mathit{req}$）の2つのコンポーネントから構成される．
目標は「出荷」アクションの発火（Markingアクション）である．
なお，説明を簡単にするため，本モデルに含まれる全てのアクションは制御可能（Controllable）であるとする．

環境モデルは，初期状態から「金属準備」を経て待機状態（状態1）へ遷移する．この状態1を起点として，2つの経路が存在する．
1つ目は「溶解」，「成形」，「冷却」を行い，再び待機状態に戻る加工サイクルである．
このサイクルは0回以上実行可能である．
2つ目は「研磨」や「皮膜」を施し，最後に「出荷」して初期状態に戻る仕上げ・出荷工程である．

要求モデルは，製品の品質担保のために「成形」が1度以上発火されることを強制する．
具体的には，初期状態（成形未実施，状態0）において「成形」を経ずに「出荷」アクションが発火された場合，未加工品の出荷とみなされ，違反状態$-1$（図下段の赤色ノード）へ遷移する．
「成形」が発火されると状態1（成形済み）へ遷移し，以降は「出荷」を行っても初期状態に戻るだけであり，違反にはならない．

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[shorten >=1pt, node distance=2.5cm, on grid, auto, >={Stealth}]

    % --- 環境モデル (Environment) ---
    \begin{scope}[yshift=0cm]
      \node[anchor=west] at (-3, 1) {\textbf{環境モデル} $E_\mathit{env}$};

      \node[state, initial, initial text=] (e0) {$0$};
      \node[state] (e1) [right=of e0] {$1$};
      \node[state] (e2) [right=of e1] {$2$};
      \node[state] (e3) [right=of e2] {$3$};
      \node[state] (e4) [below=of e1] {$4$};

      \path[->]
      (e0) edge node {\footnotesize 金属準備} (e1)
      (e1) edge node {\footnotesize 溶解} (e2)
      (e2) edge node {\footnotesize 成形} (e3)
      (e3) edge [bend left=45] node {\footnotesize 冷却} (e1)
      (e1) edge node [swap] {\footnotesize 研磨，皮膜} (e4)
      (e4) edge [bend left=45, orange] node {\footnotesize 出荷} (e0);
    \end{scope}

    % --- 要求モデル (Requirement) ---
    \begin{scope}[yshift=-4.5cm]
      \node[anchor=west] at (-3, 1) {\textbf{要求モデル} $E_\mathit{req}$};

      \node[state, draw=red, fill=red!15] (r-1) {$-1$};
      \node[state, initial, initial text=] (r0) [right=of r-1] {$0$};
      \node[state] (r1) [right=of r0] {$1$};

      \path[->]
      (r0) edge node {\footnotesize 成形} (r1)
      (r1) edge [loop right] node {\footnotesize 成形} ()
      (r0) edge [bend left=45, orange] node {\footnotesize 出荷} (r-1)
      (r1) edge [bend left=45, orange] node {\footnotesize 出荷} (r0);
    \end{scope}

  \end{tikzpicture}
  \caption{金属加工システムの環境モデルと要求モデル}
  \label{fig:metal_processing_model}
\end{figure}

\subsubsection{Ready Abstraction適用のためのMarked状態への変換}

RAは本来，Marked状態への到達を目的とする探索手法である．
一方，本問題の目標は「出荷」アクションの発火であるため，\aref{subsec:marking_to_marked}で述べた変換手法を適用し，アクションベースの目標を状態ベースの目標に置き換える必要がある．

\aref{fig:metal_processing_model_marked}は，変換後のシステム構成を示している．
ここでは，新たなコンポーネントとしてMarking判定モデル $E_M$ を導入している．
$E_M$は，「出荷」アクションが発火された直後のみMarked状態（状態1）に遷移し，それ以外の場合は非Marked状態（状態0）に留まる機能を持つ．
いわば，アクションの発火イベントを状態遷移として表現するためのモデルである．

この変換に伴い，既存の環境モデル $E_\mathit{env}$ および要求モデル $E_\mathit{req}$ においては，違反状態を除くすべての状態をMarked状態（図中の二重丸）として再定義する．
これにより，システム全体の並列合成状態がMarkedとなる（全てのコンポーネントが同時にMarked状態にある）ための条件は，実質的に$E_M$が状態1になること，すなわち直前に出荷アクションが発火したことと等価になる．

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[shorten >=1pt, node distance=2.5cm, on grid, auto, >={Stealth}]

    % --- 環境モデル (Environment) ---
    \begin{scope}[yshift=0cm]
      \node[anchor=west] at (-3, 1) {\textbf{環境モデル} $E_\mathit{env}$};

      \node[state, initial, initial text=, accepting] (e0) {$0$};
      \node[state, accepting] (e1) [right=of e0] {$1$};
      \node[state, accepting] (e2) [right=of e1] {$2$};
      \node[state, accepting] (e3) [right=of e2] {$3$};
      \node[state, accepting] (e4) [below=of e1] {$4$};

      \path[->]
      (e0) edge node {\footnotesize 金属準備} (e1)
      (e1) edge node {\footnotesize 溶解} (e2)
      (e2) edge node {\footnotesize 成形} (e3)
      (e3) edge [bend left=45] node {\footnotesize 冷却} (e1)
      (e1) edge node [swap] {\footnotesize 研磨，皮膜} (e4)
      (e4) edge [bend left=45] node {\footnotesize 出荷} (e0);
    \end{scope}

    % --- 要求モデル (Requirement) ---
    \begin{scope}[yshift=-4.5cm]
      \node[anchor=west] at (-3, 1) {\textbf{要求モデル} $E_\mathit{req}$};

      \node[state, draw=red, fill=red!15] (r-1) {$-1$};
      \node[state, initial, initial text=, accepting] (r0) [right=of r-1] {$0$};
      \node[state, accepting] (r1) [right=of r0] {$1$};

      \path[->]
      (r0) edge node {\footnotesize 成形} (r1)
      (r1) edge [loop right] node {\footnotesize 成形} ()
      (r0) edge [bend left=45] node {\footnotesize 出荷} (r-1)
      (r1) edge [bend left=45] node {\footnotesize 出荷} (r0);
    \end{scope}

    \begin{scope}[yshift=-7.5cm]
      \node[anchor=west] at (-3, 1.2) {\textbf{Marking判定モデル} $E_M$};

      \node[state, initial, initial text=] (m0) {$0$};
      \node[state, accepting] (m1) [right=3.5cm of m0] {$1$};

      \path[->]
      (m0) edge [loop below] node {\footnotesize $A_{E_\mathit{env}} \setminus \{\text{出荷}\}$} ()
      (m1) edge [bend left=20] node {\footnotesize $A_{E_\mathit{env}} \setminus \{\text{出荷}\}$} (m0)
      (m0) edge [bend left=20] node {\footnotesize 出荷} (m1)
      (m1) edge [loop below] node {\footnotesize 出荷} ();
    \end{scope}

  \end{tikzpicture}
  \caption{アクション目標を状態目標へ変換した金属加工システム}
  \label{fig:metal_processing_model_marked}
\end{figure}

\subsubsection{RAによる探索と失敗のプロセス}

前目で述べた変換後の金属加工システム（\aref{fig:metal_processing_model_marked}）に対し，RAを用いたOn-The-Fly探索を適用した場合の具体的な挙動を示す．
本モデルでは，$E_\mathit{env}$ と $E_\mathit{req}$ の全状態がMarkedと設定されているため，探索の主目的は Mark判定モデル $E_M$ を状態1（Marked）に遷移させること，すなわち「出荷」アクションを発火させることになる．

RAを用いた場合でも，最終的には適切な制御器が合成されるが，その過程で生じる非効率な探索挙動について以下に段階的に示す．

\begin{description}
  \descitem{Step 1: 初期状態からの遷移}
  初期状態 $\bm{s}_0 = (0, 0, 0)$ （順に $E_\mathit{env}, E_\mathit{req}, E_M$ の状態）において，発火可能なアクションは金属準備のみである．
  システムはこれを選択し，状態 $\bm{s}_1 = (1, 0, 0)$ へ遷移する．
  このとき，$E_\mathit{env}$ は状態1（分岐点）に進むが，$E_\mathit{req}$ と $E_M$ は金属準備に関与しないため状態0に留まる．

  \descitem{Step 2: RAによるヒューリスティック評価と誤った選択}
  状態 $\bm{s}_1$ において，RAは次に選択すべきアクションを決定する．
  この時点で局所的に発火可能なアクション（Readyアクション）の集合は，$A^R = \{\text{研磨}, \text{皮膜}, \text{溶解}, \text{成形}, \text{出荷}\}$ である．

  まず，環境モデル $E_\mathit{env}$ および要求モデル $E_\mathit{req}$ の評価を行う．
  これらは設定により全状態がMarkedであるため，現在の状態が既に目標であるとみなされる．したがって，これらのコンポーネントにおける距離推定値は $1$ となり，アクション選択の差別化要因とならない．

  したがって，評価の差が生じるのは Mark判定モデル $E_M$ における推定である．
  $E_M$ がMarked状態（状態1）へ遷移するためには，同期アクションである「出荷」の発火が不可欠である．
  RAは，展開対象のアクション $\hat{a}$ から「出荷」へのGap（遷移コスト）と，その先の $E_M$ における距離（Dist）の和として値を算出する．

  \begin{description}
    \descitem{選択肢A：「研磨」または「皮膜」}
    環境モデル $E_\mathit{env}$ において，「研磨」または「皮膜」から「出荷」へのGapは $1$ である．
    一方，$E_M$ において「出荷」発火後の状態はMarked状態そのものであるため，その距離（Dist）は $1$ である．
    よって，推定距離は $d = 1 + 1 = 2$ と算出される．

    \descitem{選択肢B：「溶解」}
    環境モデル $E_\mathit{env}$ において，「溶解」から「成形」「冷却」を経て「出荷」に至る最小のGapは $3$ である．
    $E_M$ における距離（Dist）は同様に $1$ である．
    よって，推定距離は $d = 3 + 1 = 4$ と算出される．
  \end{description}

  RAはこの推定値に基づき，距離の小さい（$2 < 4$）「研磨」および「皮膜」を優先すべき有望なアクションと判断する．
  その結果，アルゴリズムは正解ルートである「溶解」を後回しにし，まずは局所的な算出コストが低い「研磨」を選択して状態 $\bm{s}_2 = (4, 0, 0)$ への遷移を行う．

  \descitem{Step 3: 経路の行き詰まりと繰り返される不要な探索}
  遷移後の状態 $\bm{s}_2 = (4, 0, 0)$ において，環境モデル上では出荷が可能である．
  しかし，要求モデル $E_\mathit{req}$ は依然として状態0（成形未実施）にある．
  この状態で出荷を発火すると，$E_\mathit{req}$ は違反状態（$-1$）へ遷移してしまうため，DCSの安全性制約によりこの遷移は禁止される．
  他に有効なアクションも存在しないため，この経路は探索の行き詰まりとなる．

  この結果，探索アルゴリズムはこの経路を破棄し，分岐点である状態 $\bm{s}_1$ までバックトラックを行う．
  しかし，RAのヒューリスティック評価では，残る選択肢である「皮膜」も「溶解」よりコストが低いと判定されている．
  そのため，アルゴリズムは「溶解」を選ぶ前に，もう一方の選択肢である「皮膜」の探索へ移行する．
  「皮膜」ルートも同様に同期待機ができず行き詰まりとなるため，再びバックトラックが発生する．

  このように，RAのヒューリスティック値に従い2つの冗長な経路を探索し尽くした後に，ようやく次善の選択肢であった「溶解」ルートの探索が開始される．
\end{description}

以上のプロセスにより，RAを用いた探索では，同期（$E_\mathit{req}$ の状態進行）の必要性を見抜けずに，局所的に目標アクション「出荷」へ近づきやすい経路を優先して探索する．
大規模なシステムにおいては，このような冗長な探索とバックトラックが頻発し，計算リソースを著しく浪費する原因となる．

\section{網羅的な距離推定による計算資源の浪費}

RAのもう一つの課題は，ヒューリスティック関数の評価プロセスそのものに内在する計算の冗長性と，それに伴うコストの増大である．

前章の\aref{alg:ra_heuristic}で示した通り，RAは1回の探索ステップ（\textsc{ExpandNext}）において，システムを構成する全てのコンポーネント $E_i \; (i=1, \dots, n)$ に対し，以下の2段階の評価を網羅的に実行する．

\begin{enumerate}
  \item Rank 0の評価: 探索中に到達済みのMarked状態への距離を計算する．
  \item Rank 1の評価: 上記が到達不能な場合，モデル上の全てのMarked状態への距離を計算する．
\end{enumerate}

すなわち，アクションを1つ選択するたびに，最大で $2n$ 回の距離推定関数（\textsc{EstimateDistToState}）が呼び出されることになる．
ここで呼び出される距離推定関数は，\aref{chap:background}で述べた通り，Readyアクショングラフ上の探索を行う処理である．
単一の計算は多項式時間で完了するが，状態や遷移に依存した動的な計算処理を伴う．

問題となるのは，この計算が現在の状態遷移に関与しないコンポーネントを含めた全てに対し，一律に実行される点である．
大規模な並列システムにおいて，ある瞬間に状態遷移のボトルネックとなっているコンポーネントは全体の一部に限られ，他は待機状態や無関係な状態にあることが多い．
しかし，RAはそのような文脈を考慮せず，全てのコンポーネントに対して毎回同様に探索計算を行う．

システム規模が拡大しコンポーネント数 $n$ が増加すると，この網羅的な探索プロセスは，探索の進行に寄与しない冗長な計算を繰り返すことを意味する．
結果として，本来不要なヒューリスティック値の算出に計算機資源を費やすことになり，大規模システムにおける合成全体の効率を低下させる要因となる．

\section{本章のまとめ}

本章では，Markingアクションを目標とする離散制御器合成において，従来のReady Abstractionが抱える課題を分析した．

第一の課題は同期の無視である．RAは局所的な最短経路を優先するため，同期のための準備動作よりも，単独で進行可能な近道を過剰評価する．これにより，パートナーの到着を待てずに脇道へ逸れる探索（不要な探索）が発生する．

第二の課題は計算の冗長性である．RAは距離推定のために，現在の状態に関与しないコンポーネントも含めて最大 $2n$ 回の計算を一律に行うため，システム規模に対して不必要な計算資源を浪費する．

これらの課題は，RAが同期構造に対する大域的な視点を欠いていることと，全コンポーネントを等しく評価対象とする網羅的な計算構造に起因する．
次章では，これらの問題を解決するために，目標達成に不可欠なアクションをPre-Markingアクション（PMA）として定義し，これを中間目標（ランドマーク）として導入する新たな手法「Landmark Ready Abstraction」を提案する．
本手法は，PMAへの到達を優先することで同期を適切に指向すると同時に，評価対象を解決すべきPMAのみに厳選することで計算の効率化を図る．

\chapter{Landmark Ready Abstraction}
\label{chap:landmark_ready_abstraction}

前章で指摘した通り，Ready Abstraction (RA)は，並列合成されたシステムにおける局所的な遷移可能性を利用して距離を推定する強力な手法である．
しかし，RAは現在の状態から局所的に遷移可能な方向を優先して評価するため，目標達成において将来的に不可避となる同期イベントを見落とし，非効率な探索経路を選択しやすいという構造的な課題を有する．

本章では，この課題を解決するため，新たなヒューリスティック手法であるLandmark Ready Abstraction (LRA)を提案する．
LRAは，RAが持つ動的なグラフ探索の枠組みを継承しつつ，システムの大域的な構造解析に基づいて抽出された中間目標としてのPre-Markingアクションを導入する．
これにより，LRAはRAの利点である遷移コストの精密な見積もりと，静的解析による大域的な方向付けを統合し，複雑な同期構造を持つシステムに対しても効率的な探索を実現する．

\section{Pre-Markingアクションの定義と階層構造}

DCSにおいて，探索の最終目標はMarkingアクションの発火である．
しかし，大規模な並列システムにおいて，初期状態から最終目標までの距離は膨大であり，単一の目標のみを指針とした探索は，広大な状態空間の中で方向を見失うリスクが高い．
そこで本研究では，最終目標に至る過程で構造上回避することのできないアクションをPre-Markingアクションとして定義し，これを最終目標へ至るための段階的な中間目標として利用する．

\subsection{必須アクション}

Pre-Markingアクションを定義するための基礎概念として，ある目標に対する不可避性を表す必須アクションを定義する．

必須アクションとは，ある状態から目標となるアクションに至るいかなるトレースを選択したとしても，その過程で必ず実行しなければならないアクションのことである．
これは，システムが目標に到達するために回避することのできない，構造上のボトルネックや前提条件と解釈できる．

\aref{chap:background}で定義した有効トレース集合 $T_{s \to A^\mathit{Target}}$ を用いて，必須アクション集合 $M^R_E$ を以下のように定義する．

\begin{definition}[必須アクション]
  状態 $s$ における $A^\mathit{Target}$ に対する必須アクション集合 $M^R_E(s, A^\mathit{Target})$ は，目標へ至る全ての有効なトレースにおいて共通して出現するアクション（目標自身を除く）として定義される．

  $$ M^R_E(s, A^\mathit{Target}) = \left( \bigcap_{t \in T_{s \to A^\mathit{Target}}} A_t \right) \setminus A^\mathit{Target} $$

  ここで，$A_t$ はトレース $t$ に含まれるアクションの集合を表す．

\end{definition}

この定義により，$M^R_E(s, A^\mathit{Target})$ に含まれるアクションが未発火である限り，$s$ から $A^\mathit{Target}$ への到達は不可能であることが保証される．

\subsection{Pre-Markingアクションの階層定義}

必須アクションの概念を用い，システムの最終目標から逆算された依存関係の階層を構築する．
本手法では，階層を以下の2段階に区分して定義する．

\begin{definition}[Primary Pre-Markingアクション]
  システム全体の最終目標であるMarkingアクション集合 $A^M$ に対する必須アクションをPrimary Pre-Markingアクションと呼ぶ．
  各状態 $s$ における Primary Pre-Markingアクション集合 $M^\mathit{PP}_E(s)$ は以下のように定義される．
  $$ M^\mathit{PP}_E(s) = M^R_E(s, A^M) \cap M^R_E(s_{E,0}, A^M) $$
\end{definition}

この定義において，$M^R_E(s_{E,0}, A^M)$ は初期状態において大域的に特定される必須アクションであり，$M^R_E(s, A^M)$ は現在の状態 $s$ から見て必須となるアクションである．
これらの積集合をとることで，$M^\mathit{PP}_E(s)$ は，構造上あらかじめ決定されたボトルネックのうち，現時点で未解決のもののみを保持する集合となる．

\begin{definition}[Secondary Pre-Markingアクション]
  ある特定のPre-Markingアクション $a^*$ に対する必須アクションをSecondary Pre-Markingアクションと呼ぶ．
  各状態 $s$ において，特定の $a^*$ に対して必須となるアクション集合 $M^\mathit{SP}_E(s, a^*)$ は以下のように定義される．
  $$ M^\mathit{SP}_E(s, a^*) = M^R_E(s, \{a^*\}) \cap M^R_E(s_{E,0}, \{a^*\}) $$
\end{definition}

ここで，Primary Pre-MarkingアクションがいずれかのMarkingアクションへの到達という選言的な目標に対する必須要件であるのに対し，Secondary Pre-Markingアクションは特定のPre-Markingアクション $a^*$ への到達という単一の目標に対する必須要件である．
本研究では，これらを総称してPre-Markingアクション（PMA）と呼び，探索の指針として用いる．

\section{Pre-Markingアクションの抽出アルゴリズム}

前節の定義に基づき，各状態におけるPMAを抽出するアルゴリズムについて述べる．
なお，本アルゴリズムは探索開始前に一度だけ実行される静的解析である．
定義に従って全ての状態とアクションの組み合わせを網羅的に検査することは，計算コストの観点から現実的ではない．
そのため，本手法では以下の2段階からなる効率的な抽出手法を採用する．

\subsection{必須アクションの抽出}

まず，任意の目標に対する必須アクションを抽出する汎用的な手続きについて述べる．
本手続きは，計算効率を考慮し，最短パス情報による候補集合の限定と，逆方向探索による必須性の判定という2つの工程で構成される．

\begin{description}
  \descitem{Step 1: 最短パスによる候補集合の限定}
  必須アクションは，目標に至るいかなる経路にも含まれるという性質を持つため，初期状態から目標への最短パス上にも必ず存在する．
  したがって，初期状態から目標への最短パスを算出し，そこに含まれるアクションのみを必須アクションの候補とすることで，検査対象となるアクション数を大幅に削減できる．

  \descitem{Step 2: 逆方向探索による必須性の判定}
  限定された候補アクション $a$ が真に不可避であるかを確認するため，アクション $a$ を経由せずに目標へ到達可能か否かを判定する．
  これは，目標のアクションを発火可能な状態集合を起点とし，遷移を逆方向に辿る探索を行うことで効率的に実行できる．
  この逆探索によって初期状態 $s_{E,0}$ に到達可能である場合，アクション $a$ を回避する経路が存在することを意味するため，$a$ は必須ではないと判断される．
  逆に，$s_{E,0}$ に到達できない場合，$a$ は初期状態において目標アクションの発火のための必須アクションであると確定する．
\end{description}

このアルゴリズムを\aref{alg:extract_required}に示す．
なお，本アルゴリズムはPMAの抽出を目的としているため，初期状態において必須でないアクションは，各状態における必須性に関わらず除外する．
したがって，得られる結果 $M$ は，必須アクションの定義における $M^R_E(s, A^\mathit{Target}) \cap M^R_E(s_{E,0}, A^\mathit{Target})$ の条件を満たす集合となる．

\begin{algorithm}
  \caption{必須アクションの抽出}
  \label{alg:extract_required}
  \begin{algorithmic}[1]
    \Require{LTS $E = (S_E, s_{E,0}, S_E^I, A_E, \Delta_E)$，目標アクション集合 $A^\mathit{Target} \subseteq A_E$}
    \Ensure{%
      各状態における必須アクション集合 $M: S_E \to 2^{A_E}$ \\
      ただし $M(s) = M^R_E(s, A^\mathit{Target}) \cap M^R_E(s_{E,0}, A^\mathit{Target})$
    }

    \Function{ExtractRequiredActions}{$E, A^\mathit{Target}$}
    \ForAll{$s \in S_E$}
      $M(s) \gets \emptyset$
    \EndFor

    \Statex
    \LComment{Step 1: 最短パス情報による候補集合の限定}
    \State $\hat{A}_{E} \gets A_{E}$
    \ForAll{$a^* \in A^\mathit{Target}$}
      \State $t \gets \operatorname*{argmin}_{t \in T_{s_{E,0} \to \{a^*\}}} |t|$
      \State $\hat{A}_{E} \gets \hat{A}_{E} \cap A_t$
      \Comment{全ての目標への最短パスに含まれるアクションのみを候補とする}
    \EndFor

    \Statex
    \LComment{Step 2: 逆方向探索による必須性の判定}
    \For{$\hat{a} \in \hat{A}_{E}$}
      \LComment{アクション $\hat{a}$ を通らずに目標に到達可能な状態（不要状態）を探索}
      \State $S^* \gets \{ s \mid \exists a^* \in A^\mathit{Target}, \exists s', (s, a^*, s') \in \Delta_E \land s' \notin S^I_E \}$
      \State $S^*_{\mathit{new}} \gets S^*$

      \While{$S^*_\mathit{new} \neq \emptyset$}
        \State $S^*_\mathit{next} \gets S^*$
        \ForAll{$s^* \in S^*_\mathit{new}$}
          \LComment{$s^*$ へ遷移可能な親状態 $s$ を探索（逆伝播）}
          \ForAll{$(s, a, s^*) \in \Delta_E$}
            \If{$a \neq \hat{a}$}
              \State $S^*_\mathit{next} \gets S^*_\mathit{next} \cup \{s\}$
            \EndIf
          \EndFor
        \EndFor
        \State $S^*_\mathit{new} \gets S^*_\mathit{next} \setminus S^*$
        \State $S^* \gets S^*_\mathit{next}$
      \EndWhile

      \LComment{初期状態から不可避であれば，必須状態に $\hat{a}$ を割り当て}
      \If{$s_{E,0} \notin S^*$}
        \For{$s \in S_E \setminus S^*$}
          \State $M(s) \gets M(s) \cup \{\hat{a}\}$
        \EndFor
      \EndIf
    \EndFor

    \Return $M$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{階層構造の構築}

次に，\aref{alg:extract_required}で定義した必須アクション抽出関数を用い，システム全体におけるPre-Markingアクションの階層構造を構築する．
本アルゴリズムは，Primary Pre-Markingアクションの抽出と，それに続くSecondary Pre-Markingアクションの連鎖的な抽出の2段階からなる．

第一段階では，Markingアクション集合 $A^M$ を目標としてPrimary PMA $M^\mathit{PP}_E$ を抽出する．
ここで，Markingアクションが特定のコンポーネントのみに関連する場合や同期アクションである場合を考慮し，Markingアクション集合全体を含むLTSのみを抽出対象とする．
これにより，目標との関連性が薄いコンポーネントにおける誤検出を回避する．

第二段階では，抽出されたPrimary PMAを起点として，Secondary PMA $M^\mathit{SP}_E$ の抽出を行う．
ここでは，あるコンポーネントで発見された必須アクションが，同期を介して他のコンポーネントにおける必須アクションとなる依存関係を網羅する必要がある．
そのために，不動点反復に基づくアプローチを採用する．
具体的には，初期状態で有効なPMAを探索すべき目標集合として管理し，未処理の目標に対して各LTSで必須アクション抽出を実行する．
そこで新たに初期状態で有効な必須アクションが発見された場合，それを新たな目標として集合に追加する．
この操作を新たな目標が発見されなくなるまで繰り返すことで，システム全体に跨る多段階の依存関係を漏らさず抽出する．

このシステム全体に対する階層構築アルゴリズムを\aref{alg:extract_pre_marking}に示す．

\begin{algorithm}
  \caption{Pre-Markingアクション階層の構築}
  \label{alg:extract_pre_marking}
  \begin{algorithmic}[1]
    \Require{全てのLTSの組 $\bm{E} = (E_1, E_2, \ldots, E_n)$}
    \Ensure{%
      各LTSの各状態におけるPrimary Pre-Markingアクション集合 $M^\mathit{PP}_E: S_E \to 2^{A_E}$， \\
      各LTSの各状態におけるSecondary Pre-Markingアクション集合 $M^\mathit{SP}_E: (S_E \times A_E) \to 2^{A_E}$
    }

    \Function{ExtractPreMarkingActions}{$\bm{E}$}
    \LComment{Step 1: Primary Pre-Markingアクションの抽出}
    \State $A^M \gets \bigcup_{i=1}^{n} A^M_{E_i}$ \Comment{全LTSのMarkingアクション集合の和集合}
    \For{$i = 1, \ldots, n$}
      \If{$A^M \subseteq A_{E_i}$}
        \LComment{Markingアクションを全て含むLTSにおいてのみ抽出}
        \State $M^\mathit{PP}_{E_i} \gets \textsc{ExtractRequiredActions}(E_i, A^M)$
      \Else
        \ForAll{$s \in S_{E_i}$}
          $M^\mathit{PP}_{E_i}(s) \gets \emptyset$
        \EndFor
      \EndIf
    \EndFor

    \Statex
    \LComment{Step 2: Secondary Pre-Markingアクションの連鎖的抽出}
    \State $A^* \gets \bigcup_{i=1}^{n} M^\mathit{PP}_{E_i}(s_{E_i,0})$ \Comment{初期状態で有効なPrimary PMAが初期目標}
    \State $A^*_\mathit{new} \gets A^*$ \Comment{新たに追加された目標集合}
    \While{$A^*_\mathit{new} \neq \emptyset$} \Comment{新たな目標が追加されなくなるまで反復}
      \ForAll{$a^* \in A^*_\mathit{new}$} \Comment{未処理の目標アクションについて}
        \For{$i = 1, \ldots, n$}
          \If{$a^* \in A_{E_i}$}
            \LComment{目標アクション $a^*$ を含むLTSにおいてのみ抽出}
            \State $M\gets \textsc{ExtractRequiredActions}(E_i, \{a^*\})$
            \ForAll{$s \in S_{E_i}$}
              $M^\mathit{SP}_{E_i}(s, a^*) \gets M(s)$
            \EndFor
          \Else
            \ForAll{$s \in S_{E_i}$}
              $M^\mathit{SP}_{E_i}(s, a^*) \gets \emptyset$
            \EndFor
          \EndIf
        \EndFor
      \EndFor
      \LComment{新たに発見されたPMAを次回の目標とする}
      \State $A^*_\mathit{new} \gets \left( \bigcup_{a^* \in A^*_\mathit{new}} \bigcup_{i=1}^{n} M^\mathit{SP}_{E_i}(s_{E_i,0}, a^*) \right) \setminus A^*$
      \State $A^* \gets A^* \cup A^*_\mathit{new}$
    \EndWhile

    \Return $M^\mathit{PP}_{E_i},\; M^\mathit{SP}_{E_i} \quad (i = 1, \ldots, n)$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\section{Landmark Ready Abstractionによる評価}

本節では，抽出されたPMAを用い，各状態の有望さを定量的に評価するヒューリスティック関数について述べる．
従来のReady Abstraction (RA) は，最終目標への幾何的な距離のみを評価指標としており，その到達過程で構造上不可避となる中間のボトルネックを考慮していない．
そのため，局所的には目標に近づいているように見えても，実際には必須となる手順を回避してしまい，後の探索で行き詰まるような経路を高く評価してしまう可能性がある．

これに対しLandmark Ready Abstraction (LRA) では，抽出されたPMAを，最終目標に至るために経由しなければならない中間目標（ランドマーク）として扱う．
未解決のPMAを距離計算の対象に含めることで，ボトルネックの解消にかかるコストを評価値に反映し，より精度の高い距離推定を実現する．
LRAは距離推定の実行対象を，その時点で解決すべきPMAおよび最終目標のみに限定するため，探索1ステップあたりの計算コストを抑制できるという利点も持つ．

\subsection{ヒューリスティック関数の構成}

LRAにおけるヒューリスティック関数 $\textsc{LandmarkReadyAbstractionHeuristic}$ の全体構成について述べる．
本関数は，最終目標であるMarkingアクションへの到達距離を基準としつつ，抽出されたPMAへの距離を評価に組み込むことで，構造的なボトルネックを反映した値を算出する．

具体的な計算手順は以下の通りである．
まず，基本となる評価値として，システムの最終目標であるMarkingアクション集合 $A^M$ への到達距離を算出する．
これにより，障害物がない理想的な状況下での最短ステップ数が得られる．

次に，現在の状態において解決すべきPMA集合 $A^P$ を構築する．
この集合は，現在の状態で必須となっているPrimary PMAを起点とし，そこから依存関係にあるSecondary PMAを再帰的に探索することで生成される．
具体的には，Primary PMA集合に対し，各アクションの前提となるSecondary PMAを追加する操作を，新たなアクションが追加されなくなるまで繰り返す．
これにより，Primary層だけでなく，より深い階層にある潜在的なボトルネックも網羅的に収集される．

最後に，収集された各PMA $a \in A^P$ について到達距離を算出し，これらを現在の推定距離と比較して最大値を更新する．
ここで，PMAへの距離に $1$ を加算しているのは，PMAが最終目標に至るための通過点であり，その達成後も少なくとも1ステップ以上の遷移が必要であることを評価値に反映させるためである．
並列システムの完了時間は，最も解決に時間を要するボトルネック工程によって律速されるため，これらの距離の最大値を採用することで，システム全体としての実質的な残り距離を見積もる．

このアルゴリズムを\aref{alg:lra_heuristic}に示す．
なお，関数 $\textsc{EstimateDistToActions}$ は次項で定義する距離推定関数であり，指定された状態から目標アクション集合へのGapを考慮した距離を返すものとする．

\begin{algorithm}
  \caption{Landmark Ready Abstractionによるヒューリスティック関数}
  \label{alg:lra_heuristic}
  \begin{algorithmic}[1]
    \Require{%
      全てのLTSの組 $\bm{E} = (E_1, E_2, \ldots, E_n)$， \\
      Primary Pre-Markingアクション写像 $\bm{M}^\mathit{PP} = (M^\mathit{PP}_{E_1}, \ldots, M^\mathit{PP}_{E_n})$， \\
      Secondary Pre-Markingアクション写像 $\bm{M}^\mathit{SP} = (M^\mathit{SP}_{E_1}, \ldots, M^\mathit{SP}_{E_n})$， \\
      現在の状態 $\bm{s} = (s_{E_1}, s_{E_2}, \ldots, s_{E_n})$， \\
      展開対象のアクション $\hat{a}$
    }
    \Ensure{推定距離 $d \in \mathbb{N} \cup \{\infty\}$}

    \Function{LandmarkReadyAbstractionHeuristic}{$\bm{E}, \bm{M}^\mathit{PP}, \bm{M}^\mathit{SP}, \bm{s}, \hat{a}$}

    \LComment{Step 1: 最終目標（Markingアクション）への距離計算}
    \State $A^M \gets \bigcup_{i=1}^{n} A^M_{E_i}$
    \State $d \gets \textsc{EstimateDistToActions}(\bm{s}, \hat{a}, A^M)$

    \Statex
    \LComment{Step 2: Pre-Markingアクション集合の構築と距離更新}
    \State $A^P \gets \bigcup_{i=1}^{n} M^\mathit{PP}_{E_i}(s_{E_i})$
    \State $A^P_\mathit{new} \gets A^P$

    \While{$A^P_\mathit{new} \neq \emptyset$}
      \State $A^P_\mathit{new} \gets \left( \bigcup_{a \in A^P_\mathit{new}} \bigcup_{i=1}^{n} M^\mathit{SP}_{E_i}(s_{E_i}, a) \right) \setminus A^P$
      \State $A^P \gets A^P \cup A^P_\mathit{new}$
    \EndWhile

    \ForAll{$a \in A^P$}
      \State $d' \gets \textsc{EstimateDistToActions}(\bm{s}, \hat{a}, \{a\})$
      \State $d \gets \max(d, d' + 1)$
    \EndFor

    \Return $d$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{アクション集合への距離推定}

前節のヒューリスティック関数内で用いられる $\textsc{EstimateDistToActions}$ は，現在の合成状態 $\bm{s}$ において，ある候補アクション $\hat{a}$ を実行した後，指定された目標アクション集合 $A^\mathit{Target}$ のいずれかを発火するまでに必要な最小ステップ数を推定する関数である．

RAにおける距離推定（\aref{alg:estimate_dist_to_state}）が，目標となる状態集合への到達距離を算出するのに対し，本関数は目標となるアクション集合への到達距離を算出する点が異なる．
計算の基本構造はRAと共通しており，現在の状態で発火可能なアクション（Readyアクション）を介して目標へ至る経路を探索し，その過程で生じる遷移コスト（Gap）と再帰的な距離の和を最小化することで値を求める．
具体的な手続きを\aref{alg:estimate_dist_to_actions}に示す．

アルゴリズムの手順は以下の通りである．
まず，候補アクション $\hat{a}$ 自体が目標集合 $A^\mathit{Target}$ に含まれる場合，距離は $1$ と判定される．
そうでない場合，現在の状態で発火可能なReadyアクション集合 $A^R$ を起点として探索を行う．
具体的には，$\hat{a}$ から各Readyアクション $a \in A^R$ への切り替えコスト（Gap）と，その $a$ から目標までの再帰的な距離の和を計算し，その最小値を推定距離とする．

ここで用いられる $\textsc{CalculateGap}(\bm{s}, \hat{a}, a)$ は，RAと同様に，各コンポーネントにおいて $\hat{a}$ から $a$ へ至るための局所的な最大コストに基づいて算出される．
この再帰的な定義により，同期による待機やアクションの切り替えを考慮した，目標までの実質的な距離が見積もられる．

\begin{algorithm}
  \caption{目標アクション集合への距離推定}
  \label{alg:estimate_dist_to_actions}
  \begin{algorithmic}[1]
    \Require{%
      現在の状態 $\bm{s} = (s_{E_1}, \ldots, s_{E_n})$， \\
      候補のアクション $\hat{a}$， \\
      目標アクション集合 $A^\mathit{Target} \subseteq \bigcup_{i=1}^{n} A_{E_i}$
    }
    \Ensure{推定距離 $d \in \mathbb{N} \cup \{\infty\}$}

    \Function{EstimateDistToActions}{$\bm{s}, \hat{a}, A^\mathit{Target}$}

    \If{$\hat{a} \in A^\mathit{Target}$}
      \Return $1$
    \EndIf

    \LComment{各LTS上で，現在の状態から発火可能なアクション（Readyアクション）を収集}
    \State $A^R \gets \bigcup_{i=1}^{n} \{a \mid \exists s, (s_{E_i}, a, s) \in \Delta_{E_i}, s \neq s_{E_i}, s \notin S^I_{E_i}\}$

    \Statex
    \LComment{候補アクション $\hat{a}$ から構造的に到達可能なアクション集合 $A^*$ を構築}
    \State $A^* \gets \emptyset$
    \For{$i = 1, \ldots, n$}
      \State $s'_{E_i} \gets s' \text{ where } (s_{E_i}, \hat{a}, s') \in \Delta_{E_i}$
      \If{$s'_{E_i} \neq \bot \land s'_{E_i} \notin S^I_{E_i}$}
        \State $A^* \gets A^* \cup \{ a^* \in A^R \cup A^\mathit{Target} \mid T_{s'_{E_i} \to \{a^*\}} \neq \emptyset \}$
      \EndIf
    \EndFor

    \Statex
    \LComment{依存関係にあるアクションの中から最短経路を探索}
    \State $d \gets \min_{a^* \in A^*} \{ \textsc{CalculateGap}(\bm{s}, \hat{a}, a^*) + \textsc{EstimateDistToActions}(\bm{s}, a^*, A^\mathit{Target}) \}$

    \Return $d$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\section{探索挙動の改善例：金属加工システム}

本節では，\aref{subsec:ra_metal_processing_example}で述べた金属加工システムの例題に対し，提案手法であるLRAを適用した場合の探索挙動を示す．
RAにおいて発生した冗長な探索を，LRAがいかにして回避し，同期に不可欠なアクションを見据えた適切な探索を行うかについて詳述する．

\subsection{Pre-Markingアクションの抽出結果}

探索に先立ち，LRAは各LTSの構造解析を行い，Pre-Markingアクション（PMA）の抽出と階層化を行う．

まず，最終目標に対する必須アクションであるPrimary PMAの抽出を行う．
環境モデル $E_\mathit{env}$ においては，初期状態から目標アクション「出荷」へ至るすべての経路において，最初のアクションである「金属準備」が必ず実行される．
したがって，「金属準備」は $E_\mathit{env}$ におけるPrimary PMAとして抽出される．
一方，要求モデル $E_\mathit{req}$ については，初期状態から「出荷」へ至る適法なトレースにおいて，アクション「成形」が必ず一度は発火されなければならない．
「成形」を回避して「出荷」を行う経路は違反状態へ遷移するため，「成形」は $E_\mathit{req}$ におけるPrimary PMAとして抽出される．

続いて，PMAに対する必須アクションであるSecondary PMAの抽出を行う．
抽出されたPrimary PMAのうち，未解決の依存関係を持つ「成形」に着目すると，環境モデル $E_\mathit{env}$ において「成形」を実行可能な状態へ到達するためには，その前段階として「溶解」が必ず実行されなければならない．
したがって，「溶解」は「成形」に対するSecondary PMAとして抽出される．

以上の解析により，探索開始時の初期状態において，システム全体の未発火PMA集合は $\{\text{金属準備}, \text{成形}, \text{溶解}\}$ となり，これらがLRAの評価対象集合 $A^P$ に含まれることになる．

\subsection{分岐点におけるヒューリスティック評価の比較}

RAが誤った選択を行った分岐点である状態 $\bm{s}_1 = (1, 0, 0)$ におけるLRAの挙動を追跡する．
この状態に至る遷移で「金属準備」は既に実行済みであるため，ここでの課題は残るPMAである「成形」および「溶解」をいかに効率よく消化するかにある．

この状態において展開可能なアクションは「研磨」，「皮膜」，「溶解」の3つである．
LRAは，これらの候補アクション $\hat{a}$ それぞれについて，実行後の状態からの最終目標（「出荷」）への距離と未消化PMA（「成形」・「溶解」）への距離を，全コンポーネントの同期構造を考慮したGap計算（$\textsc{EstimateDistToActions}$）により算出し，その最大値を評価値 $d$ とする．

すなわち，評価値は以下の式に基づき決定される．
$$
  d = \max \left(
  \begin{aligned}
       & \textsc{EstimateDistToActions}(\bm{s}_1, \hat{a}, \{\text{出荷}\}),    \\
       & \textsc{EstimateDistToActions}(\bm{s}_1, \hat{a}, \{\text{成形}\}) +1, \\
       & \textsc{EstimateDistToActions}(\bm{s}_1, \hat{a}, \{\text{溶解}\}) +1
    \end{aligned}
  \right)
$$

各選択肢における評価の詳細を以下に示す．

\begin{description}
  \descitem{選択肢A：「研磨」または「皮膜」}
  これらのアクションを選択した場合，環境モデル $E_\mathit{env}$ は状態4へ遷移し，要求モデル $E_\mathit{req}$ は状態0に留まる．

  まず，目標（「出荷」）への距離について確認する．
  この遷移後の状態において，「研磨」または「皮膜」と「出荷」の間のGap（遷移ステップ数）は $1$ である．
  これに目標アクション自身のコスト $1$ を加算し，推定距離は $1+1=2$ となる．

  次に，PMA（「成形」・「溶解」）への距離について確認する．
  状態4から「溶解」や「成形」へ到達するためには，構造的な迂回（「出荷」$\to$「金属準備」$\to \dots$）が必要となる．
  LRAの距離推定はこのコストを検出し，それぞれの距離を以下のように算出する．
  「成形」までのGapは $4$ であり，目標コスト $1$ を加えて推定距離は $5$ となる．
  「溶解」までのGapは $3$ であり，目標コスト $1$ を加えて推定距離は $4$ となる．

  結果として，最も遠いPMA（「成形」）への項が支配的となり，LRA評価値は以下のように算出される．
  $$ d = \max(2, 5, 4) = 5 $$

  \descitem{選択肢B：「溶解」}
  このアクションを選択した場合，環境モデル $E_\mathit{env}$ は状態2へ遷移する．

  まず，目標（「出荷」）への距離について確認する．
  状態2から「出荷」へ至る最短パス（「成形」$\to$「冷却」$\to$「研磨」$\to$「出荷」）に基づき，Gapは $3$ となる．
  これに目標コスト $1$ を加算し，推定距離は $4$ となる．

  次に，PMA（「成形」・「溶解」）への距離について確認する．
  「溶解」自体がPMAであるため，推定距離は $1$ と算出される．
  また，「成形」については，直後の状態からのGapは $1$ と計算される．
  これに目標コスト $1$ を加え，推定距離は $1+1=2$ となる．

  結果として，目標への距離の項が支配的となり，LRA評価値は以下のように算出される．
  $$ d = \max(4, 1, 2) = 4 $$
\end{description}

\subsection{探索の結果}

算出された推定距離を比較すると，「研磨」・「皮膜」の評価値 $5$ に対し，「溶解」の評価値は $4$ となり，より小さい値を示す．
RAは目標（「出荷」）への局所的な近さのみを見て「研磨」（距離2）を推奨したが，LRAはシステム全体としてPMA（「成形」）への到達が困難になるコストを評価値に反映している．
これにより，LRAは局所的な近道である研磨ルートを却下し，必須アクションを確実に消化できる「溶解」ルートを正しく選択する．

結果として，探索アルゴリズムはバックトラックを発生させることなく，初手から正解ルートである「溶解」$\to$「成形」$\to$「冷却」$\to$「出荷」の経路を探索する．
このように，LRAは抽出されたPMAの階層構造と，全モデルを考慮した動的距離推定を組み合わせることで，複雑な同期構造を持つシステムにおいても効率的な探索を実現する．

\chapter{評価}
\label{chap:evaluation}

本章では，提案手法であるLandmark Ready Abstraction（LRA）の有効性を検証するために実施した評価実験について述べる．
ベンチマーク問題として，同期構造や規模の異なる8つのシナリオを用意し，既存手法および提案手法における探索状態数と計算コストを比較する．

\section{評価の目的とリサーチクエスチョン}

本実験の目的は，第\ref{chap:ready_abstraction_limitations}章で指摘したReady Abstraction（RA）の課題である，同期構造の看過による探索空間の拡大および網羅的な距離推定による計算資源の浪費が，提案手法によって解決されているかを検証することである．
本評価では，以下の3つのリサーチクエスチョン（RQ）を設定し，これらに対する回答を導く形で定量的評価を行う．

\begin{description}
  \descitem{RQ1: 探索効率の改善}
  提案手法は，Pre-Markingアクションを用いた距離推定により，RAにおいて発生していた局所解への停留や不要なバックトラックを抑制し，探索状態数を削減できるか．

  \descitem{RQ2: 計算コストの削減}
  提案手法は，探索空間の削減効果により，PMA抽出などの前処理に伴うオーバーヘッドを考慮してもなお，メモリ使用量および合成時間を含めたトータルの計算コストを低減できるか．

  \descitem{RQ3: 規模拡大に対する耐性}
  システムを構成するコンポーネント数やパラメータが増加し，問題が大規模かつ複雑になった場合においても，従来手法に対する提案手法の優位性は維持・拡大されるか．
\end{description}

これらのRQを検証するため，次節に示す実験設定の下で，探索状態数，合成時間，および最大ヒープ使用量を計測し比較を行う．

\section{実験設定}

\subsection{実験環境}

本実験は，CPUにIntel Core Ultra 9 285K，メインメモリに128GBを搭載した計算機上で行った．
OSにはWindows 11 Pro (64bit) を使用した．
各アルゴリズムの実装は，離散事象システムの分析ツールであるMTSA（Model Transition System Analyser）~\cite{ModelTransitionSystemAnalyser}を拡張する形で行った．
MTSAはJava言語で開発されているため，本研究の実装もJava言語により行い，実行環境にはJava 11.0.5を用いた．
実行に際しては，Java仮想マシンの最大ヒープサイズを80GBに設定し，各テストケースに対する計算時間の制限は12時間とした．
この制限時間を超過した場合は，タイムアウトとして記録した．

\subsection{比較手法}

本実験では，探索効率と計算コストを多角的に評価するため，以下の4つの手法を比較対象とする．

\begin{description}
  \descitem{Breadth-First Search（BFS）}
  ヒューリスティックを用いない単純な幅優先探索である~\cite{IntroductionToAlgorithms}．
  探索のベースラインとして，問題の難易度や状態空間の広がりを確認するために用いる．

  \descitem{Ready Abstraction（RA）}
  Ciolekらが提案した従来手法である~\cite{ReadyAbstraction}．
  RAは，探索履歴として到達済みのMarked状態を考慮し，既知の目標に近い経路を優先する動的なヒューリスティックを用いる．
  具体的には，\aref{chap:background}で述べた通り，到達済みMarked状態への距離と，任意のMarked状態への距離の2段階で評価を行う．

  \descitem{Static Ready Abstraction（SRA）}
  RAの評価関数から探索履歴への依存を排除し，純粋にシステム構造のみに基づいて距離を推定する手法である．
  \aref{chap:background}で述べた静的な推定関数のみを用い，探索履歴（Marked状態への到達）を考慮しない手法を，本実験ではStatic Ready Abstraction（SRA）と呼ぶ．
  これを比較対象に加えることで，RAにおける履歴の利用が探索効率に与える影響を分離して評価する．

  \descitem{Landmark Ready Abstraction（LRA）}
  本研究で提案する手法である．
  事前解析により抽出されたPre-Markingアクション（PMA）を中間目標として利用し，SRAの距離推定にPMAへの到達コストを組み込んだ評価を行う．
\end{description}

\subsection{ベンチマーク問題}

評価実験には，同期構造や制約の複雑さが異なる以下の8つのシナリオを用いた．
シナリオ1からシナリオ6（AT, BW, CM, DP, TA, TL）は，離散制御器合成のベンチマークとして共通の文献~\cite{6Scenarios}で定義されている標準的なモデルである．
一方，シナリオ7およびシナリオ8は，より複雑な協調動作やリソース管理を要するモデルとして，個別の文献から採用した．
各シナリオにおいて，コンポーネント数やリソース容量などのパラメータを変化させることで問題規模を拡大し，合計27個のテストケースを作成した．

\subsubsection{シナリオ1: Air Traffic（AT）}

本シナリオは，空港における航空機の着陸管制をモデル化した問題である．
システムは $N$ 機の航空機と $K$ 段階の高度レベル，および着陸用のランプから構成される．
各航空機は着陸要求後に高度を段階的に下げてランプへ進入し着陸を行うが，安全性制約として同一高度およびランプ領域における航空機の相互排除が求められる．
本実験では，航空機数 $N$ と高度レベル数 $K$ を $(N, K) = (4, 5), (5, 5), (5, 10)$ と変化させて検証を行った．

\subsubsection{シナリオ2: Bidding Workflow（BW）}

本シナリオは，エンジニアリング企業における入札プロジェクトの評価ワークフローをモデル化した問題である．
システムは $N$ 個の評価チームと，各チームが実行可能な最大 $K$ 回の評価ステップから構成される．
各チームは文書の承認または却下を判断するが，再評価の割り当てや全員一致による承認といった複雑な承認ロジックを，安全性制約を満たしつつ制御する必要がある．
本実験では，チーム数 $N$ とステップ数 $K$ を $(N, K) = (4, 4), (4, 5), (5, 4), (5, 5)$ と変化させて検証を行った．

\subsubsection{シナリオ3: Cat and Mouse（CM）}

本シナリオは，細長い廊下におけるネコとネズミの追跡回避問題をモデル化したものである．
システムはセル状に分割された廊下と，その両端に配置された $N$ 匹のネコおよび $N$ 匹のネズミから構成される．
ネコとネズミはターン制で交互に移動し，ネズミはネコと同じセルに留まることなく，廊下の中央にある安全地帯へ到達することを目指す．
本実験では，個体数 $N$ と廊下の長さを決定するパラメータ $K$ （総セル数は $2K+1$）を $(N, K) = (2, 3), (2, 5), (3, 3), (3, 4), (4, 2)$ と変化させて検証を行った．

\subsubsection{シナリオ4: Dining Philosophers（DP）}

本シナリオは，並行システムにおける資源共有とデッドロックの古典的な例題である「食事する哲学者問題」を拡張したものである．
円卓に座る $N$ 人の哲学者が左右のフォークを共有しながら食事を行うが，本モデルでは片方のフォークを取得した後，もう一方を取得するまでに $K$ 回の所定の準備手順を実行する必要がある．
この遅延構造によりデッドロックが発生しやすい状況下で，適切な資源割り当て制御を行うことが求められる．
本実験では，哲学者数 $N$ と準備手順のステップ数 $K$ を $(N, K) = (3, 3), (4, 4), (4, 5), (5, 5)$ と変化させて検証を行った．

\subsubsection{シナリオ5: Travel Agency（TA）}

本シナリオは，旅行代理店によるWebサービスのオーケストレーションをモデル化した問題である．
システムは航空券や宿泊予約といった $N$ 種類のサービスと，各サービスの手続きに必要な最大 $K$ 回のステップから構成される．
各サービスはプロトコルが異なり，予約確保が可能な場合と，競合により購入が失敗する場合が混在するため，制御器はこれらを調整して一貫したトランザクション処理を保証する必要がある．
本実験では，サービス数 $N$ とステップ数 $K$ を $(N, K) = (3, 3), (4, 4), (4, 5), (5, 5)$ と変化させて検証を行った．

\subsubsection{シナリオ6: Transfer Line（TL）}

本シナリオは，離散制御器合成の分野で標準的なベンチマークとして知られるTransfer Line問題である．
システムは直列に接続された $N$ 台の加工機とそれらを繋ぐバッファ，および最終段の検査ユニットから構成される．
加工物は順次処理され検査を受けるが，不合格と判定された場合は再処理のために先頭のバッファへと戻される．
制御器は，各バッファのオーバーフローやアンダーフローといった違反動作を回避しつつ，システムを継続的に稼働させる必要がある．
本実験では，加工機数 $N$ とバッファ容量 $K$ を $(N, K) = (10, 10), (15, 15), (20, 20)$ と変化させて検証を行った．

\subsubsection{シナリオ7: Drone Coordination（DC）}

本シナリオは，複数のドローンによる協調飛行と資源管理をモデル化した問題である~\cite{DroneCoordinationScenario}．
システムは $N$ 機のドローンと，三次元格子状の飛行空間（最大高度 $K$）から構成される．
各ドローンはバッテリー残量を管理しながら飛行し，バッテリー低下時には上昇や遠方への移動が制限される．
安全性制約として，ドローン間の衝突回避に加え，すべてのドローンが指定された目標地点に到達した状態でのみ実行可能な同期アクション（照明の点灯）が定義されている．
本実験では，ドローン数 $N$ と最大高度 $K$ を $(N, K) = (2, 2), (3, 3)$ と変化させて検証を行った．

\subsubsection{シナリオ8: Kiva System（KS）}

本シナリオは，物流倉庫における商品搬送システムをモデル化した問題である~\cite{KivaSystemScenario}．
システムは $N$ 台の搬送ロボットと複数の可動式棚，および出荷や補充を行う作業ステーションから構成される．
各ロボットは棚の搬送や空箱の補充といった異なる役割を担い，ステーション内や通路における衝突を回避しながら協調してタスクを遂行する必要がある．
本実験では，ロボット数 $N$ を $N = 2, 3$ と変化させて検証を行った．

\section{各シナリオにおける実験結果と考察}

本節では，前節で定義した8つのベンチマークシナリオ，計27ケースに対する評価実験の結果を提示し，各シナリオの構造的特性と探索挙動の関連について個別の考察を行う．
その後，\aref{sec:discussion}において，全シナリオを通した総合的な傾向を分析し，本研究で設定したリサーチクエスチョンに対する検証を行う．

各シナリオの評価においては，提案手法および比較手法の性能を示す表と，抽出されたPre-Markingアクション（PMA）の統計を示す表の2種類を提示する．

第一の表は，各アルゴリズムの探索効率および計算コストを定量的に比較したものである．
比較対象となる手法は，幅優先探索（BFS），履歴を用いない静的Ready Abstraction（SRA），従来手法であるReady Abstraction（RA），および本研究の提案手法であるLandmark Ready Abstraction（LRA）の4手法である．
評価指標として，探索された状態総数 $|S|$，最大ヒープ使用量 $M$ [MiB]，全体の合成時間 $T$ [ms]，およびヒューリスティック関数の計算に要した時間 $T_\mathit{eval}$ [ms] を用いる．
各指標の数値の右側に併記された括弧内の値は，提案手法LRAの値を基準（$1.0$）として正規化した相対比を表す．
本実験における評価指標はいずれも値が小さいほど性能が高いことを意味するため，この相対比が$1.0$を超える場合，提案手法が比較対象に対して優位性を有することを示す．
なお，制限時間（12時間）以内に解が求まらなかった場合は T.O. と表記する．

第二の表は，提案手法におけるPMAの構成統計を示したものである．
システムに含まれる総アクション数 $|A|$ に対し，抽出されたPrimary PMAの数 $|A^\mathit{PP}|$，およびSecondary PMAの数 $|A^\mathit{SP}|$ を示す．
また，総アクション数に対する全PMA（PrimaryおよびSecondaryの和）の占有率を $\rho$ [\%] として記載する．
この指標 $\rho$ は，システム全体のアクション空間に対する中間目標の占有率を表しており，LRAが探索の指針として利用可能な構造的情報の密度を示唆する．

以下，各シナリオにおける詳細な結果を示す．

\subsection{シナリオ1: Air Traffic（AT）}

本シナリオは，航空機の着陸管制におけるリソース競合を扱ったモデルである．
実験結果を\aref{tab:result_at}に，PMAの構成統計を\aref{tab:pma_at}に示す．

\begin{table}
  \caption{Air Trafficシナリオの実験結果}
  \label{tab:result_at}
  \centering
  \begin{rtblr}{cell{2,6,10}{1} = {r=4}{c}}
    \toprule
    \resultheadernk
    \midrule
    $(4, 5)$
     & BFS & 6025  & ( & 12.8 & ) & 995.75  & ( & 8.5 & ) & 21311   & ( & 146.0  & ) & \NA   &   &      &   \\
     & RA  & 485   & ( & 1.0  & ) & 116.61  & ( & 1.0 & ) & 518     & ( & 3.5    & ) & 383   & ( & 3.4  & ) \\
     & SRA & 472   & ( & 1.0  & ) & 121.36  & ( & 1.0 & ) & 140     & ( & 1.0    & ) & 106   & ( & 0.9  & ) \\
     & LRA & 472   & ( & 1.0  & ) & 116.60  & ( & 1.0 & ) & 146     & ( & 1.0    & ) & 114   & ( & 1.0  & ) \\
    \cmidrule[lr]{1-Z}
    $(5, 5)$
     & BFS & 41833 & ( & 13.6 & ) & 1474.56 & ( & 2.1 & ) & 2194145 & ( & 2119.9 & ) & \NA   &   &      &   \\
     & RA  & 2743  & ( & 0.9  & ) & 693.01  & ( & 1.0 & ) & 6792    & ( & 6.6    & ) & 3022  & ( & 4.5  & ) \\
     & SRA & 3078  & ( & 1.0  & ) & 693.05  & ( & 1.0 & ) & 1007    & ( & 1.0    & ) & 624   & ( & 0.9  & ) \\
     & LRA & 3078  & ( & 1.0  & ) & 693.01  & ( & 1.0 & ) & 1035    & ( & 1.0    & ) & 665   & ( & 1.0  & ) \\
    \cmidrule[lr]{1-Z}
    $(5, 10)$
     & BFS & \NA   &   &      &   & \NA     &   &     &   & \TO     &   &        &   & \NA   &   &      &   \\
     & RA  & 2756  & ( & 2.4  & ) & 711.16  & ( & 1.2 & ) & 15885   & ( & 15.8   & ) & 11931 & ( & 13.8 & ) \\
     & SRA & 1134  & ( & 1.0  & ) & 695.22  & ( & 1.2 & ) & 1045    & ( & 1.0    & ) & 865   & ( & 1.0  & ) \\
     & LRA & 1134  & ( & 1.0  & ) & 583.15  & ( & 1.0 & ) & 1008    & ( & 1.0    & ) & 864   & ( & 1.0  & ) \\
    \bottomrule
  \end{rtblr}
\end{table}

\begin{table}
  \caption{Air TrafficシナリオにおけるPMAの構成}
  \label{tab:pma_at}
  \centering
  \begin{ptblr}{}
    \toprule
    \pmaheadernk
    \midrule
    $(4, 5)$  & 37 & 0 & 0 & 0.0 \\
    $(5, 5)$  & 46 & 0 & 0 & 0.0 \\
    $(5, 10)$ & 71 & 0 & 0 & 0.0 \\
    \bottomrule
  \end{ptblr}
\end{table}

\subsubsection{考察}

まずPMAの構成に着目すると，本シナリオにおいては全てのケースでPMAが抽出されず，$\rho$は$0.0\%$となった．
これは本問題が特定のイベント順序を強制する構造を持たないことに起因する．
このためLRAの挙動はSRAと完全に一致しており，PMAによる追加の誘導効果は発現していない．

次にRAの挙動に着目する．
探索履歴を利用して誘導を行うRAは，ケース$(5, 5)$においてLRAよりも少ない状態数で解を発見している．
しかし，ケース$(5, 10)$では逆に探索状態数が2倍以上に増大しており，探索履歴への誘導が必ずしも最短経路を指し示すとは限らず，状況によっては局所解への過度な停留を招く不安定さを示唆している．

さらに計算時間に関して顕著な差が確認できる．
RAの合成時間 $T$ はLRAと比較して大幅に長く，特にケース$(5, 10)$では約16倍の時間を要している．
この主因はヒューリスティック関数の評価時間 $T_\mathit{eval}$ の増大にある．
RAは毎ステップ全てのコンポーネントに対して，到達済みMarked状態および任意のMarked状態への距離推定を網羅的に実行する．
対してLRAおよびSRAは，本シナリオにおいて評価対象を最終目標であるMarkingアクションのみに限定して距離推定を行っている．
これにより，1ステップあたりの計算コストを低く抑えつつ，RAと同等以上の探索効率を実現している．

\subsection{シナリオ2: Bidding Workflow（BW）}

本シナリオは，企業内における入札案件の承認ワークフローをモデル化したシナリオである．
実験結果を\aref{tab:result_bw}に，PMAの構成統計を\aref{tab:pma_bw}に示す．

\begin{table}
  \caption{Bidding Workflowシナリオの実験結果}
  \label{tab:result_bw}
  \centering
  \begin{rtblr}{cell{2,6,10, 14}{1} = {r=4}{c}}
    \toprule
    \resultheadernk
    \midrule
    $(4, 4)$
     & BFS & 7538  & ( & 123.6 & ) & 1095.68 & ( & 31.5 & ) & 125731   & ( & 6617.4    & ) & \NA &   &     &   \\
     & RA  & 61    & ( & 1.0   & ) & 34.76   & ( & 1.0  & ) & 32       & ( & 1.7       & ) & 16  & ( & 2.0 & ) \\
     & SRA & 61    & ( & 1.0   & ) & 34.82   & ( & 1.0  & ) & 17       & ( & 0.9       & ) & 9   & ( & 1.1 & ) \\
     & LRA & 61    & ( & 1.0   & ) & 34.76   & ( & 1.0  & ) & 19       & ( & 1.0       & ) & 8   & ( & 1.0 & ) \\
    \cmidrule[lr]{1-Z}
    $(4, 5)$
     & BFS & 15135 & ( & 201.8 & ) & 1259.52 & ( & 36.2 & ) & 863799   & ( & 35991.6   & ) & \NA &   &     &   \\
     & RA  & 75    & ( & 1.0   & ) & 34.79   & ( & 1.0  & ) & 32       & ( & 1.3       & ) & 22  & ( & 1.5 & ) \\
     & SRA & 75    & ( & 1.0   & ) & 34.78   & ( & 1.0  & ) & 20       & ( & 0.8       & ) & 8   & ( & 0.5 & ) \\
     & LRA & 75    & ( & 1.0   & ) & 34.84   & ( & 1.0  & ) & 24       & ( & 1.0       & ) & 15  & ( & 1.0 & ) \\
    \cmidrule[lr]{1-Z}
    $(5, 4)$
     & BFS & 62042 & ( & 805.7 & ) & 2959.36 & ( & 85.0 & ) & 31230321 & ( & 1419560.0 & ) & \NA &   &     &   \\
     & RA  & 77    & ( & 1.0   & ) & 34.86   & ( & 1.0  & ) & 33       & ( & 1.5       & ) & 18  & ( & 1.4 & ) \\
     & SRA & 77    & ( & 1.0   & ) & 34.81   & ( & 1.0  & ) & 17       & ( & 0.8       & ) & 9   & ( & 0.7 & ) \\
     & LRA & 77    & ( & 1.0   & ) & 34.80   & ( & 1.0  & ) & 22       & ( & 1.0       & ) & 13  & ( & 1.0 & ) \\
    \cmidrule[lr]{1-Z}
    $(5, 5)$
     & BFS & \NA   &   &       &   & \NA     &   &      &   & \TO      &   &           &   & \NA &   &     &   \\
     & RA  & 95    & ( & 1.0   & ) & 50.87   & ( & 1.5  & ) & 40       & ( & 1.5       & ) & 25  & ( & 1.8 & ) \\
     & SRA & 95    & ( & 1.0   & ) & 34.83   & ( & 1.0  & ) & 24       & ( & 0.9       & ) & 9   & ( & 0.6 & ) \\
     & LRA & 95    & ( & 1.0   & ) & 34.87   & ( & 1.0  & ) & 26       & ( & 1.0       & ) & 14  & ( & 1.0 & ) \\
    \bottomrule
  \end{rtblr}
\end{table}

\begin{table}
  \caption{Bidding WorkflowシナリオにおけるPMAの構成}
  \label{tab:pma_bw}
  \centering
  \begin{ptblr}{}
    \toprule
    \pmaheadernk
    \midrule
    $(4, 4)$ & 27 & 1 & 0 & 3.7 \\
    $(4, 5)$ & 31 & 1 & 0 & 3.2 \\
    $(5, 4)$ & 33 & 1 & 0 & 3.0 \\
    $(5, 5)$ & 38 & 1 & 0 & 2.6 \\
    \bottomrule
  \end{ptblr}
\end{table}

\subsubsection{考察}

本シナリオにおける探索状態数 $|S|$ は，RA，SRA，およびLRAの3手法において完全に一致する結果となった．
\aref{tab:pma_bw}に示すように，本シナリオで抽出されたPMAは極めて少数であり，Secondary PMAに至っては存在しない．
これは，システム内の依存関係の多くが局所的であり，大域的なボトルネックとなるアクションがほとんど存在しないことを意味する．
このため，LRAのヒューリスティック関数は実質的にSRAと同等の距離推定を行うこととなり，結果として同一の探索経路を選択したと考えられる．

一方，計算時間に関しては手法間の構造的な差異が確認できる．
まず，網羅的な評価を行うRAは，他のヒューリスティック手法と比較して $T$ および $T_\mathit{eval}$ が最も大きい傾向にある．
次に，同じ経路を辿ったSRAとLRAを比較すると，LRAの方がわずかに時間を要している．
例えばケース$(5, 5)$において，合成時間 $T$ はSRAの24msに対してLRAは26ms，評価時間 $T_\mathit{eval}$ はSRAの9msに対してLRAは14msとなっている．
この差異が生じる要因は大きく分けて二つ存在する．
第一の要因は，探索開始前に実行されるPMA抽出処理のオーバーヘッドである．
第二の要因は，各探索ステップにおける計算負荷の違いである．
SRAが距離推定の対象を最終目標のみとするのに対し，LRAは抽出されたPMA（本ケースではPrimary PMA 1つ）についても距離計算を行い，その最大値を評価値として採用する．
本シナリオではPMAによる探索空間削減の恩恵が得られなかったため，これら計算コストの増加分が純粋なオーバーヘッドとして顕在化した形となる．

\subsection{シナリオ3: Cat and Mouse（CM）}

本シナリオは，直列に接続されたエリア上での追跡者と逃走者の移動制御をモデル化したシナリオである．
実験結果を\aref{tab:result_cm}に，PMAの構成統計を\aref{tab:pma_cm}に示す．

\begin{table}
  \caption{Cat and Mouseシナリオの実験結果}
  \label{tab:result_cm}
  \centering
  \begin{rtblr}{cell{2,6,10,14,18}{1} = {r=4}{c}}
    \toprule
    \resultheadernk
    \midrule
    $(2, 3)$
     & BFS & 7972   & ( & 17.3 & ) & 867.96  & ( & 7.5 & ) & 7096     & ( & 33.6  & ) & \NA   &   &      &   \\
     & RA  & 2113   & ( & 4.6  & ) & 639.65  & ( & 5.5 & ) & 1568     & ( & 7.4   & ) & 414   & ( & 8.6  & ) \\
     & SRA & 1440   & ( & 3.1  & ) & 452.01  & ( & 3.9 & ) & 594      & ( & 2.8   & ) & 93    & ( & 1.9  & ) \\
     & LRA & 460    & ( & 1.0  & ) & 115.97  & ( & 1.0 & ) & 211      & ( & 1.0   & ) & 48    & ( & 1.0  & ) \\
    \cmidrule[lr]{1-Z}
    $(2, 5)$
     & BFS & 67656  & ( & 10.3 & ) & 1280.00 & ( & 1.4 & ) & 1307166  & ( & 67.8  & ) & \NA   &   &      &   \\
     & RA  & 11284  & ( & 1.7  & ) & 759.39  & ( & 0.8 & ) & 116454   & ( & 6.0   & ) & 3017  & ( & 2.9  & ) \\
     & SRA & 11896  & ( & 1.8  & ) & 927.87  & ( & 1.0 & ) & 164845   & ( & 8.5   & ) & 748   & ( & 0.7  & ) \\
     & LRA & 6571   & ( & 1.0  & ) & 931.73  & ( & 1.0 & ) & 19285    & ( & 1.0   & ) & 1035  & ( & 1.0  & ) \\
    \cmidrule[lr]{1-Z}
    $(3, 3)$
     & BFS & 270861 & ( & 57.3 & ) & 2621.44 & ( & 2.7 & ) & 10909788 & ( & 323.5 & ) & \NA   &   &      &   \\
     & RA  & 36083  & ( & 7.6  & ) & 1105.92 & ( & 1.2 & ) & 1050811  & ( & 31.2  & ) & 11170 & ( & 16.3 & ) \\
     & SRA & 38552  & ( & 8.2  & ) & 1341.44 & ( & 1.4 & ) & 1668333  & ( & 49.5  & ) & 2640  & ( & 3.8  & ) \\
     & LRA & 4729   & ( & 1.0  & ) & 960.61  & ( & 1.0 & ) & 33728    & ( & 1.0   & ) & 687   & ( & 1.0  & ) \\
    \cmidrule[lr]{1-Z}
    $(3, 4)$
     & BFS & \NA    &   &      &   & \NA     &   &     &   & \TO      &   &       &   & \NA   &   &      &   \\
     & RA  & \NA    &   &      &   & \NA     &   &     &   & \TO      &   &       &   & \NA   &   &      &   \\
     & SRA & \NA    &   &      &   & \NA     &   &     &   & \TO      &   &       &   & \NA   &   &      &   \\
     & LRA & 10309  & ( & 1.0  & ) & 738.85  & ( & 1.0 & ) & 207353   & ( & 1.0   & ) & 1473  & ( & 1.0  & ) \\
    \cmidrule[lr]{1-Z}
    $(4, 2)$
     & BFS & 402709 & ( & 29.0 & ) & 4239.36 & ( & 3.9 & ) & 35043207 & ( & 60.8  & ) & \NA   &   &      &   \\
     & RA  & 59362  & ( & 4.3  & ) & 1740.80 & ( & 1.6 & ) & 1828240  & ( & 3.2   & ) & 18905 & ( & 8.5  & ) \\
     & SRA & 19248  & ( & 1.4  & ) & 1792.00 & ( & 1.6 & ) & 609075   & ( & 1.0   & ) & 1493  & ( & 0.7  & ) \\
     & LRA & 13901  & ( & 1.0  & ) & 1095.68 & ( & 1.0 & ) & 576107   & ( & 1.0   & ) & 2219  & ( & 1.0  & ) \\
    \bottomrule
  \end{rtblr}
\end{table}

\begin{table}
  \caption{Cat and MouseシナリオにおけるPMAの構成}
  \label{tab:pma_cm}
  \centering
  \begin{ptblr}{}
    \toprule
    \pmaheadernk
    \midrule
    $(2, 3)$ & 31 & 8  & 0 & 25.8 \\
    $(2, 5)$ & 47 & 12 & 0 & 25.5 \\
    $(3, 3)$ & 45 & 11 & 0 & 24.4 \\
    $(3, 4)$ & 57 & 14 & 0 & 24.6 \\
    $(4, 2)$ & 43 & 10 & 0 & 23.2 \\
    \bottomrule
  \end{ptblr}
\end{table}

\subsubsection{考察}

本シナリオにおいて，LRAは他手法に対し圧倒的な優位性を示している．
\aref{tab:pma_cm}に示す通り，本シナリオにおけるPMAの占有率 $\rho$ は23\%から25\%と極めて高い．
これは，各コンポーネントにて目標へ到達するために通過しなければならない経路が構造的に決まっていることを反映している．
LRAはこの豊富なPMAを中間目標として利用することで探索空間を効率的に削減しており，特に難易度の高いケース$(3, 4)$において，他の全ての手法がタイムアウトする中で唯一解を算出することに成功している．

また，RAとSRAの比較から，探索履歴を利用するRAの不安定さが確認できる．
ケース$(2, 5)$および$(3, 3)$においてはRAがSRAよりも少ない探索状態数を示しているが，逆にケース$(2, 3)$および$(4, 2)$においてはSRAの方が少ない状態数で解に到達している．
この優劣の逆転現象は，到達済みMarked状態への誘導が必ずしも未探索領域における最適経路と一致しないことを示唆している．
対照的に，LRAはRAおよびSRAよりも常に少ない状態数で安定した性能を発揮しており，PMAに基づく構造的な誘導が履歴に基づく発見的な誘導よりも堅牢であることを裏付けている．

\subsection{シナリオ4: Dining Philosophers（DP）}

本シナリオは，円卓に配置された複数のプロセスが共有リソース（フォーク）を排他的に利用しながら食事を行う，並行システムの古典的なモデルである．
実験結果を\aref{tab:result_dp}に，PMAの構成統計を\aref{tab:pma_dp}に示す．

\begin{table}
  \caption{Dining Philosophersシナリオの実験結果}
  \label{tab:result_dp}
  \centering
  \begin{rtblr}{cell{2,6,10,14}{1} = {r=4}{c}}
    \toprule
    \resultheadernk
    \midrule
    $(3, 3)$
     & BFS & 2288  & ( & 14.0  & ) & 690.77  & ( & 10.3 & ) & 1358    & ( & 29.5    & ) & \NA  &   &     &   \\
     & RA  & 336   & ( & 2.0   & ) & 98.79   & ( & 1.5  & ) & 78      & ( & 1.7     & ) & 25   & ( & 0.9 & ) \\
     & SRA & 1912  & ( & 11.7  & ) & 546.85  & ( & 8.2  & ) & 685     & ( & 14.9    & ) & 21   & ( & 0.8 & ) \\
     & LRA & 164   & ( & 1.0   & ) & 66.79   & ( & 1.0  & ) & 46      & ( & 1.0     & ) & 28   & ( & 1.0 & ) \\
    \cmidrule[lr]{1-Z}
    $(4, 4)$
     & BFS & 47787 & ( & 92.6  & ) & 1648.64 & ( & 19.3 & ) & 1822454 & ( & 9394.1  & ) & \NA  &   &     &   \\
     & RA  & 1530  & ( & 3.0   & ) & 683.47  & ( & 8.0  & ) & 1606    & ( & 8.3     & ) & 98   & ( & 1.3 & ) \\
     & SRA & 6014  & ( & 11.7  & ) & 1064.96 & ( & 12.5 & ) & 9170    & ( & 47.3    & ) & 43   & ( & 0.6 & ) \\
     & LRA & 516   & ( & 1.0   & ) & 85.28   & ( & 1.0  & ) & 194     & ( & 1.0     & ) & 78   & ( & 1.0 & ) \\
    \cmidrule[lr]{1-Z}
    $(4 ,5)$
     & BFS & 73471 & ( & 122.2 & ) & 1976.32 & ( & 20.0 & ) & 3950285 & ( & 19555.9 & ) & \NA  &   &     &   \\
     & RA  & 1876  & ( & 3.1   & ) & 690.87  & ( & 7.0  & ) & 2490    & ( & 12.3    & ) & 163  & ( & 1.8 & ) \\
     & SRA & 44687 & ( & 74.4  & ) & 1443.84 & ( & 14.6 & ) & 1234959 & ( & 6113.7  & ) & 839  & ( & 9.4 & ) \\
     & LRA & 601   & ( & 1.0   & ) & 98.89   & ( & 1.0  & ) & 202     & ( & 1.0     & ) & 89   & ( & 1.0 & ) \\
    \cmidrule[lr]{1-Z}
    $(5, 5)$
     & BFS & \NA   &   &       &   & \NA     &   &      &   & \TO     &   &         &   & \NA  &   &     &   \\
     & RA  & 18651 & ( & 10.5  & ) & 1085.44 & ( & 1.6  & ) & 829989  & ( & 383.9   & ) & 2102 & ( & 7.6 & ) \\
     & SRA & 86627 & ( & 48.8  & ) & 3102.72 & ( & 4.5  & ) & 4362290 & ( & 2017.7  & ) & 1292 & ( & 4.6 & ) \\
     & LRA & 1775  & ( & 1.0   & ) & 690.99  & ( & 1.0  & ) & 2162    & ( & 1.0     & ) & 278  & ( & 1.0 & ) \\
    \bottomrule
  \end{rtblr}
\end{table}

\begin{table}
  \caption{Dining PhilosophersシナリオにおけるPMAの構成}
  \label{tab:pma_dp}
  \centering
  \begin{ptblr}{}
    \toprule
    \pmaheadernk
    \midrule
    $(3, 3)$ & 22 & 15 & 0 & 68.1 \\
    $(4, 4)$ & 29 & 20 & 0 & 69.0 \\
    $(4, 5)$ & 29 & 20 & 0 & 69.0 \\
    $(5, 5)$ & 36 & 25 & 0 & 69.4 \\
    \bottomrule
  \end{ptblr}
\end{table}

\subsubsection{考察}

本シナリオにおいても，LRAは他手法と比較して最も優れた探索効率を示している．
\aref{tab:pma_dp}より，本シナリオにおけるPMAの占有率 $\rho$ は68\%から69\%と極めて高い値を示している．
これは，食事を行うために必要な一連の手順（フォークの取得準備や食事動作など）が厳密に定義されており，各コンポーネントの動作に対する構造的な制約が強いことを意味する．
LRAはこの豊富な構造的情報を活用することで，デッドロックを回避しつつ効率的に解を発見している．

また，本シナリオではRAがSRAと比較して良好な性能を示している点に注目したい．
前述のCat and Mouseシナリオ等とは異なり，ここでは探索履歴（到達済みMarked状態）への誘導が有効に機能し，探索空間の削減に寄与している．
例えばケース$(4, 5)$において，SRAの探索状態数が44,687であるのに対し，RAは1,876と約1/24に抑えられている．
これは，PMAのような構造的解析とは異なるアプローチである履歴に基づくヒューリスティックも，問題の性質によっては有効な指針となり得ることを示唆している．

しかしながら，LRAはそのRAと比較してもさらに少ない探索状態数（ケース$(4, 5)$で601）を達成している．
これは，本シナリオにおいて，探索履歴に基づく動的な誘導よりも，PMAに基づく静的な構造解析の方が，より直接的かつ強力に目標への経路を指し示していることを表している．

\subsection{シナリオ5: Travel Agency（TA）}

本シナリオは，旅行代理店における航空券や宿泊予約といったWebサービスの連携をモデル化したシナリオであり，トランザクションの一貫性を保つための調停が求められる．
実験結果を\aref{tab:result_ta}に，PMAの構成統計を\aref{tab:pma_ta}に示す．

\begin{table}
  \caption{Travel Agencyシナリオの実験結果}
  \label{tab:result_ta}
  \centering
  \begin{rtblr}{cell{2,6,10,14}{1} = {r=4}{c}}
    \toprule
    \resultheadernk
    \midrule
    $(3, 3)$
     & BFS & 1161  & ( & 2.6 & ) & 643.15   & ( & 5.6  & ) & 1159     & ( & 6.9   & ) & \NA  &   &     &   \\
     & RA  & 472   & ( & 1.0 & ) & 115.16   & ( & 1.0  & ) & 266      & ( & 1.6   & ) & 164  & ( & 4.7 & ) \\
     & SRA & 446   & ( & 1.0 & ) & 115.15   & ( & 1.0  & ) & 162      & ( & 1.0   & ) & 22   & ( & 0.6 & ) \\
     & LRA & 446   & ( & 1.0 & ) & 115.15   & ( & 1.0  & ) & 169      & ( & 1.0   & ) & 35   & ( & 1.0 & ) \\
    \cmidrule[lr]{1-Z}
    $(4, 4)$
     & BFS & 9702  & ( & 3.9 & ) & 1044.48  & ( & 1.2  & ) & 188135   & ( & 42.7  & ) & \NA  &   &     &   \\
     & RA  & 2727  & ( & 1.1 & ) & 851.46   & ( & 1.0  & ) & 5058     & ( & 1.1   & ) & 745  & ( & 3.9 & ) \\
     & SRA & 2496  & ( & 1.0 & ) & 851.41   & ( & 1.0  & ) & 4337     & ( & 1.0   & ) & 159  & ( & 0.8 & ) \\
     & LRA & 2496  & ( & 1.0 & ) & 851.46   & ( & 1.0  & ) & 4403     & ( & 1.0   & ) & 191  & ( & 1.0 & ) \\
    \cmidrule[lr]{1-Z}
    $(4, 5)$
     & BFS & 10781 & ( & 4.2 & ) & 1341.44  & ( & 1.6  & ) & 231921   & ( & 48.6  & ) & \NA  &   &     &   \\
     & RA  & 2751  & ( & 1.1 & ) & 867.44   & ( & 1.0  & ) & 5269     & ( & 1.1   & ) & 789  & ( & 4.0 & ) \\
     & SRA & 2549  & ( & 1.0 & ) & 851.46   & ( & 1.0  & ) & 4772     & ( & 1.0   & ) & 148  & ( & 0.8 & ) \\
     & LRA & 2549  & ( & 1.0 & ) & 851.43   & ( & 1.0  & ) & 4775     & ( & 1.0   & ) & 197  & ( & 1.0 & ) \\
    \cmidrule[lr]{1-Z}
    $(5, 5)$
     & BFS & 79964 & ( & 5.5 & ) & 11100.16 & ( & 12.0 & ) & 36380104 & ( & 117.8 & ) & \NA  &   &     &   \\
     & RA  & 15953 & ( & 1.1 & ) & 971.02   & ( & 1.1  & ) & 236716   & ( & 0.8   & ) & 7042 & ( & 5.9 & ) \\
     & SRA & 14538 & ( & 1.0 & ) & 943.48   & ( & 1.0  & ) & 303399   & ( & 1.0   & ) & 1175 & ( & 1.0 & ) \\
     & LRA & 14538 & ( & 1.0 & ) & 923.56   & ( & 1.0  & ) & 308801   & ( & 1.0   & ) & 1193 & ( & 1.0 & ) \\
    \bottomrule
  \end{rtblr}
\end{table}

\begin{table}
  \caption{Travel AgencyシナリオにおけるPMAの構成}
  \label{tab:pma_ta}
  \centering
  \begin{ptblr}{}
    \toprule
    \pmaheadernk
    \midrule
    $(3, 3)$ & 48 & 1 & 0 & 2.1 \\
    $(4, 4)$ & 67 & 1 & 0 & 1.5 \\
    $(4, 5)$ & 71 & 1 & 0 & 1.4 \\
    $(5, 5)$ & 88 & 1 & 0 & 1.1 \\
    \bottomrule
  \end{ptblr}
\end{table}

本シナリオにおけるPMAの占有率 $\rho$ は\aref{tab:pma_ta}に示す通り1\%から2\%と低く，Bidding Workflowと同様に構造的なボトルネックが希薄である．
そのため，LRAとSRAの探索状態数 $|S|$ は一致しており，PMAによる探索空間の削減効果は限定的であった．

一方で，RAの挙動に関して特異な傾向が確認された．
最大規模のケース$(5, 5)$において，RAはLRAと比較して探索状態数が増加し，かつヒューリスティック関数の評価時間 $T_\mathit{eval}$ も約5.9倍を要している．
それにもかかわらず，全体の合成時間 $T$ は約0.8倍に短縮された．
合成時間は主として探索処理時間 $T_\mathit{search}$ と評価時間 $T_\mathit{eval}$ の和で構成されるため，この結果はRAにおいてDCSアルゴリズム自体の処理時間 $T_\mathit{search}$ が大幅に短縮されたことを意味する．

大規模な問題において探索状態数が増大した場合，DCSのボトルネックはヒューリスティック計算から，グラフ展開後の勝利条件伝播や閉路検出といったアルゴリズム内部の処理へと移行する．
本結果は，RAによる到達済みMarked状態への誘導が，必ずしも最小状態数での解到達を保証しないものの，DCSのアルゴリズムにとって処理負荷の低いグラフ構造を形成した可能性を示唆している．
具体的には，勝利閉路の早期発見や伝播処理の収束性が向上したと考えられる．
この知見は，PMAによる構造的誘導とRAによる履歴的誘導を統合する意義，およびDCSアルゴリズム自体の最適化の必要性を裏付けるものであり，今後の課題として取り組むべき方向性を示している．

\subsection{シナリオ6: Transfer Line（TL）}

本シナリオは，直列に接続された複数の加工機とバッファから構成される製造ラインの制御をモデル化したシナリオである．
実験結果を\aref{tab:result_tl}に，PMAの構成統計を\aref{tab:pma_tl}に示す．

\begin{table}
  \caption{Transfer Lineシナリオの実験結果}
  \label{tab:result_tl}
  \centering
  \begin{rtblr}{cell{2,6,10}{1} = {r=4}{c}}
    \toprule
    \resultheadernk
    \midrule
    $(10, 10)$
     & BFS &     & ( &     & ) &         & ( &     & ) &      & ( &     & ) & \NA  &   &       &   \\
     & RA  & 68  & ( & 1.0 & ) & 256.14  & ( & 1.9 & ) & 567  & ( & 3.7 & ) & 438  & ( & 36.5  & ) \\
     & SRA & 68  & ( & 1.0 & ) & 118.05  & ( & 0.9 & ) & 95   & ( & 0.6 & ) & 8    & ( & 0.7   & ) \\
     & LRA & 68  & ( & 1.0 & ) & 134.04  & ( & 1.0 & ) & 153  & ( & 1.0 & ) & 12   & ( & 1.0   & ) \\
    \cmidrule[lr]{1-Z}
    $(15, 15)$
     & BFS &     & ( &     & ) &         & ( &     & ) &      & ( &     & ) & \NA  &   &       &   \\
     & RA  & 98  & ( & 1.0 & ) & 851.97  & ( & 1.4 & ) & 2474 & ( & 6.5 & ) & 2063 & ( & 62.5  & ) \\
     & SRA & 98  & ( & 1.0 & ) & 585.85  & ( & 1.0 & ) & 358  & ( & 0.9 & ) & 18   & ( & 0.5   & ) \\
     & LRA & 98  & ( & 1.0 & ) & 601.75  & ( & 1.0 & ) & 378  & ( & 1.0 & ) & 33   & ( & 1.0   & ) \\
    \cmidrule[lr]{1-Z}
    $(20, 20)$
     & BFS &     & ( &     & ) &         & ( &     & ) &      & ( &     & ) & \NA  &   &       &   \\
     & RA  & 128 & ( & 1.0 & ) & 2099.20 & ( & 2.9 & ) & 8252 & ( & 7.4 & ) & 7316 & ( & 124.0 & ) \\
     & SRA & 128 & ( & 1.0 & ) & 702.81  & ( & 1.0 & ) & 1005 & ( & 0.9 & ) & 41   & ( & 0.7   & ) \\
     & LRA & 128 & ( & 1.0 & ) & 721.44  & ( & 1.0 & ) & 1121 & ( & 1.0 & ) & 59   & ( & 1.0   & ) \\
    \bottomrule
  \end{rtblr}
\end{table}

\begin{table}
  \caption{Transfer LineシナリオにおけるPMAの構成}
  \label{tab:pma_tl}
  \centering
  \begin{ptblr}{}
    \toprule
    \pmaheadernk
    \midrule
    $(10, 10)$ & 244 & 1 & 0 & 0.4 \\
    $(15, 15)$ & 514 & 1 & 0 & 0.2 \\
    $(20, 20)$ & 844 & 1 & 0 & 0.1 \\
    \bottomrule
  \end{ptblr}
\end{table}

本シナリオにおけるPMAの占有率 $\rho$ は，\aref{tab:pma_tl}に示す通り0.1\%から0.4\%と極めて低く，Bidding Workflowと同様に構造的なボトルネックがほとんど存在しない．
このため，LRA，SRA，およびRAの探索状態数 $|S|$ は全ケースにおいて完全に一致しており，各手法が同一の探索経路を選択したことがわかる．

一方で，計算コストに関しては手法間で顕著な差異が生じている．
特にRAは，コンポーネント数の増加に伴い，ヒューリスティック関数の評価時間 $T_\mathit{eval}$ が急激に増大している．
ケース$(20, 20)$においては，LRAの59msに対しRAは7,316msと，約124倍の時間を要している．
これは，本シナリオが多数のコンポーネント（最大20台の加工機とバッファなど）で構成されており，RAがその全てに対して毎ステップ網羅的に距離推定を行う計算負荷が支配的になったためである．

また，SRAとLRAを比較すると，LRAの方がわずかに合成時間 $T$ および評価時間 $T_\mathit{eval}$ が大きい傾向にある．
探索経路が同一であることから，この時間差はLRA特有の処理コストに起因する．
具体的には，探索開始前に行われるPMA抽出処理のオーバーヘッド，および各ステップにおいて抽出されたPMA（Primary PMA 1つ）への距離推定を行う追加の計算負荷が反映された結果である．
% なお，BFSはいずれのケースにおいても制限時間内に解を算出できておらず，単純な探索では対処不可能な規模の問題であることが確認できる．

\subsection{シナリオ7: Drone Coordination（DC）}

本シナリオは，複数のドローンによる協調飛行とバッテリー残量などの資源管理をモデル化したシナリオである．
実験結果を\aref{tab:result_dc}に，PMAの構成統計を\aref{tab:pma_dc}に示す．

\begin{table}
  \caption{Drone Coordinationシナリオの実験結果}
  \label{tab:result_dc}
  \centering
  \begin{rtblr}{cell{2,6}{1} = {r=4}{c}}
    \toprule
    \resultheadernk
    \midrule
    $(2, 2)$
     & BFS & 7197   & ( & 24.6 & ) & 948.15  & ( & 8.2 & ) & 12574    & ( & 78.6  & ) & \NA    &   &      &   \\
     & RA  & 1166   & ( & 4.0  & ) & 628.36  & ( & 5.4 & ) & 1162     & ( & 7.3   & ) & 409    & ( & 4.4  & ) \\
     & SRA & 386    & ( & 1.3  & ) & 100.35  & ( & 0.9 & ) & 160      & ( & 1.0   & ) & 42     & ( & 0.5  & ) \\
     & LRA & 293    & ( & 1.0  & ) & 116.25  & ( & 1.0 & ) & 160      & ( & 1.0   & ) & 92     & ( & 1.0  & ) \\
    \cmidrule[lr]{1-Z}
    $(3, 3)$
     & BFS &        & ( &      & ) &         & ( &     & ) &          & ( &       & ) & \NA    &   &      &   \\
     & RA  & 159768 & ( & 18.9 & ) & 4751.36 & ( & 5.2 & ) & 32991134 & ( & 356.7 & ) & 264285 & ( & 45.0 & ) \\
     & SRA & 9181   & ( & 1.1  & ) & 740.04  & ( & 0.8 & ) & 120566   & ( & 1.3   & ) & 3237   & ( & 0.6  & ) \\
     & LRA & 8461   & ( & 1.0  & ) & 906.45  & ( & 1.0 & ) & 92500    & ( & 1.0   & ) & 5873   & ( & 1.0  & ) \\
    \bottomrule
  \end{rtblr}
\end{table}

\begin{table}
  \caption{Drone CoordinationシナリオにおけるPMAの構成}
  \label{tab:pma_dc}
  \centering
  \begin{ptblr}{}
    \toprule
    \pmaheadernk
    \midrule
    $(2, 2)$ & 38 & 2 & 9  & 29.0 \\
    $(3, 3)$ & 68 & 3 & 14 & 25.0 \\
    \bottomrule
  \end{ptblr}
\end{table}

本シナリオにおけるPMAの構成は，これまでのシナリオとは異なる特徴を示している．
\aref{tab:pma_dc}に示す通り，Primary PMAは少数に留まる一方で，Secondary PMAが多数抽出されており，結果として全体の占有率 $\rho$ は25\%から29\%と高い値となっている．
これは，最終目標となる同期アクション自体は少数であるものの，その前提条件として各コンポーネントが解決すべき準備動作が多層的な依存関係を持っていることを表している．
LRAはこのSecondary PMAによって細粒度な中間目標を設定することで，複雑な手順を要する状態遷移を効率的に制御し，最も少ない探索状態数で解に到達している．

一方，RAはSRAと比較しても性能が著しく悪化している．
特にケース$(3, 3)$において，RAの探索状態数はSRAの約17倍，LRAの約19倍に達しており，合成時間 $T$ に至ってはLRAの約350倍を要している．
SRAがLRAに近い良好な性能を示していることから，RAの敗因は探索履歴の利用にあることが明白である．
本シナリオのような空間的な配置問題において，過去に到達したMarked状態への距離を単純に最小化しようとする誘導は，各コンポーネント間の競合やデッドロック状態へ探索を引き込む要因となり，かえって探索効率を低下させたと考えられる．
本結果は，不適切なヒューリスティック情報が探索に悪影響を及ぼす事例であり，構造解析に基づくLRAの堅牢性を逆説的に支持するものである．

\subsection{シナリオ8: Kiva System（KS）}

本シナリオは，物流倉庫における自動搬送システムをモデル化したシナリオである．
実験結果を\aref{tab:result_ks}に，PMAの構成統計を\aref{tab:pma_ks}に示す．

\begin{table}
  \caption{Kiva Systemシナリオの実験結果}
  \label{tab:result_ks}
  \centering
  \begin{rtblr}{cell{2,6}{1} = {r=4}{c}}
    \toprule
    \resultheadern
    \midrule
    $2$
     & BFS & 93707  & ( & 94.2 & ) & 1587.20 & ( & 2.9 & ) & 847124  & ( & 1473.3 & ) & \NA    &   &     &   \\
     & RA  & 376    & ( & 0.4  & ) & 638.74  & ( & 1.2 & ) & 1387    & ( & 2.4    & ) & 1337   & ( & 3.0 & ) \\
     & SRA & 2408   & ( & 2.4  & ) & 702.80  & ( & 1.3 & ) & 1018    & ( & 1.8    & ) & 860    & ( & 1.9 & ) \\
     & LRA & 995    & ( & 1.0  & ) & 542.83  & ( & 1.0 & ) & 575     & ( & 1.0    & ) & 445    & ( & 1.0 & ) \\
    \cmidrule[lr]{1-Z}
    $3$
     & BFS & \NA    &   &      &   & \NA     &   &     &   & \TO     &   &        &   & \NA    &   &     &   \\
     & RA  & 6846   & ( & 0.1  & ) & 745.49  & ( & 0.4 & ) & 28174   & ( & 0.1    & ) & 27029  & ( & 0.3 & ) \\
     & SRA & 189008 & ( & 1.3  & ) & 2222.08 & ( & 1.1 & ) & 4458564 & ( & 10.2   & ) & 106450 & ( & 1.2 & ) \\
     & LRA & 144547 & ( & 1.0  & ) & 2017.28 & ( & 1.0 & ) & 437201  & ( & 1.0    & ) & 90819  & ( & 1.0 & ) \\
    \bottomrule
  \end{rtblr}
\end{table}

\begin{table}
  \caption{Kiva SystemシナリオにおけるPMAの構成}
  \label{tab:pma_ks}
  \centering
  \begin{ptblr}{}
    \toprule
    \pmaheadern
    \midrule
    $2$ & 53 & 1 & 5 & 11.3 \\
    $3$ & 75 & 1 & 5 & 8.0  \\
    \bottomrule
  \end{ptblr}
\end{table}

\subsubsection{考察}

本シナリオにおける実験結果は，これまでのシナリオとは異なる傾向を示している．
探索状態数および合成時間において，従来手法であるRAが他手法に対し最も優れた性能を発揮した．
特にケース$3$において，RAの探索状態数はLRAの約1/20にまで抑制されており，圧倒的な効率化を実現している．

各手法の比較を行うと，SRAに対しLRAおよびRAの双方が探索状態数を削減していることが確認できる．
これは，PMAに基づく構造的な誘導と，探索履歴に基づく発見的な誘導の双方が，本問題の探索において有効な指針となっていることを意味する．
\aref{tab:pma_ks}に示す通り，本シナリオでは8\%から11\%程度のPMAが抽出されており，LRAはこれを利用することでSRAよりも効率的な探索を実現した．

しかしながら，本シナリオにおいてはLRA以上にRAによる探索履歴の利用が効果的であった．
先のDrone Coordinationシナリオでは探索履歴への誘導がデッドロックを招く要因となったが，本シナリオにおいては逆に，過去に成功した経路周辺を集中的に探索することが解の発見を早める結果となった．
この事実は，対象とする問題の構造や制約の性質によって，最適なヒューリスティックの指針が構造解析（PMA）と履歴利用（RA）の間で変化することを示唆している．
Dining Philosophersシナリオや本シナリオの結果は，これら異なる特性を持つ指標を統合することで，より汎用的かつ強力なヒューリスティックを構築できる可能性を強く支持するものである．

\section{提案手法の有効性に関する考察}
\label{sec:discussion}

本節では，前節で得られた実験結果に基づき，本研究で設定した3つのリサーチクエスチョン（RQ）に対する回答を示す．
さらに，実験結果の傾向から明らかになったPre-Markingアクション（PMA）の占有率と探索手法の適合性について議論する．

\subsection{探索効率の改善（RQ1）}

RQ1は，PMAを用いた距離推定が探索状態数を削減し，探索効率を改善するかという問いである．
実験結果より，Cat and Mouse（CM），Dining Philosophers（DP），Drone Coordination（DC）といったシナリオにおいて，提案手法であるLRAは従来手法（RA）および静的RA（SRA）と比較して，探索状態数を大幅に削減していることが確認された．

特に，CMシナリオのケース$(3, 4)$では，他手法がすべてタイムアウトする中でLRAのみが解を導出しており，これはPMAによる中間目標の設定が，複雑な同期を要する探索空間において強力な指針となることを示している．
RAは探索履歴（到達済みMarked状態）への誘導を行うため，DCシナリオのように過去の成功体験がデッドロックへの誘導となり得る問題構造においては，SRAよりも多くの状態を探索する非効率性を示した．
これに対し，LRAはシステム構造から抽出されたPMAを必須通過点として評価するため，探索履歴に依存せず，常に解決すべきボトルネックへ向かう安定した経路選択を実現している．

一方で，Kiva System（KS）シナリオのように，RAがLRAよりも少ない状態数で解を発見するケースも確認された．
これは，構造的な制約よりも，過去に発見された有効経路周辺を集中的に探索する戦略が功を奏する場合があることを示唆している．
しかし，その場合においてもLRAはSRAより少ない状態数で推移しており，PMAの導入による一定の探索空間削減効果は維持されている．
以上より，提案手法は同期構造が複雑な問題において，局所解への停留や不要なバックトラックを抑制し，探索効率を著しく改善すると結論付けられる．

\subsection{計算コストの削減（RQ2）}

RQ2は，提案手法がトータルの計算コストを低減できるかという問いである．
実験結果において，LRAは探索状態数が削減されたシナリオ（CM，DP，DC）において，合成時間および最大ヒープ使用量の双方を大幅に低減した．
これは，探索空間の縮小が探索処理自体の負荷軽減に直結した結果である．

特筆すべきは，Air Traffic（AT）やTransfer Line（TL）のように，PMAが抽出されずLRAとSRAの探索経路が一致したシナリオにおける挙動である．
これらのシナリオにおいて，RAはコンポーネント数の増加に伴いヒューリスティック関数の評価時間（$T_\mathit{eval}$）が急激に増大する傾向を示した．
RAは毎ステップ，全コンポーネントに対して網羅的に距離計算を行うため，システム規模に比例して計算負荷が増大する．
対してLRAは，評価対象を最終目標および現在解決すべきPMAのみに限定するため，コンポーネント数が増加しても1ステップあたりの計算コストを低く抑えることができる．
実際，TLシナリオのケース$(20, 20)$において，LRAはRAと比較して約100倍の高速化を実現している．

LRAは探索開始前にPMA抽出という静的解析のオーバーヘッドを伴うが，実験結果が示す通り，そのコストは探索全体の時間と比較して無視できるほど小さい．
したがって，提案手法は探索効率の向上と評価関数の軽量化の双方により，計算コストを有効に削減可能であるといえる．

\subsection{規模拡大に対する耐性（RQ3）}

RQ3は，問題の大規模化に対する提案手法の優位性に関する問いである．
各シナリオにおけるパラメータ増加時の挙動を確認すると，従来手法RAは問題規模の拡大に伴い，探索状態数の爆発的な増加（DCシナリオ）や，評価計算時間の指数的な増大（TLシナリオ）といったスケーラビリティの限界を露呈した．

一方，LRAはこれらの大規模ケースにおいても安定した性能を維持している．
CMシナリオの最大ケースにおいて唯一解を算出した点や，TLシナリオの大規模ケースにおいて計算時間の増加を微増に留めた点は，LRAが高いスケーラビリティを有することを裏付けている．
PMAによる階層的な目標設定は，問題規模が大きくなるほど探索空間を剪定する効果が高まるため，LRAは大規模で複雑なシステムに対して特に有効であると結論付けられる．

\subsection{Pre-Markingアクションの占有率と手法の適用指針}

最後に，実験を通じて得られた知見として，システムに含まれるPMAの密度に基づく最適な探索手法の選択指針について議論する．
実験結果の統計を見ると，全アクション数に対するPMAの占有率 $\rho$ が，手法の有効性を分かつ重要な指標となっていることが示唆される．

CM，DP，DCシナリオのように $\rho$ が20\%を超える高い値を示す場合，システムは強い構造的制約を持っており，LRAによる誘導が支配的に有効である．
これらのケースでは，LRAがRAおよびSRAを圧倒する性能を示しており，$\rho \geq 20\%$ はLRAを優先的に適用すべき明確な領域であるといえる．
この領域では，履歴に基づく発見的な探索よりも，構造解析に基づく計画的な探索が不可欠である．

一方で，KSやTAシナリオのように $\rho$ が20\%を下回る領域においては，RAの適用が推奨される．
PMAの占有率が低いということは，静的解析から得られる構造的な手掛かりが希薄であることを意味する．
このような状況下では，LRAは探索の指針を失い，SRAと同等の非効率な探索を行う傾向にある．
対してRAは，探索履歴（到達済みMarked状態）を活用することで，構造情報の不足を補い，過去に発見された有効経路周辺を集中的に探索する戦略をとる．
実際，KSシナリオ（$\rho \approx 10\%$）においてRAはLRAの約1/20の探索状態数で解に到達しており，TAシナリオの一部でも最短時間での合成を実現している．
このことから，構造的特徴が弱い問題においては，探索履歴という動的な情報の価値が相対的に高まると考えられる．

なお，ATやBW，TLシナリオのように，PMAも探索履歴も共に有効に機能せず，全手法が同等の探索経路を辿るケースも確認された．
このような問題に対しては，計算オーバーヘッドが最も小さいSRAを選択することが理想的である．
現状では，探索前に履歴情報が有効か否かを判定する指標は存在しないが，将来的にそのような判定が可能となれば，$\rho < 20\%$ の領域においてRAとSRAを適切に使い分けることで，さらなる合成効率の向上が期待できる．

以上の考察より，現時点での実用的な指針として，事前解析により算出可能な指標 $\rho$ を用い，$\rho \geq 20\%$ ならばLRAを，それ以外の場合はRAを選択するという戦略が有効であると結論付けられる．

\chapter{関連研究}
\label{chap:related_works}

\todo{以下の4点について触れ，本研究の立ち位置を明確にする．(1) 離散制御器合成における状態空間爆発への対処手法の変遷，(2) On-The-Flyを用いた他の分野の話（状態爆発系），(3) RAや機械学習を用いたヒューリスティック手法との対比，(4) 他の分野におけるLandmark Heuristic．}

\section{スーパバイザ制御理論の基礎と大規模システムへの展開}

並行して動作する複数のプロセスから構成されるシステムの正当性を保証することは，計算機科学および制御工学における長年の課題である．
Lamport~\cite{ProvingTheCorrectnessOfMultiprocessPrograms}は，マルチプロセスプログラムの正当性証明において，プログラムが意図しない悪い状態に到達しないことを保証するSafetyと，プログラムがいずれ望ましい状態に到達することを保証するLivenessという2つの性質の証明が不可欠であると指摘した．
これらの性質を，非同期に発生する離散的な事象（イベント）の列としてモデル化し，制御理論の枠組みで形式的に扱ったのが，RamadgeとWonhamによって提唱されたスーパバイザ制御理論（Supervisory Control Theory: SCT）である~\cite{DiscreteControllerSynthesis, DiscreteEventSystem}．

SCTにおいて，制御対象である離散事象システム（DES）は形式言語の生成器（Generator）としてモデル化される．
Ramadgeらは，システムが生成しうる言語（振る舞い）と，仕様として与えられた許容言語との包含関係に基づき，スーパバイザ（Supervisor）の存在条件を記述した~\cite{DiscreteControllerSynthesis}．
彼らは，システムに対して禁止可能なイベント（Controllable Event）を動的に無効化することで，仕様を満たす最大の振る舞いである最大制御可能部分言語（Supremal Controllable Sublanguage）を合成できることを示した．
これにより，Safety（仕様言語への包含）とSCTにおけるNon-Blocking（Marked状態への到達可能性）を数学的に保証するスーパバイザの自動生成が可能となった．

しかし，システムが大規模化・分散化するにつれて，単一の集中型スーパバイザを合成することは計算量および実装の観点から困難となる．
これに対し，LinとWonhamは，システムを複数の部分観測可能な局所スーパバイザ（Local Supervisor）によって制御する分散制御（Decentralized Control）の枠組みを提案した~\cite{DecentralizedSupervisoryControlOfDiscreteEventSystems}．
分散制御では，各局所スーパバイザが部分的な情報のみに基づいて制御判断を行い，それらの制御判断を融合することで，全体としてのSafetyを実現する．

また，大規模なシステムを効率的に扱うための階層的なアプローチも多数提案されている．
CaiとWonhamは，全体として合成された全体スーパバイザ（Global Supervisor）を，各エージェントが持つべき局所制御器（Local Controller）へと分解するスーパバイザ・ローカリゼーション（Supervisor Localization）の手法を提案した~\cite{SupervisorLocalization}．
この手法はトップダウンのアプローチにより，大域的な制御仕様を等価な局所制御ロジックへと配分することを可能にする．
一方，Komendaらは，システムを複数のサブシステムとそれらを調停するコーディネータ（Coordinator）の組み合わせとして捉えるコーディネーションスキーム（Coordination Scheme）を提案した~\cite{SupervisoryControlSynthesisOfDiscreteEventSystemsUsingACoordinationScheme}．
彼らは，条件付き制御可能性（Conditional Controllability）という概念を導入し，コーディネータを用いることで分散的な合成を行いながらも，大域的な仕様を満たす制御器を構成できることを示した．

これらの研究は，DESの制御においてSafetyとNon-Blockingを保証するための堅牢な理論的基盤を提供している．
しかし，全体スーパバイザを事前に構築する手法や，複雑な協調構造を必要とする手法は，依然として状態空間爆発の問題や設計の複雑さに直面する場合がある．
特に，動的に変化する環境や未知の制約に対してリアルタイムに制御を行う場合，あるいは巨大な状態空間を持つシステムに対しては，全状態空間を事前に構築することなく，必要な経路のみを探索的に決定するOn-The-Fly探索の手法や，探索を効率化するためのヒューリスティック技術が重要となる．

\chapter{結論}
\label{chap:conclusion}

\section{本論文のまとめ}

\todo{本論文で提案したLRAの総括を行う．}

\section{将来研究}

本研究では，LRAの導入により，評価すべきターゲットをシステムにとって真に不可欠なPMAに絞り込むことで，RAが抱える多重な距離計算の冗長性を解消し，探索効率を大幅に改善した．
今後の展望として，以下の三つの方向性が挙げられる．

第一に，On-The-Fly探索アルゴリズム自体のデータ構造とメモリ管理の最適化である．
実験を通じて，LRAによって探索状態数が削減された場合でも，システム規模が極めて大きい場合には，既訪問状態の保存や照合にかかる管理コストが探索速度の律速要因となる傾向が確認された．
現在の実装ではハッシュセットを用いた明示的な状態管理を行っているが，数百万状態を超える規模の探索においては，メモリ使用量とキャッシュ効率の観点で改善の余地がある．
したがって，今後はBDD（二分決定グラフ）を用いたシンボリックな状態管理手法の導入や，探索済み状態の圧縮表現技術を適用することで，より大規模なシステムに対しても高速かつ省メモリな制御器合成を実現する必要がある．

第二に，PMA抽出アルゴリズムの拡張と汎用化である．
現行の手法では，目標達成に必ず発火しなければならないアクションをPMAとして定義している．
この定義は強力な剪定効果を持つ一方で，複数の加工ルートが存在する場合（OR条件）や，確率的な分岐を含むシステムにおいては，必須アクションが存在せずPMAが抽出されないケースがある．
今後は，必須性の条件を緩和し，複数の候補集合を選言的な中間目標として扱う枠組みや，静的解析と動的探索を組み合わせたより柔軟なボトルネック抽出手法を開発することで，LRAの適用範囲をさらに広げることが期待される．

第三に，探索履歴に基づいたヒューリスティック評価の高度化である．
RAは，探索中に到達済みのMarked状態への距離（Rank 0）を，未到達のMarked状態への距離（Rank 1）よりも優先して評価する仕組みを持つ．
この戦略は，探索を既知の安全なループへ誘導し，Non-Blocking性を早期に確定させる上で有効に機能する場合がある．
現在のLRAは，Markingアクションが複数存在する場合でも，それらを一律の目標集合として扱っている．
そこで，LRAにおいてもRAの知見を取り入れ，既に発火履歴のあるMarkingアクションへの指向性を強化する動的な重み付けを導入することで，探索の安定性と収束速度をさらに向上させることが可能であると考えられる．

\appendix

\backmatter

\chapter{謝辞}

\bibliographystyle{jplain}
\bibliography{references}

\end{document}
