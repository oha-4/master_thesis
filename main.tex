\documentclass[a4paper,11pt,oneside,openany,report,dvipdfmx]{jsbook}

\usepackage[left=30mm,right=30mm,top=25mm,bottom=25mm]{geometry}
\usepackage{cscover}
\usepackage{graphicx}
\usepackage[nobreak]{cite}
\usepackage[a4paper,dvipdfmx,pdfdisplaydoctitle=true,%
	bookmarks=true,bookmarksnumbered=true,bookmarkstype=toc,bookmarksopen=true%
]{hyperref}
\usepackage{pxjahyper}

\hypersetup{
  pdftitle={Pre-Markingアクションを用いたDirected Controller Synthesisの探索ヒューリスティック改善},
  pdfauthor={大畑允人}
}

\renewcommand{\headfont}{\bfseries}
\renewcommand{\bibname}{参考文献}
\setcounter{tocdepth}{2}
\pagestyle{plain}

\thesistype{修士論文}
\title{Pre-Markingアクションを用いた\\Directed Controller Synthesisの\\探索ヒューリスティック改善}
\author{大畑 允人}
\studentid{24M30552}
\affiliation{%
	東京科学大学\\
	情報理工学院\\
	情報工学コース
}
\date{2026年1月}

\supervisorname{指導教員}
\supervisor{鄭 顕志}

\usepackage{algorithm}
\usepackage[italicComments=false,indLines=false]{algpseudocodex}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{comment}
\usepackage{mathtools}
\usepackage{thmtools}
\usepackage{tikz}
\usepackage{prettyref}

\declaretheoremstyle[
	notefont=\mdseries, notebraces={（}{）},
	headpunct=．,
]{jstyle}
\declaretheorem[name=定義,style=jstyle]{definition}

\newcommand{\descitem}[1]{\item[#1]\mbox{}\\}

\usetikzlibrary{arrows.meta,automata,positioning}

\newrefformat{chap}{第\ref*{#1}章}
\newrefformat{sec}{第\ref*{#1}節}
\newrefformat{subsec}{第\ref*{#1}項}
\newrefformat{subsubsec}{第\ref*{#1}目}
\newrefformat{fig}{図\ref*{#1}}
\newrefformat{alg}{アルゴリズム\ref*{#1}}
\newcommand\aref[1]{\hyperref[#1]{\prettyref{#1}}}

\makeatletter

\renewcommand{\fps@algorithm}{H}
\renewcommand{\ALG@name}{アルゴリズム}
\renewcommand{\algorithmicrequire}{\textbf{入力：}}
\renewcommand{\algorithmicensure}{\textbf{出力：}}
\algrenewcommand\Return{\State\textbf{return} }
\algnewcommand\Break{\State\textbf{break}}
\algnewcommand\Continue{\State\textbf{continue}}

\makeatother

\begin{document}

\frontmatter

\maketitle

\chapter{概要}

\tableofcontents
\listoffigures
\listoftables

\mainmatter

\chapter{序論}

現代の社会インフラや産業システムにおいて，ソフトウェアが担う役割は拡大の一途をたどっている．
これらのシステムの多くは，離散的な状態と，その状態を遷移させる事象（アクション）の列によって振る舞いが記述される離散事象システム（Discrete Event System, DES）としてモデル化できる．
システムの高機能化・複雑化に伴い，システムが安全性や活性といった要求仕様を確実に満たすことを保証するのはますます困難になっており，設計段階における支援技術の重要性が高まっている．

本章では，離散事象システムとその制御に関する背景を述べ，本研究が取り組む課題と目的，および本論文の構成について概説する．

\section{離散事象システムと離散制御器合成}

離散事象システム（DES）は，離散的な状態空間を持ち，非同期に発生する事象によって状態遷移が引き起こされる動的システムである．
製造ラインの工程管理，ロボットの動作計画，通信プロトコル，組み込みシステムなど，その適用範囲は多岐にわたる．
これらのシステムに対し，危険な状態に到達しないというSafetyや，目的とするタスクを無限回完了できるというNon-Blockingを保証することは，システムの信頼性を確保する上で不可欠である．

従来，これらの要求を満たす制御ロジック（動作仕様）の設計は，熟練した設計者の経験則や，試行錯誤的な検証に依存していた．
しかし，並行して動作する複数のコンポーネントが複雑に相互作用するシステムにおいて，人間の直感だけで全ての境界条件や例外ケースを網羅し，デッドロックや禁止状態への到達を防ぐことは極めて困難である．
設計ミスは再設計のコストを増大させるだけでなく，運用時の重大な事故につながるリスクも孕んでいる．

この課題に対する解決策として，形式手法に基づき，与えられた環境モデルと要求仕様から正しい制御器を自動生成する離散制御器合成（Discrete Controller Synthesis）の研究が進められている~\cite{}．
離散制御器合成は，環境の可能な振る舞いをすべて考慮した上で，制御可能なアクションを適切に許可・禁止することで，システムが常に仕様を満たすことを数学的に保証する．
特に，システム自身が能動的にアクションを選択してタスクを遂行するようなシステムにおいては，各状態で高々1つの制御アクションのみを選択するDirected Controllerの合成が有効である~\cite{}．
このDirected Controllerを合成する技術をDirected Controller Synthesis（DCS）と呼ぶ．

しかし，DCSの実適用における最大の障壁は状態空間爆発問題である．
システムを構成するコンポーネント数が増加すると，合成後の状態空間は指数関数的に増大する．
これに対処するため，状態空間全体を事前に構築せず，初期状態から必要な部分のみを探索するOn-The-Fly探索手法や，探索を効率化するためのヒューリスティック技術が提案されてきた~\cite{}．
特に，Ciolekらが提案したReady Abstraction（RA）は，並列合成の構造を利用して目標までの距離を効率的に推定する強力なヒューリスティックであり，DCSの適用範囲を拡大させてきた．

\section{本論文の目的}

本論文の目的は，DCSにおけるOn-The-Fly探索の効率をさらに向上させるため，従来のReady Abstraction（RA）が抱える構造的な課題を解決する新たな探索指針であるPre-Marking Directionを提案することである．

従来のRAは，各コンポーネントにおいて局所的に発火可能なアクション（Readyアクション）の情報に基づいて目標までの距離を推定する．
しかし，この推定手法には以下の構造的な課題が存在する．

\begin{description}
  \descitem{同期構造を無視した到達可能性評価の限界}
  RAは，Readyアクションのみをノードとするグラフ上で距離を推定する．しかし，目標達成に特定のコンポーネント間の同期が不可欠な場合，現在はReadyアクションではないが将来的に同期を解放するために必要な予備アクションが評価から漏れる．その結果，同期ボトルネックを考慮しない近視眼的な経路選択が行われ，探索空間が不必要に拡大する．
  \descitem{Readyアクション探索に伴う計算負荷}
  RAは距離推定において，Readyアクション間の遷移コストやその先の距離を考慮し，再帰的に様々なパスを探索して最小値を計算する．この探索は，特にReadyアクションの候補が多い場合に計算コストが増大し，1ステップごとの処理時間を長引かせる要因となる．
\end{description}

そこで本研究では，複雑なReadyアクショングラフの探索に依存せず，目標アクションの発火に不可欠な同期イベント（Pre-Markingアクション）を直接的な指針とする新たな距離推定手法を提案する．
具体的には，以下の項目に取り組む．

\begin{description}
  \descitem{Ready Abstractionの探索特性と課題の分析}
  Readyアクションを用いた距離推定が，同期を要するシステムにおいて近視眼的な挙動を示す原因と，それによって探索空間が不必要に拡大するメカニズムについて，具体的なモデルを用いて分析する．
  \descitem{Pre-Marking Directionの提案}
  目標アクションの発火に不可欠な同期アクションをPre-Markingアクション（PMA）として定義し，これを探索の指針とする新たなヒューリスティック手法Pre-Marking Direction（PMD）を提案する．
  PMDは，RAのような複雑な探索を行わず，各コンポーネント単体での距離のみを用いた軽量な計算を採用する．
  PMAが同期構造上の要所を捉えているため，この単純化された指標でも十分な探索性能を発揮でき，計算負荷を抑えつつ同期ボトルネックを考慮した高速な探索を実現する．
  \descitem{評価実験による有効性の検証}
  提案手法を実装し，ベンチマーク問題を用いて従来手法と比較することで，探索状態数や計算時間の削減効果を定量的に評価する．
\end{description}

本研究の成果は，より大規模で複雑なシステムの制御器合成を現実的な時間・メモリリソースで可能にし，高信頼なシステム開発の自動化に貢献するものである．

\section{本論文の構成}

本論文の構成は以下の通りである．

\aref{chap:background}「背景技術」では，本研究の基礎となる離散制御器合成およびDCSの理論的枠組み，On-The-Fly探索アルゴリズム，および既存のヒューリスティック手法であるReady Abstractionについて詳説する．

\aref{chap:ready_abstraction_limitations}「Ready Abstractionの課題」では，既存のRAが抱える構造的な限界について述べる．特に，Markingアクションの発火にコンポーネント間の同期が必要な状況において，現状態のReadyアクションのみに基づくRAの推定が機能せず，近視眼的な探索となり探索空間の爆発を招くメカニズムについて分析する．

\aref{chap:pre_marking_direction}「Pre-Marking Direction」では，本研究の中核となる提案手法について述べる．目標アクションの発火に必要な同期イベント（Pre-Markingアクション）を定義し，複雑なグラフ探索を行わずに各コンポーネント単体での距離情報のみを用いることで，同期を考慮した高精度な探索と，計算負荷の低い高速な推論を両立するアルゴリズムを示す．また，提案手法の適用による性能向上を実験により評価する．

\aref{chap:related_works}「関連研究」では，DCSの効率化やヒューリスティック探索に関する先行研究を概観し，本研究の位置づけを明確にする．

\aref{chap:conclusion}「結論」では，本論文の成果を総括し，今後の展望について述べる．

\chapter{背景技術}
\label{chap:background}

本章では，本研究の基盤となる離散制御器合成の概要，Directed Controller Synthesis（DCS）の定式化とOn-The-Fly探索アルゴリズム，およびReady Abstraction（RA）に基づくヒューリスティック関数について述べる．

\section{離散制御器合成}

離散制御器合成（Discrete Controller Synthesis）は，離散事象システム（Discrete Event System, DES）に対して，与えられた安全性などの制約を満たす制御器を自動的に構築する技術である．
DESは有限状態オートマトン（あるいはLTS）の並列合成によってモデル化されるが，並列合成により得られる状態空間はコンポーネント数に対して指数的に増大しうる．
この指数的爆発は離散制御問題の解決を困難にし，現在も研究上の課題となっている．

制御器は，制御可能なアクションを動的に無効化しながら，制御不能なアクションを監視することで，システムの振る舞いを制限する．
一般のスーパバイザ制御では可能な限り多くの制御可能アクションを有効にする（最大許容）ことが求められることが多い．
しかし，DESの制御器が「制御されたアクションを実行するアクティブなコンポーネント」として振る舞う文脈では，任意の時点で高々1つの制御可能アクションのみを選択する制御が適切となる場合がある．
このような制御器はDirected Controllerと呼ばれる．

\subsection{ラベル付き遷移系}

本研究では，システムを構成する各コンポーネントをラベル付き遷移系（Labeled Transition System, LTS）としてモデル化する．
なお，本研究ではMarkingアクション（アクションベースの目標）を主に用いるが，既存研究ではMarked状態（状態ベースの目標）を用いることもある．
この両者を扱えるよう，LTSにはMarked状態集合とMarkingアクション集合の両方を持たせる（必要に応じて片方を空集合または全体集合として扱う）．

\begin{definition}[LTS]
  LTSは
  $E = (S_E, s_{E,0}, S^I_E, S^M_E, A_E, A^M_E, \Delta_E)$
  で表現される．
  $S_E$は有限の状態集合であり，$s_{E,0} \in S_E$は初期状態を表す．
  $S^I_E \subseteq S_E$は違反状態の集合であり，システムが到達してはならない状態を表す．
  $S^M_E \subseteq S_E$はMarked状態の集合である（RAや既存のDCS定式化で用いる）．
  $A_E = A^C_E \cup A^U_E$はアクション集合であり，$A^C_E$は制御可能アクション，$A^U_E$は制御不能アクションを表す．
  $A^M_E \subseteq A_E$はMarkingアクション集合である（本研究の定式化で用いる）．
  $\Delta_E \subseteq S_E \times A_E \times S_E$は遷移関係を表す．
\end{definition}

\begin{definition}[決定性]
  LTS $E$が決定的であるとは，任意の状態$s\in S_E$とアクション$a\in A_E$について，
  $(s,a,s_1)\in\Delta_E$かつ$(s,a,s_2)\in\Delta_E$ならば$s_1=s_2$が成り立つことをいう．
\end{definition}

本研究では，全てのLTSは決定的であると仮定する．

\begin{definition}[トレース]
  $\Delta_E$に従う状態とアクションの有限または無限の交互列
  $t = s_0, a_0, s_1, a_1, \ldots$
  をトレースと呼ぶ．
  ただし，各$i$について$(s_i, a_i, s_{i+1}) \in \Delta_E$が成り立つ．
  $E$上のトレースの集合を$T_E$で表す．
\end{definition}

\subsection{同期アクションと並列合成}

\begin{definition}[同期アクション]
  複数のLTS $E_1, \ldots, E_n$において，アクション$a$が2つ以上のコンポーネントのアクション集合に含まれるとき，
  $a$を同期アクションと呼ぶ．同期アクション集合$A^S$は
  $$
    A^S = \left\{a \in \bigcup_{i=1}^{n} A_{E_i} \;\middle|\; |\{i \mid a \in A_{E_i}\}| \geq 2\right\}
  $$
  と定義する．
\end{definition}

\begin{definition}[並列合成]
  LTS集合$\mathcal{E} = \{E_1,\ldots,E_n\}$の並列合成$E_\parallel = E_1 \parallel E_2 \parallel \cdots \parallel E_n$を$E_\parallel = (S_{E_\parallel}, s_{E_\parallel ,0}, S^I_{E_\parallel}, S^M_{E_\parallel}, A_{E_\parallel}, A^M_{E_\parallel}, \Delta_{E_\parallel})$
  として定義する．
  状態集合$S_{E_\parallel}=\prod_{i=1}^{n}S_{E_i}$は各コンポーネントの状態の直積であり，初期状態は$s_{E_\parallel,0}=(s_{E_1,0},\ldots,s_{E_n,0})$である．
  違反状態集合$S^I_{E_\parallel}$は，いずれかのコンポーネントが違反状態にある状態の集合$\{(s_1, \ldots, s_n) \in S_{E_\parallel} \mid \exists i . s_i \in S^I_{E_i}\}$として定義される．
  Marked状態集合は$S^M_{E_\parallel}=\prod_{i=1}^{n}S^M_{E_i}$，
  アクション集合$A_{E_\parallel}=\bigcup_{i=1}^{n}A_{E_i}$，
  Markingアクション集合$A^M_{E_\parallel}=\bigcup_{i=1}^{n}A^M_{E_i}$である．
  遷移関係$\Delta_{E_\parallel}$については，同期アクション$a \in A^S$は$a$を持つ全てのLTSで同時に発火し，非同期アクション$a \notin A^S$は$a$を持つLTSのみで発火する．
\end{definition}

並列合成には以下の特徴がある：
\begin{itemize}
  \item 同期アクションによりコンポーネント間の協調動作を実現できる
  \item 状態数$|S_{E_\parallel}|$はLTS数に対して指数的に増大しうる
\end{itemize}

\section{Directed Controller Synthesis}

本節では，Directed Controller Synthesis（DCS）の形式的定義と，On-The-Fly探索によるアルゴリズムについて述べる．

\subsection{制御可能性とDirected Controller}

アクションには制御可能なものと制御不能なものがある．
制御可能アクションは，制御器によって有効化・無効化が可能である．
一方，制御不能なアクションは環境によって発火されるため，発火し得る場合は全ての発火を考慮しなければならない．
各状態の制御可能なアクションのうち高々1つのみを有効にする制御器を合成することで，システム全体の振る舞いを制御する．
このような制御器をDirected Controllerと呼ぶ．

\begin{definition}[Directed Controller]
  並列合成LTS $E_\parallel$に対する制御器が以下の条件を満たすとき，Directed Controllerと呼ぶ：
  \begin{description}
    \item[Controllable]
          すべての制御不能アクションを常に有効化する
    \item[Directed]
          各状態で高々1つの制御可能アクションのみを有効化する
    \item[Eager]
          Marked状態，またはMarkingアクション発火後の状態において，制御可能アクションのみ存在する場合，必ず1つを選択する
  \end{description}
\end{definition}

\subsection{制御問題}

既存のDCSでは，タスク完了などを表すMarked状態への到達可能性に基づいてNon-Blocking性を定義することがある．
本研究のMarkingアクションベース定式化との関係は\aref{subsec:marking_to_marked}で述べる．
また，本研究では，目標を状態ではなくMarkingアクション$A^M$の発火として与える．

\begin{definition}[Directed Controllerの制御問題]
  LTSの組$\bm{E}=(E_1,\ldots,E_n)$に対し，解は以下を満たすDirected Controllerである：
  \begin{description}
    \item[Safety]
          制御下のシステムが違反状態に到達しない
    \item[Non-Blocking]
          Marked状態への到達，またはMarkingアクションの発火を無限回行える
  \end{description}
\end{definition}

\subsection{MarkingアクションからMarked状態への変換}
\label{subsec:marking_to_marked}

本研究では，目標を特定の状態への到達ではなく，Markingアクション集合 $A^M$ のいずれかの要素が発火することとして定義する．既存のReady Abstraction (RA) の枠組みは状態ベースの目標を想定しているため，アクションベースの目標を状態ベースに変換するためのLTS $E_M$ を導入し，他のコンポーネントの設定を調整する．

合成対象のコンポーネント集合を $\mathcal{E} = \{E_1, \dots, E_n\}$ とし，全コンポーネントのアクション集合の和を $A = \bigcup_{i=1}^n A_{E_i}$ とする．このとき，Markingアクションの発生を状態として保持するMarking判定LTS $E_M = (S_{E_M}, s_{E_M,0}, S^I_{E_M}, S^M_{E_M}, A_{E_M}, A^M_{E_M}, \Delta_{E_M})$ を以下のように定義する：

\begin{itemize}
  \item $S_{E_M} = \{0, 1\}$, $s_{E_M,0} = 0$, $S^I_{E_M} = \emptyset$, $S^M_{E_M} = \{1\}$
  \item $A_{E_M} = A$ （同期のために全アクションをアルファベットに含める）
  \item 遷移関係 $\Delta_{E_M}$：
        \begin{itemize}
          \item 任意の $a \in A^M$ に対し，$(0, a, 1) \in \Delta_{E_M}$ および $(1, a, 1) \in \Delta_{E_M}$
          \item 任意の $a \notin A^M$ に対し，$(0, a, 0) \in \Delta_{E_M}$ および $(1, a, 0) \in \Delta_{E_M}$
        \end{itemize}
\end{itemize}

さらに，並列合成 $E_\parallel = E_1 \parallel \dots \parallel E_n \parallel E_M$ において目標達成の判定を $E_M$ に一任するため，他のすべてのコンポーネント $E_i \in \{E_1, \dots, E_n\}$ について，そのMarked状態集合を $S^M_{E_i} = S_{E_i}$ （全状態をMarkedとする）へ再定義する．

この変換により，合成システム $E_\parallel$ がMarked状態にあることは，$E_M$ が状態 $1$ にあることと等価になる．$E_M$ は直前に実行されたアクションが $A^M$ に属する場合のみ状態 $1$ に遷移するため，このMarked状態を無限回訪問することは，元のシステムにおいてMarkingアクションを無限回発火し続けるNon-blockingな振る舞いと完全に一致する．

\subsection{On-The-Fly探索アルゴリズム}

従来のアプローチでは，まずオートマトンを完全に合成し，その後で制御問題を解く．
しかし，この方法は指数的な状態空間爆発を引き起こす可能性がある．
Ciolekら~\cite{}は，ヒューリスティックに導かれたOn-The-Fly探索により，状態空間の一部のみを探索してDirected Controllerを発見するアルゴリズムを提案した．

On-The-Fly探索は，状態空間全体を事前に構築することなく，初期状態から到達可能な必要な部分のみを段階的に展開しながら制御器を合成する手法である．
この手法は，主に以下の3つのプロセスから構成される．

\begin{enumerate}
  \item \textbf{展開（Expansion）}:
        現在の探索フロンティアから，ヒューリスティック関数（例えばRA）を用いて最も有望な未探索の遷移を選択し，探索グラフに追加する（\textsc{ExpandNext}）．これにより，Marked状態への到達可能性が高い経路を優先的に探索する．
  \item \textbf{伝播（Propagation）}:
        ある状態が\textit{Goals}（勝利状態）または\textit{Errors}（敗北状態）であることが確定した場合，その情報を探索グラフの逆方向（親状態）へ伝播させる（\textsc{PropagateGoal}, \textsc{PropagateError}）．
        状態の分類は以下の論理に基づき決定される：
        \begin{itemize}
          \item \textbf{Goalsへの伝播}：
                ある状態から制御可能な遷移によって少なくとも1つの\textit{Goals}状態へ到達可能であるか，あるいはその状態から発生しうる全ての制御不能な遷移の先が\textit{Goals}である場合，その状態は\textit{Goals}となる．
          \item \textbf{Errorsへの伝播}：
                ある状態から発生しうる全ての制御可能な遷移の先が\textit{Errors}かつ制御不能な遷移によって少なくとも1つの\textit{Errors}状態へ到達可能である場合，その状態は\textit{Errors}となる．
        \end{itemize}
  \item \textbf{閉路検出と判定（Loop Detection）}:
        探索中に新たな閉路が形成された場合，その閉路がNon-Blockingを満たすか否かを判定する．
        Markingアクションを含む閉路などの「勝利閉路」が見つかれば，その閉路上の状態は\textit{Goals}となり，逆にMarkingアクションを含まず脱出不可能な閉路は\textit{Errors}となる．
\end{enumerate}

探索は初期状態が\textit{Goals}または\textit{Errors}に分類されるまで継続される．初期状態が\textit{Goals}に分類された場合，探索グラフから有効な部分グラフを抽出することで制御器が得られる．逆に\textit{Errors}に分類された場合は，制御器の合成は不可能であると結論付けられる．

\begin{algorithm}
  \caption{On-The-Fly探索によるDirected Controller Synthesis}
  \label{alg:dcs}
  \begin{algorithmic}[1]
    \Require{全てのLTSの組 $\bm{E} = (E_1, \ldots, E_n)$，ヒューリスティック関数 $H$}
    \Ensure{Directed Controller $C$ または 合成不可能}

    \Function{DirectedControllerSynthesis}{$\bm{E}, H$}

    \State $\mathit{ES} \gets$初期状態$\bm{s}_0$のみを持つ部分探索グラフ
    \State $\mathit{Goals} \gets \emptyset, \mathit{Errors} \gets \emptyset, \mathit{None} \gets \{\bm{s}_0\}$

    \Statex

    \LComment{探索ループ：初期状態が未分類状態でなくなるまで}
    \While{$\bm{s}_0 \notin (\mathit{Goals} \cup \mathit{Errors})$}
      \State $(\bm{s}, a, \bm{s}') \gets \textsc{ExpandNext}(\mathit{ES}, H)$ \Comment{ヒューリスティックによる次遷移の選択}
      \State $\mathit{ES} \gets \mathit{ES} \cup \{(\bm{s}, a, \bm{s}')\}$ \Comment{探索グラフの更新}

      \Statex
      \If{$\bm{s}' \in \mathit{Errors}$}
        \State $\mathit{Errors} \gets \mathit{Errors} \cup \{\bm{s}'\}$
        \State $\textsc{PropagateError}(\bm{s}')$ \Comment{敗北状態の伝播}
      \ElsIf{$\bm{s}' \in \mathit{Goals}$}
        \State $\mathit{Goals} \gets \mathit{Goals} \cup \{\bm{s}'\}$
        \State $\textsc{PropagateGoal}(\bm{s}')$ \Comment{勝利状態の伝播}
      \ElsIf{$\bm{s}'$ が新しいループを形成する}
        \State $\mathit{Loop} \gets \textsc{GetLoop}(\bm{s}, \bm{s}')$
        \If{$\mathit{Loop}$ が勝利条件を満たす}
          \State $\mathit{newGoals} \gets \textsc{FindNewGoals}(\mathit{Loop})$
          \State $\mathit{Goals} \gets \mathit{Goals} \cup \mathit{newGoals}$
          \State $\textsc{PropagateGoal}(\mathit{newGoals})$
        \Else
          \State $\mathit{newErrors} \gets \textsc{FindNewErrors}(\mathit{Loop})$
          \State $\mathit{Errors} \gets \mathit{Errors} \cup \mathit{newErrors}$
          \State $\textsc{PropagateError}(\mathit{newErrors})$
        \EndIf
      \EndIf
    \EndWhile

    \Statex

    \If{$s_0 \in \mathit{Goals}$}
      \State $C \gets \textsc{ExtractController}(\mathit{ES}, \mathit{Goals})$
      \Return $C$
    \Else
      \Return 合成不可能
    \EndIf

    \EndFunction

  \end{algorithmic}
\end{algorithm}

\section{Ready Abstraction}

Ready Abstraction（RA）は，並列合成構造を活用して，Marked状態への到達に必要なステップ数を多項式時間で推定するヒューリスティック手法である．
各コンポーネントの局所情報のみを用いて距離を推定することで状態空間爆発を回避しつつ，On-The-Fly探索における次遷移選択（\textsc{ExpandNext}）を導く．

RAの基本的な着想は，合成状態 $\bm{s} = (s_{E_1}, s_{E_2}, \ldots, s_{E_n})$ の周辺で局所的に発火可能なアクション（Readyアクション）を集め，それらの間に，あるアクションの実行が別のアクションの実行可能性を高めるという関係を仮想的に張ったグラフ上で最短路を解くことで，目標（Marked状態）までの距離を見積もる点にある．
同期制約のため，局所的に発火可能（Ready）であっても合成状態全体では直ちに発火できない場合があるが，RAはこの差を局所到達可能性とグラフ探索に基づいて保守的に見積もる．

\subsection{候補アクションの評価}

\aref{alg:ready_abstraction}は，現在の合成状態 $\bm{s}$ において候補アクション $\hat{a}$ を選ぶことがどれだけ目標に近いかを評価するためのヒューリスティック関数である．
評価は各コンポーネント $E_i$ ごとに $(\mathrm{rank}, d)$ の形で返され，rank は距離推定に用いる目標集合の優先度を表す．

本章で示すRAの記述では，探索中にすでに到達したMarked状態集合 $\bm{S}^M$ を基準にした距離（Rank 0）を優先する．
これは，探索が進むほど既知の到達済み領域へ近づく選択を上位に扱うことで，任意のMarked状態を一様に目指す場合に比べて探索が過度に広がることを避け，探索空間を抑制できるという見込みに基づく．
Rank 0での推定が不可能な場合に限り，任意のMarked状態への距離（Rank 1）を用いる．
どちらも不可能と推定された場合は $(2,\infty)$ を返す．

\begin{algorithm}
  \caption{Ready Abstractionによるヒューリスティック関数}
  \label{alg:ready_abstraction}
  \begin{algorithmic}[1]
    \Require{%
      全てのLTSの組 $\bm{E} = (E_1, E_2, \ldots, E_n)$， \\
      探索到達済みのMarked状態の集合 $\bm{S}^M \subseteq S^M_{E_1} \times S^M_{E_2} \times \cdots \times S^M_{E_n}$， \\
      各LTSにおける状態の組 $\bm{s} = (s_{E_1}, s_{E_2}, \ldots, s_{E_n})$， \\
      候補のアクション $\hat{a}$
    }
    \Ensure{%
      各LTSにおける距離の降順の組 $\bm{d} = (\bm{d}_1, \bm{d}_2, \ldots, \bm{d}_n)$ \\
      ただし，$\bm{d}_i \in \{(0, d), (1, d), (2, \infty) \mid d \in \mathbb{N}\}$ \\
      各LTSにおける距離の意味は以下の通り： \\
      $(0, d)$：次にアクション$\hat{a}$を発火して$d$ステップで探索到達済みのMarked状態に到達可能 \\
      $(1, d)$：次にアクション$\hat{a}$を発火して$d$ステップでMarked状態に到達可能 \\
      $(2, \infty)$：Marked状態に到達不可能
    }

    \Function{ReadyAbstractionHeuristic}{$\bm{E}, \bm{S}^M, \bm{s}, \hat{a}$}

    \For{$i = 1, 2, \ldots, n$}
      \State $\mathit{minSteps} \gets \infty$

      \Statex

      \LComment{Rank 0: 探索到達済みのMarked状態への到達可能性確認}
      \ForAll{$(s^*_{E_1}, s^*_{E_2}, \ldots, s^*_{E_n}) \in \bm{S}^M$}
        \State $\mathit{steps} \gets \textsc{EstimateDist}(\bm{s}, \hat{a}, s^*_{E_i})$
        \If{$\mathit{steps} < \mathit{minSteps}$}
          $\mathit{minSteps} \gets \mathit{steps}$
        \EndIf
      \EndFor
      \If{$\mathit{minSteps} \ne \infty$} \Comment{いずれかの探索到達済みのMarked状態に到達可能な場合}
        \State $\bm{d}_{E_i} \gets (0, minSteps)$
        \Continue
      \EndIf

      \Statex

      \LComment{Rank 1: 任意のMarked状態への到達可能性確認}
      \ForAll{$s^*_{E_i} \in S^M_{E_i}$}
        \State $\mathit{steps} \gets \textsc{EstimateDist}(\bm{s}, \hat{a}, s^*_{E_i})$
        \If{$\mathit{steps} < \mathit{minSteps}$}
          $\mathit{minSteps} \gets \mathit{steps}$
        \EndIf
      \EndFor

      \If{$\mathit{minSteps} \ne \infty$} \Comment{いずれかのMarked状態に到達可能な場合}
        \State $\bm{d}_{E_i} \gets (1, minSteps)$
      \Else
        \State $\bm{d}_{E_i} \gets (2, \infty)$
      \EndIf
    \EndFor

    \Statex

    \Return $\textsc{SortDescending}((\bm{d}_{E_1}, \bm{d}_{E_2}, \ldots, \bm{d}_{E_n}))$
    \Comment{距離を辞書式降順でソートして返す}

    \EndFunction
  \end{algorithmic}
\end{algorithm}

\aref{alg:ready_abstraction}の戻り値は各コンポーネントの距離推定の組であるが，実際の探索（\textsc{ExpandNext}）において候補アクション $\hat{a}$ を選択する際は，以下の優先順位に従って順位付けを行う：

\begin{enumerate}
  \item \textbf{制御不能アクションの優先}：$\hat{a} \in A^U$ であるアクションを，全ての制御可能アクション $\hat{a} \in A^C$ よりも優先する．
  \item \textbf{辞書式順序による比較}：アクションの属性が同じ（共に制御可能，あるいは共に制御不能）である場合，\aref{alg:ready_abstraction}が返す距離の組 $\bm{d}$ を辞書式に比較し，値が小さい（より目標に近いと推定される）ものを優先する．
\end{enumerate}

制御不能アクションを最優先するのは，環境側で発生しうる全ての振る舞いを早期に探索し，反例（違反状態やデッドロック）を迅速に検出するためである．

\subsection{距離推定の中核}

\aref{alg:estimate_dist}は，\aref{alg:ready_abstraction}が内部で呼び出す距離推定関数である．
入力は現在の合成状態 $\bm{s}$，次に実行する候補アクション $\hat{a}$，距離の対象となるコンポーネント状態 $s^*_{E_i}$ であり，出力は推定距離 $d$ である．

推定は大きく二段階で行われる．
まず，$\hat{a}$ がコンポーネント $E_i$ に存在するなら，$\hat{a}$ を局所的に一回発火した後の状態 $s'_{E_i}$ を確認し，そこからの局所最短距離 $\textsc{CalculateDist}(s'_{E_i}, s^*_{E_i})$ を用いて直接効果を見積もる．
これで判断できない場合には，現在の合成状態から（同期を無視すれば）状態を変化させ得るアクション集合 $A^R$ を列挙し，切り替えコスト（Gap）とその先の推定距離の和の最小値として距離を与える．
この再帰的最小化は，実装上はRAグラフ上の最短路として扱うことで効率化できる．

\begin{algorithm}
  \caption{Ready Abstractionにおける距離推定関数}
  \label{alg:estimate_dist}
  \begin{algorithmic}[1]
    \Require{%
      現在の状態 $\bm{s} = (s_{E_1}, \ldots, s_{E_n})$， \\
      候補のアクション $\hat{a}$， \\
      距離を推定する対象の状態 $s^*_{E_i}$
    }
    \Ensure{推定距離 $d \in \mathbb{N} \cup \{\infty\}$}

    \Function{EstimateDist}{$\bm{s}, \hat{a}, s^*_{E_i}$}

    \If{$\hat{a} \in A_{E_i}$} \Comment{$\hat{a}$ がLTS $E_i$ に存在している場合}
      \State $s'_{E_i} \gets s' \text{ where } (s_{E_i}, \hat{a}, s') \in \Delta_{E_i}$ \Comment{$\hat{a}$ を発火した後の状態}
      \If{$s'_{E_i} = s^*_{E_i}$} \Comment{対象の状態に到達する場合}
        \Return $1$
      \ElsIf{$s'_{E_i} \in S^I_{E_i}$} \Comment{違反状態に到達する場合}
        \Return $\infty$
        \Comment{距離を無限と推定し，Marked状態に到達不可能であることを表す}
      \ElsIf{$s'_{E_i} \ne s_{E_i}$} \Comment{他の状態に遷移する場合}
        \Return $\textsc{CalculateDist}(s'_{E_i}, s^*_{E_i}) + 1$
      \EndIf
    \ElsIf{$s_{E_i} = s^*_{E_i}$} \Comment{$\hat{a}$で遷移が発生せず，すでに対象の状態の場合}
      \Return $1$
    \EndIf

    \Statex

    \LComment{各LTS上で，現在の状態から発火可能なアクションのうち，自己ループでないものの集合}
    \For{$j = 1, 2, \ldots, n$}
      \State $A^R_{E_j} \gets \{a \mid \exists s', (s_{E_j}, a, s') \in \Delta_{E_j}, s' \neq s_{E_j}\}$
    \EndFor
    \State $A^R \gets \bigcup_{j=1}^{n} A^R_{E_j}$ \Comment{Readyアクションの集合}

    \Statex

    \LComment{Gapを加味した最短経路探索}
    \State $d \gets \min_{a \in A^R}\{\textsc{CalculateGap}(\bm{s}, \hat{a}, a) + \textsc{EstimateDist}(\bm{s}, a, s^*_{E_i})\}$
    \LComment{この再帰的な最小値問題は，実装上はダイクストラ法により効率的に解かれる}

    \If{$d = \infty$} \Comment{Readyアクションを用いて距離を推定できない場合}
      \State $d \gets \textsc{CalculateDist}(s_{E_i}, s^*_{E_i}) + 1$
    \EndIf

    \Return $d$

    \EndFunction
  \end{algorithmic}
\end{algorithm}

ここで用いられる \textsc{CalculateGap}$(\hat{a}, a)$ は，アクション間の切り替えのしやすさを表すコストであり，既存研究における定義に従い，あるコンポーネント内でアクション $\hat{a}$ を経て $a$ へ至る最短パスの長さ（から1を引いた値）として計算される．

以上により，RAは局所情報から，次にどのアクションを展開するのが有望かを推定する枠組みを提供する．
On-The-Fly探索側では，これらの推定値を用いて展開順序を制御することで，合成状態空間の全探索を避けつつ，目的を満たす制御器の発見を狙う．

\begin{comment}
\subsection{Markingアクションまでの距離推定}

RAは，Marked状態への到達距離を推定する枠組みとして提案されている．
一方，本研究では目標をMarkingアクションの発火として定式化するため，RAを本研究の目的関数と同じ観点で比較するには，Marked状態ではなくMarkingアクションまでの距離をどのように見積もるかを明示しておく必要がある．
そこで本節では，Markingアクション集合 $A^M$ に対する距離推定手続きとして\textsc{EstimateDistToMarking}を示す．

\textsc{EstimateDistToMarking}は，候補アクション$\hat{a}$がMarkingアクションであれば距離1を返し，そうでなければ，合成状態$\bm{s}$から（同期を無視すれば）状態を変化させ得るアクション集合$A^R$を介して，Gapとその先での推定距離の和の最小値を再帰的に求める．
構造は\aref{alg:estimate_dist}（\textsc{EstimateDist}）と同型であり，終端条件がMarked状態ではなくMarkingアクションになっている点が相違である．

なお，\textsc{EstimateDistToMarking}は，探索到達済みMarked状態集合$\bm{S}^M$を基準とするRank 0の推定が利用できない状況，特に$\bm{S}^M=\emptyset$の場合に用いることを想定している．


\begin{algorithm}
  \caption{Ready AbstractionにおけるMarkingアクションまでの距離推定}
  \begin{algorithmic}[1]
    \Require{%
      現在の状態 $\bm{s} = (s_{E_1}, \ldots, s_{E_n})$， \\
      候補のアクション $\hat{a}$
    }
    \Ensure{推定距離 $d \in \mathbb{N} \cup \{\infty\}$}

    \Function{EstimateDistToMarking}{$\bm{s}, \hat{a}$}

    \If{$\hat{a} \in A^M$}
      \Return $1$
    \EndIf

    \LComment{各LTS上で，現在の状態から発火可能なアクションのうち，自己ループでないものの集合}
    \For{$j = 1, 2, \ldots, n$}
      \State $A^R_{E_j} \gets \{a \mid \exists s', (s_{E_j}, a, s') \in \Delta_{E_j}, s' \neq s_{E_j}\}$
    \EndFor
    \State $A^R \gets \bigcup_{j=1}^{n} A^R_{E_j}$ \Comment{Readyアクションの集合}

    \Return $\min_{a \in A^R \cup A^M}\{\textsc{CalculateGap}(\hat{a}, a) + \textsc{EstimateDistToMarking}(\bm{s}, a)\}$

    \EndFunction
  \end{algorithmic}
\end{algorithm}

以上により，RAは局所情報から，次にどのアクションを展開するのが有望かを推定する枠組みを提供する．
On-The-Fly探索側では，これらの推定値を用いて展開順序を制御することで，合成状態空間の全探索を避けつつ，目的を満たす制御器の発見を狙う．
\end{comment}

\chapter{Ready Abstractionの課題}
\label{chap:ready_abstraction_limitations}

前章で述べたように，Ready Abstraction（RA）は局所的に発火可能なアクション（Readyアクション）間の関係性を利用して，目標までの距離を推定するヒューリスティック手法である．
RAは，コンポーネント間の結合が疎であり，各コンポーネントが比較的自律的に目標へ遷移できるシステムにおいては強力なガイドとなる．

しかし，本研究が対象とするような，Markingアクションの発火に複数のコンポーネントによる厳密な同期が必要となるシステムにおいては，RAの推定精度と計算効率の両面で深刻な課題が生じる．
本章では，RAが抱える構造的な限界について，同期構造の無視による探索効率の低下と，Readyアクション探索に伴う計算コストの増大という2つの観点から分析する．

\section{同期構造に起因する近視眼的な探索}

RAの最大の特徴は，現在の合成状態において直ちに発火可能なアクション（Readyアクション）のみをノードとするグラフ上で距離計算を行う点にある．
この特性は，将来的に発生する同期イベントを適切に評価できないという欠点につながる．

\subsection{同期待ち時間の無視}

Markingアクション $a_m$ が同期アクションである場合，その発火には関与する全てのコンポーネントが $a_m$ を発火可能な状態に到達していなければならない．
しかし，あるコンポーネント $E_i$ が既に $a_m$ の直前状態に到達していても，他のコンポーネント $E_j$ がまだ準備できていなければ，システム全体として $a_m$ は実行できない．

RAの距離推定アルゴリズム（\aref{alg:estimate_dist}）は，現在のReadyアクション集合 $A^R$ を起点として，目標までの最短パスを探索する．
このとき，同期が必要なアクションへのパスは，パートナーの到着を待つための遷移（同期待ち）を含める必要があるため，RAのグラフ上では遠い，あるいは到達困難と判定されやすい．
対照的に，同期を必要とせず単独で進行でき，かつ局所的に目標に近い場所へ遷移できるアクションが存在する場合，RAはその見かけ上の近さを優先して評価する．

RAはこの他者の同期待ちという大域的な制約を軽視し，各コンポーネントが局所的な最短経路を選択し続けるような近視眼的な評価を下すため，結果として合流不可能な経路や，効率の悪い脇道状態を優先的に探索する結果となる．

\subsection{具体的な不適合例：金属加工システム}

RAが不適切な誘導を行う具体的なシナリオとして，\aref{fig:metal_processing_model}に示す金属加工システムのモデルを用いて説明する．

本システムは，加工プロセスを表す環境モデル（$E_\mathit{env}$）と，工程管理を行う要求モデル（$E_\mathit{req}$）の2つのコンポーネントから構成される．
目標は「出荷」アクションの発火（Markingアクション）である．
なお，説明を簡単にするため，本モデルに含まれる全てのアクションは制御可能（Controllable）であるとする．

環境モデルは，初期状態から「金属準備」を経て待機状態（状態1）へ遷移する．この状態1を起点として，2つの経路が存在する．
1つ目は「溶解」，「成形」，「冷却」を行い，再び待機状態に戻る加工サイクルである．
このサイクルは0回以上実行可能である．
2つ目は「研磨」や「皮膜」を施し，最後に「出荷」して初期状態に戻る仕上げ・出荷工程である．

要求モデルは，製品の品質担保のために「成形」が1度以上発火されることを強制する．
具体的には，初期状態（成形未実施，状態0）において「成形」を経ずに「出荷」アクションが発火された場合，未加工品の出荷とみなされ，違反状態$-1$（図下段の赤色ノード）へ遷移する．
「成形」が発火されると状態1（成形済み）へ遷移し，以降は「出荷」を行っても初期状態に戻るだけであり，違反にはならない．

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[shorten >=1pt, node distance=2.5cm, on grid, auto, >={Stealth}]

    % --- 環境モデル (Environment) ---
    \begin{scope}[yshift=0cm]
      \node[anchor=west] at (-3, 1) {\textbf{環境モデル} $E_\mathit{env}$};

      \node[state, initial, initial text=] (e0) {$0$};
      \node[state] (e1) [right=of e0] {$1$};
      \node[state] (e2) [right=of e1] {$2$};
      \node[state] (e3) [right=of e2] {$3$};
      \node[state] (e4) [below=of e1] {$4$};

      \path[->]
      (e0) edge node {\footnotesize 金属準備} (e1)
      (e1) edge node {\footnotesize 溶解} (e2)
      (e2) edge node {\footnotesize 成形} (e3)
      (e3) edge [bend left=45] node {\footnotesize 冷却} (e1)
      (e1) edge node [swap] {\footnotesize 研磨，皮膜} (e4)
      (e4) edge [bend left=45, orange] node {\footnotesize 出荷} (e0);
    \end{scope}

    % --- 要求モデル (Requirement) ---
    \begin{scope}[yshift=-4.5cm]
      \node[anchor=west] at (-3, 1) {\textbf{要求モデル} $E_\mathit{req}$};

      \node[state, draw=red, fill=red!15] (r-1) {$-1$};
      \node[state, initial, initial text=] (r0) [right=of r-1] {$0$};
      \node[state] (r1) [right=of r0] {$1$};

      \path[->]
      (r0) edge node {\footnotesize 成形} (r1)
      (r1) edge [loop right] node {\footnotesize 成形} ()
      (r0) edge [bend left=45, orange] node {\footnotesize 出荷} (r-1)
      (r1) edge [bend left=45, orange] node {\footnotesize 出荷} (r0);
    \end{scope}

  \end{tikzpicture}
  \caption{金属加工システムの環境モデルと要求モデル}
  \label{fig:metal_processing_model}
\end{figure}

\subsubsection{Ready Abstraction適用のためのMarked状態への変換}

RAは本来，Marked状態への到達を目的とする探索手法である．
一方，本問題の目標は「出荷」アクションの発火であるため，\aref{subsec:marking_to_marked}で述べた変換手法を適用し，アクションベースの目標を状態ベースの目標に置き換える必要がある．

\aref{fig:metal_processing_model_marked}は，変換後のシステム構成を示している．
ここでは，新たなコンポーネントとしてMarking判定モデル $E_M$ を導入している．
$E_M$は，「出荷」アクションが発火された直後のみMarked状態（状態1）に遷移し，それ以外の場合は非Marked状態（状態0）に留まる機能を持つ．
いわば，アクションの発火イベントを状態遷移として表現するためのモデルである．

この変換に伴い，既存の環境モデル $E_\mathit{env}$ および要求モデル $E_\mathit{req}$ においては，違反状態を除くすべての状態をMarked状態（図中の二重丸）として再定義する．
これにより，システム全体の並列合成状態がMarkedとなる（全てのコンポーネントが同時にMarked状態にある）ための条件は，実質的に$E_M$が状態1になること，すなわち直前に出荷アクションが発火したことと等価になる．

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[shorten >=1pt, node distance=2.5cm, on grid, auto, >={Stealth}]

    % --- 環境モデル (Environment) ---
    \begin{scope}[yshift=0cm]
      \node[anchor=west] at (-3, 1) {\textbf{環境モデル} $E_\mathit{env}$};

      \node[state, initial, initial text=, accepting] (e0) {$0$};
      \node[state, accepting] (e1) [right=of e0] {$1$};
      \node[state, accepting] (e2) [right=of e1] {$2$};
      \node[state, accepting] (e3) [right=of e2] {$3$};
      \node[state, accepting] (e4) [below=of e1] {$4$};

      \path[->]
      (e0) edge node {\footnotesize 金属準備} (e1)
      (e1) edge node {\footnotesize 溶解} (e2)
      (e2) edge node {\footnotesize 成形} (e3)
      (e3) edge [bend left=45] node {\footnotesize 冷却} (e1)
      (e1) edge node [swap] {\footnotesize 研磨，皮膜} (e4)
      (e4) edge [bend left=45] node {\footnotesize 出荷} (e0);
    \end{scope}

    % --- 要求モデル (Requirement) ---
    \begin{scope}[yshift=-4.5cm]
      \node[anchor=west] at (-3, 1) {\textbf{要求モデル} $E_\mathit{req}$};

      \node[state, draw=red, fill=red!15] (r-1) {$-1$};
      \node[state, initial, initial text=, accepting] (r0) [right=of r-1] {$0$};
      \node[state, accepting] (r1) [right=of r0] {$1$};

      \path[->]
      (r0) edge node {\footnotesize 成形} (r1)
      (r1) edge [loop right] node {\footnotesize 成形} ()
      (r0) edge [bend left=45] node {\footnotesize 出荷} (r-1)
      (r1) edge [bend left=45] node {\footnotesize 出荷} (r0);
    \end{scope}

    \begin{scope}[yshift=-7.5cm]
      \node[anchor=west] at (-3, 1.2) {\textbf{Marking判定モデル} $E_M$};

      \node[state, initial, initial text=] (m0) {$0$};
      \node[state, accepting] (m1) [right=3.5cm of m0] {$1$};

      \path[->]
      (m0) edge [loop below] node {\footnotesize $A_{E_\mathit{env}} \setminus \{\text{出荷}\}$} ()
      (m1) edge [bend left=20] node {\footnotesize $A_{E_\mathit{env}} \setminus \{\text{出荷}\}$} (m0)
      (m0) edge [bend left=20] node {\footnotesize 出荷} (m1)
      (m1) edge [loop below] node {\footnotesize 出荷} ();
    \end{scope}

  \end{tikzpicture}
  \caption{アクション目標を状態目標へ変換した金属加工システム}
  \label{fig:metal_processing_model_marked}
\end{figure}

\subsubsection{RAによる探索と失敗のプロセス}

前目で述べた変換後の金属加工システム（\aref{fig:metal_processing_model_marked}）に対し，RAを用いたOn-The-Fly探索を適用した場合の具体的な挙動を示す．
本モデルでは，$E_\mathit{env}$ と $E_\mathit{req}$ の全状態がMarkedと設定されているため，探索の主目的は Mark判定モデル $E_M$ を状態1（Marked）に遷移させること，すなわち「出荷」アクションを発火させることになる．

RAを用いた場合でも，最終的には適切な制御器が合成されるが，その過程で生じる非効率な探索挙動について以下に段階的に示す．

\begin{description}
  \descitem{Step 1: 初期状態からの遷移}
  初期状態 $\bm{s}_0 = (0, 0, 0)$ （順に $E_\mathit{env}, E_\mathit{req}, E_M$ の状態）において，発火可能なアクションは金属準備のみである．
  システムはこれを選択し，状態 $\bm{s}_1 = (1, 0, 0)$ へ遷移する．
  このとき，$E_\mathit{env}$ は状態1（分岐点）に進むが，$E_\mathit{req}$ と $E_M$ は金属準備に関与しないため状態0に留まる．

  \descitem{Step 2: RAによるヒューリスティック評価と誤った選択}
  状態 $\bm{s}_1$ において，RAは次に選択すべきアクションを決定する．
  この時点で局所的に発火可能なアクション（Readyアクション）の集合は，$A^R = \{\text{溶解}, \text{研磨}, \text{皮膜}, \text{成形}, \text{出荷}\}$ である．
  RAはこれらの候補について，目標（Marked状態）までの距離を推定する．

  \begin{description}
    \descitem{$E_\mathit{env}$ および $E_\mathit{req}$ の評価（差がつかない）}
    設定により全状態がMarkedであるため，現在の状態が既に目標状態であるとみなされる．したがって，これら2つのコンポーネントにおける距離推定値は1となり，アクション選択の差別化要因とならない．
    \descitem{$E_M$ およびReadyアクションを用いた評価（差が生じる）}
    $E_M$ が状態1（Marked）へ遷移するためには，「出荷」アクションの発火が不可欠である．
    RAは，現在のReadyアクション候補から「出荷」を発火可能にするまでの近さ（Gap）を評価する．
    \begin{description}
      \item[研磨・皮膜] $E_\mathit{env}$ において，これらのアクションを実行すると状態4へ遷移し，直ちに「出荷」が発火可能となる．したがって，「出荷」へのGapは共に1と評価される．
      \item[溶解] $E_\mathit{env}$ において，これを実行すると状態2へ遷移するが，その後「成形」「冷却」を経なければ「出荷」が可能な状態に戻らない．したがって，「出荷」へのGapは3と評価される．
    \end{description}
  \end{description}

  この結果，RAは「出荷」への到達コストが低い「研磨」および「皮膜」の2つを，同等に有望なアクションであると判断する．これらは「溶解」よりも優先度が高いため，探索アルゴリズムはまずこの2つのアクションのいずれか（例えば「研磨」）を選択し，状態 $\bm{s}_2 = (4, 0, 0)$ への遷移を行う．

  \descitem{Step 3: 経路の行き詰まりと繰り返される不要な探索}
  遷移後の状態 $\bm{s}_2 = (4, 0, 0)$ において，環境モデル上では出荷が可能である．
  しかし，要求モデル $E_\mathit{req}$ は依然として状態0（成形未実施）にある．
  この状態で出荷を発火すると，$E_\mathit{req}$ は違反状態（$-1$）へ遷移してしまうため，DCSの安全性制約によりこの遷移は禁止される．
  他に有効なアクションも存在しないため，この経路は探索の行き詰まりとなる．

  この結果，探索アルゴリズムはこの経路を破棄し，分岐点である状態 $\bm{s}_1$ までバックトラックを行う．
  しかし，RAのヒューリスティック評価では，残る候補である「皮膜」も「溶解」よりコストが低いと判定されている．
  そのため，アルゴリズムは「溶解」を選ぶ前に，もう一方の候補である「皮膜」の探索へ移行する．
  「皮膜」ルートも同様に同期待機ができず行き詰まりとなるため，再びバックトラックが発生する．

  このように，RAの誘導により2つの不要な経路を探索し尽くした後に，ようやく次善の候補であった「溶解」ルートの探索が開始される．
\end{description}

以上のプロセスにより，RAを用いた探索では，同期（$E_\mathit{req}$ の状態進行）の必要性を見抜けずに，局所的に目標アクション「出荷」へ近づきやすい経路を優先して探索する．
大規模なシステムにおいては，このような不要な探索とバックトラックが頻発し，計算リソースを著しく浪費する原因となる．

\section{Readyアクション探索による計算コストの増大}

RAのもう一つの課題は，ヒューリスティック値の計算自体のオーバーヘッドである．
前章の\aref{alg:estimate_dist}（\textsc{EstimateDist}）に示した通り，RAは距離を算出するために以下の処理を行う．

$$
  d \gets \min_{a \in A^R}\{\textsc{CalculateGap}(\bm{s}, \hat{a}, a) + \textsc{EstimateDist}(\bm{s}, a, s^*_{E_i})\}
$$

この式は，現在の合成状態における全てのReadyアクション $A^R$ に対して，遷移コスト（Gap）と再帰的な距離推定を行い，その最小値を求めることを意味している．
これは実質的に，探索の1ステップごとに，Readyアクションをノードとするグラフ上でダイクストラ法に近い最短経路探索を行っているに等しい．

システム規模が大きくなり，並列動作するコンポーネント数が増加すると，Readyアクション集合 $A^R$ のサイズは増大する．
DCSのOn-The-Fly探索では，数十万の状態を探索することが珍しくない．その全ての遷移において，この重い計算処理が走ることは，合成時間全体に対して無視できないペナルティとなる．

特に，前節で述べたように同期待ちが発生している状況では，有効なパスが見つからずに $A^R$ 全体を探索し尽くす最悪ケースの計算が発生しやすくなる．
すなわち，RAは探索中に迷いやすいだけでなく，その計算処理自体も重いという二重の課題を抱えていると言える．

\section{本章のまとめ}

本章では，Markingアクションを目標とする離散制御器合成において，従来のReady Abstractionが抱える課題を分析した．

第一の課題は同期の無視である．RAは局所的な最短経路を優先するため，同期のための準備動作よりも，単独で進行可能な近道を過剰評価する．これにより，パートナーの到着を待てずに脇道へ逸れる探索（不要な探索）が発生する．

第二の課題は計算コストである．RAは距離推定のためにReadyアクショングラフ上の探索を都度行うため，1ステップあたりの計算負荷が高く，大規模なシステムにおいて合成時間のボトルネックとなる．

これらの課題は，RAが動的なReady情報とその探索に依存しすぎていることに起因する．
次章では，これらの問題を解決するために，静的な構造情報である同期アクションまでの局所距離を活用し，計算コストを抑えつつ同期を強力に指向する新たな手法「Pre-Marking Direction」を提案する．

\chapter{Pre-Marking Direction}
\label{chap:pre_marking_direction}

\chapter{関連研究}
\label{chap:related_works}

\chapter{結論}
\label{chap:conclusion}

\section{本論文のまとめ}

\section{将来研究}

\appendix

\backmatter

\chapter{謝辞}

\bibliographystyle{jplain}
\bibliography{references}

\end{document}
