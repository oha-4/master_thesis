\documentclass[a4paper,11pt,oneside,openany,report,dvipdfmx]{jsbook}

\usepackage[left=30mm,right=30mm,top=25mm,bottom=25mm]{geometry}
\usepackage{cscover}
\usepackage{graphicx}
\usepackage[nobreak]{cite}
\usepackage[a4paper,dvipdfmx,pdfdisplaydoctitle=true,%
	bookmarks=true,bookmarksnumbered=true,bookmarkstype=toc,bookmarksopen=true%
]{hyperref}
\usepackage{pxjahyper}

\hypersetup{
  pdftitle={Pre-Markingアクションを用いたDirected Controller Synthesisの探索ヒューリスティック改善},
  pdfauthor={大畑允人}
}

\renewcommand{\headfont}{\bfseries}
\renewcommand{\bibname}{参考文献}
\setcounter{tocdepth}{2}
\pagestyle{plain}

\thesistype{修士論文}
\title{Pre-Markingアクションを用いた\\Directed Controller Synthesisの\\探索ヒューリスティック改善}
\author{大畑 允人}
\studentid{24M30552}
\affiliation{%
	東京科学大学\\
	情報理工学院\\
	情報工学コース
}
\date{2026年1月}

\supervisorname{指導教員}
\supervisor{鄭 顕志}

\usepackage{algorithm}
\usepackage[italicComments=false,indLines=false]{algpseudocodex}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{comment}
\usepackage{mathtools}
\usepackage{thmtools}
\usepackage{tikz}
\usepackage{todonotes}
\usepackage{prettyref}

\declaretheoremstyle[
	notefont=\mdseries, notebraces={（}{）},
	headpunct=．,
]{jstyle}
\declaretheorem[name=定義,style=jstyle]{definition}

\newcommand{\descitem}[1]{\item[#1]\mbox{}\\}

\usetikzlibrary{arrows.meta,automata,positioning}

\newrefformat{chap}{第\ref*{#1}章}
\newrefformat{sec}{第\ref*{#1}節}
\newrefformat{subsec}{第\ref*{#1}項}
\newrefformat{subsubsec}{第\ref*{#1}目}
\newrefformat{fig}{図\ref*{#1}}
\newrefformat{alg}{アルゴリズム\ref*{#1}}
\newcommand\aref[1]{\hyperref[#1]{\prettyref{#1}}}

\setuptodonotes{inline,backgroundcolor=red!15,bordercolor=red}
\newcommand{\memo}[1]{\todo[inline,backgroundcolor=green!15,bordercolor=green]{#1}}

\makeatletter

\renewcommand{\fps@algorithm}{htbp}
\renewcommand{\ALG@name}{アルゴリズム}
\renewcommand{\algorithmicrequire}{\textbf{入力：}}
\renewcommand{\algorithmicensure}{\textbf{出力：}}
\algrenewcommand\Return{\State\textbf{return} }
\algnewcommand\Break{\State\textbf{break}}
\algnewcommand\Continue{\State\textbf{continue}}

\makeatother

\begin{document}

\frontmatter

\maketitle

\chapter{概要}

\tableofcontents
\listoffigures
\listoftables

\mainmatter

\chapter{序論}

現代の社会インフラや産業システムにおいて，ソフトウェアが担う役割は拡大の一途をたどっている．
これらのシステムの多くは，離散的な状態と，その状態を遷移させる事象（アクション）の列によって振る舞いが記述される離散事象システム（Discrete Event System, DES）としてモデル化できる．
システムの高機能化・複雑化に伴い，システムが安全性や活性といった要求仕様を確実に満たすことを保証するのはますます困難になっており，設計段階における支援技術の重要性が高まっている．

本章では，離散事象システムとその制御に関する背景を述べ，本研究が取り組む課題と目的，および本論文の構成について概説する．

\section{離散事象システムと離散制御器合成}

離散事象システム（Discrete Event System, DES）は，離散的な状態空間を持ち，非同期に発生する事象によって状態遷移が引き起こされる動的システムである~\cite{DiscreteEventSystem}．
製造ラインの工程管理，ロボットの動作計画，通信プロトコル，組み込みシステムなど，その適用範囲は多岐にわたる．
こうしたシステムにおいて，危険な状態に到達しないというSafetyや，目的とするタスクを無限回完了できるというNon-Blockingを保証することは，システムの信頼性を確保する上で不可欠である．

従来，これらの要求を満たす制御ロジック（動作仕様）の設計は，熟練した設計者の経験則や，試行錯誤的な検証に依存していた．
しかし，並行して動作する複数のコンポーネントが複雑に相互作用するシステムにおいて，人間の直感だけで全ての境界条件や例外ケースを網羅し，デッドロックや禁止状態への到達を防ぐことは極めて困難である．
設計ミスは再設計のコストを増大させるだけでなく，運用時の重大な事故につながるリスクも孕んでいる．

この課題に対する解決策として，形式手法に基づき，与えられた環境モデルと要求仕様から正しい制御器を自動生成する離散制御器合成（Discrete Controller Synthesis）の研究が進められている~\cite{DiscreteControllerSynthesis}．
離散制御器合成は，環境の可能な振る舞いをすべて考慮した上で，制御可能なアクションを適切に許可・禁止することで，システムが常に仕様を満たすことを数学的に保証する．
特に，システム自身が能動的にアクションを選択してタスクを遂行する場合には，各状態で高々1つの制御アクションのみを選択するDirected Controllerの合成が有効である~\cite{DirectedController}．
このDirected Controllerを合成する技術をDirected Controller Synthesis（DCS）と呼ぶ~\cite{DirectedControllerSynthesis}．

しかし，DCSの実適用における最大の障壁は状態空間爆発問題である．
システムを構成するコンポーネント数が増加すると，合成後の状態空間は指数関数的に増大する．
これに対処するため，状態空間全体を事前に構築せず，初期状態から必要な部分のみを探索するOn-The-Fly探索手法や，探索を効率化するためのヒューリスティック技術が提案されてきた~\cite{Heuristic}．
特に，Ciolekらが提案したReady Abstraction（RA）~\cite{ReadyAbstraction}は，並列合成の構造を利用して目標までの距離を効率的に推定する強力なヒューリスティックであり，DCSの適用範囲を拡大させてきた．

\section{本論文の目的}

本論文の目的は，DCSにおけるOn-The-Fly探索の効率をさらに向上させるため，従来のReady Abstraction（RA）が抱える構造的な課題を解決する新たな探索指針であるPre-Marking Directionを提案することである．

従来のRAは，各コンポーネントにおいて局所的に発火可能なアクション（Readyアクション）の情報に基づいて目標までの距離を推定する．
しかし，この推定手法には以下の構造的な課題が存在する．

\begin{description}
  \descitem{同期構造を無視した到達可能性評価の限界}
  RAは，Readyアクションのみをノードとするグラフ上で距離を推定する．しかし，目標達成に特定のコンポーネント間の同期が不可欠な場合，現在はReadyアクションではないが将来的に同期を解放するために必要な予備アクションが評価から漏れる．その結果，同期ボトルネックを考慮しない近視眼的な経路選択が行われ，探索空間が不必要に拡大する．
  \descitem{Readyアクション探索に伴う計算負荷}
  RAは距離推定において，Readyアクション間の遷移コストやその先の距離を考慮し，再帰的に様々なパスを探索して最小値を計算する．この探索は，特にReadyアクションの数が多い場合に計算コストが増大し，1ステップごとの処理時間を長引かせる要因となる．
\end{description}

そこで本研究では，複雑なReadyアクショングラフの探索に依存せず，目標アクションの発火に不可欠な同期イベント（Pre-Markingアクション）を直接的な指針とする新たな距離推定手法を提案する．
具体的には，以下の項目に取り組む．

\begin{description}
  \descitem{Ready Abstractionの探索特性と課題の分析}
  Readyアクションを用いた距離推定が，同期を要するシステムにおいて近視眼的な挙動を示す原因と，それによって探索空間が不必要に拡大するメカニズムについて，具体的なモデルを用いて分析する．
  \descitem{Pre-Marking Directionの提案}
  目標アクションの発火に不可欠な同期アクションをPre-Markingアクション（PMA）として定義し，これを探索の指針とする新たなヒューリスティック手法Pre-Marking Direction（PMD）を提案する．
  PMDは，RAのような動的なReadyアクショングラフの探索を排除し，静的解析によって得られる各コンポーネント単体での距離情報を統合する軽量な計算手法を採用する．
  PMAが同期構造上の要所を捉えているため，この単純化された指標でも十分な探索性能を発揮でき，計算負荷を抑えつつ同期ボトルネックを考慮した高速な探索を実現する．
  \descitem{評価実験による有効性の検証}
  提案手法を実装し，ベンチマーク問題を用いて従来手法と比較することで，探索状態数や計算時間の削減効果を定量的に評価する．
\end{description}

本研究の成果は，より大規模で複雑なシステムの制御器合成を現実的な時間・メモリリソースで可能にし，高信頼なシステム開発の自動化に貢献するものである．

\section{本論文の構成}

本論文の構成は以下の通りである．

\aref{chap:background}「背景技術」では，本研究の基礎となる離散制御器合成およびDCSの理論的枠組み，On-The-Fly探索アルゴリズム，および既存のヒューリスティック手法であるReady Abstractionについて詳説する．

\aref{chap:ready_abstraction_limitations}「Ready Abstractionの課題」では，既存のRAが抱える構造的な限界について述べる．特に，Markingアクションの発火にコンポーネント間の同期が必要な状況において，現状態のReadyアクションのみに基づくRAの推定が機能せず，近視眼的な探索となり探索空間の爆発を招くメカニズムについて分析する．

\aref{chap:pre_marking_direction}「Pre-Marking Direction」では，本研究の中核となる提案手法について述べる．目標アクションの発火に必要な同期イベント（Pre-Markingアクション）を定義し，複雑なグラフ探索を行わずに各コンポーネント単体での距離情報のみを用いることで，同期を考慮した高精度な探索と，計算負荷の低い高速な推論を両立するアルゴリズムを示す．また，提案手法の適用による性能向上を実験により評価する．

\aref{chap:related_works}「関連研究」では，DCSの効率化やヒューリスティック探索に関する先行研究を概観し，本研究の位置づけを明確にする．

\aref{chap:conclusion}「結論」では，本論文の成果を総括し，今後の展望について述べる．

\chapter{背景技術}
\label{chap:background}

本章では，本研究の基盤となる離散制御器合成の概要，Directed Controller Synthesis（DCS）の定式化とOn-The-Fly探索アルゴリズム，およびReady Abstraction（RA）に基づくヒューリスティック関数について述べる．

\section{離散制御器合成}

離散制御器合成（Discrete Controller Synthesis）は，離散事象システム（Discrete Event System, DES）に対して，与えられた安全性などの制約を満たす制御器を自動的に構築する技術である~\cite{DiscreteControllerSynthesis}．
DESは有限状態オートマトン（あるいはLTS）の並列合成によってモデル化されるが，並列合成により得られる状態空間はコンポーネント数に対して指数的に増大しうる．
この指数的爆発は離散制御問題の解決を困難にし，現在も研究上の課題となっている．

制御器は，制御可能なアクションを動的に無効化しながら，制御不能なアクションを監視することで，システムの振る舞いを制限する．
一般のスーパバイザ制御では可能な限り多くの制御可能アクションを有効にする（最大許容）ことが求められることが多い．
しかし，制御器自身がアクションを能動的に実行するアクティブなコンポーネントとして振る舞う場合には，任意の時点で高々1つの制御可能アクションのみを選択する制御が適切となる．
このような制御器はDirected Controllerと呼ばれる~\cite{DirectedController}．

\subsection{ラベル付き遷移系}

本研究では，システムを構成する各コンポーネントをラベル付き遷移系（Labeled Transition System, LTS）としてモデル化する．
なお，本研究ではMarkingアクション（アクションベースの目標）を主に用いるが，既存研究ではMarked状態（状態ベースの目標）を用いることもある．
この両者を扱えるよう，LTSにはMarked状態集合とMarkingアクション集合の両方を持たせる（必要に応じて片方を空集合または全体集合として扱う）．

\begin{definition}[LTS]
  LTSは
  $E = (S_E, s_{E,0}, S^I_E, S^M_E, A_E, A^M_E, \Delta_E)$
  で表現される．
  $S_E$は有限の状態集合であり，$s_{E,0} \in S_E$は初期状態を表す．
  $S^I_E \subseteq S_E$は違反状態の集合であり，システムが到達してはならない状態を表す．
  $S^M_E \subseteq S_E$はMarked状態の集合である（RAや既存のDCS定式化で用いる）．
  $A_E = A^C_E \cup A^U_E$はアクション集合であり，$A^C_E$は制御可能アクション，$A^U_E$は制御不能アクションを表す．
  $A^M_E \subseteq A_E$はMarkingアクション集合である（本研究の定式化で用いる）．
  $\Delta_E \subseteq S_E \times A_E \times S_E$は遷移関係を表す．
\end{definition}

\begin{definition}[決定性]
  LTS $E$が決定的であるとは，任意の状態$s\in S_E$とアクション$a\in A_E$について，
  $(s,a,s_1)\in\Delta_E$かつ$(s,a,s_2)\in\Delta_E$ならば$s_1=s_2$が成り立つことをいう．
\end{definition}

本研究では，全てのLTSは決定的であると仮定する．

\begin{definition}[トレース]
  $\Delta_E$に従う状態とアクションの有限または無限の交互列
  $t = s_0, a_0, s_1, a_1, \ldots$
  をトレースと呼ぶ．
  ただし，各$i$について$(s_i, a_i, s_{i+1}) \in \Delta_E$が成り立つ．
  $E$上のトレースの集合を$T_E$で表す．
\end{definition}

\subsection{同期アクションと並列合成}

\begin{definition}[同期アクション]
  複数のLTS $E_1, \ldots, E_n$において，アクション$a$が2つ以上のコンポーネントのアクション集合に含まれるとき，
  $a$を同期アクションと呼ぶ．同期アクション集合$A^S$は
  $$
    A^S = \left\{a \in \bigcup_{i=1}^{n} A_{E_i} \;\middle|\; |\{i \mid a \in A_{E_i}\}| \geq 2\right\}
  $$
  と定義する．
\end{definition}

\begin{definition}[並列合成]
  LTS集合$\mathcal{E} = \{E_1,\ldots,E_n\}$の並列合成$E_\parallel = E_1 \parallel E_2 \parallel \cdots \parallel E_n$を$E_\parallel = (S_{E_\parallel}, s_{E_\parallel ,0}, S^I_{E_\parallel}, S^M_{E_\parallel}, A_{E_\parallel}, A^M_{E_\parallel}, \Delta_{E_\parallel})$
  として定義する．
  状態集合$S_{E_\parallel}=\prod_{i=1}^{n}S_{E_i}$は各コンポーネントの状態の直積であり，初期状態は$s_{E_\parallel,0}=(s_{E_1,0},\ldots,s_{E_n,0})$である．
  違反状態集合$S^I_{E_\parallel}$は，いずれかのコンポーネントが違反状態にある状態の集合$\{(s_1, \ldots, s_n) \in S_{E_\parallel} \mid \exists i . s_i \in S^I_{E_i}\}$として定義される．
  Marked状態集合は$S^M_{E_\parallel}=\prod_{i=1}^{n}S^M_{E_i}$，
  アクション集合$A_{E_\parallel}=\bigcup_{i=1}^{n}A_{E_i}$，
  Markingアクション集合$A^M_{E_\parallel}=\bigcup_{i=1}^{n}A^M_{E_i}$である．
  遷移関係$\Delta_{E_\parallel}$については，同期アクション$a \in A^S$は$a$を持つ全てのLTSで同時に発火し，非同期アクション$a \notin A^S$は$a$を持つLTSのみで発火する．
\end{definition}

並列合成には以下の特徴がある：
\begin{itemize}
  \item 同期アクションによりコンポーネント間の協調動作を実現できる
  \item 状態数$|S_{E_\parallel}|$はLTS数に対して指数的に増大しうる
\end{itemize}

\section{Directed Controller Synthesis}

本節では，Directed Controller Synthesis（DCS）の形式的定義と，On-The-Fly探索によるアルゴリズムについて述べる．

\subsection{制御可能性とDirected Controller}

アクションには制御可能なものと制御不能なものがある．
制御可能アクションは，制御器によって有効化・無効化が可能である．
一方，制御不能なアクションは環境によって発火されるため，発火し得る場合は全ての発火を考慮しなければならない．
各状態の制御可能なアクションのうち高々1つのみを有効にする制御器を合成することで，システム全体の振る舞いを制御する．
このような制御器をDirected Controllerと呼ぶ．

\begin{definition}[Directed Controller]
  並列合成LTS $E_\parallel$に対する制御器が以下の条件を満たすとき，Directed Controllerと呼ぶ：
  \begin{description}
    \item[Controllable]
          すべての制御不能アクションを常に有効化する
    \item[Directed]
          各状態で高々1つの制御可能アクションのみを有効化する
    \item[Eager]
          Marked状態，またはMarkingアクション発火後の状態において，制御可能アクションのみ存在する場合，必ず1つを選択する
  \end{description}
\end{definition}

\subsection{制御問題}

既存のDCSでは，タスク完了などを表すMarked状態への到達可能性に基づいてNon-Blocking性を定義することがある．
本研究のMarkingアクションベース定式化との関係は\aref{subsec:marking_to_marked}で述べる．
また，本研究では，目標を状態ではなくMarkingアクション$A^M$の発火として与える．

\begin{definition}[Directed Controllerの制御問題]
  LTSの組$\bm{E}=(E_1,\ldots,E_n)$に対し，解は以下を満たすDirected Controllerである：
  \begin{description}
    \item[Safety]
          制御下のシステムが違反状態に到達しない
    \item[Non-Blocking]
          Marked状態への到達，またはMarkingアクションの発火を無限回行える
  \end{description}
\end{definition}

\subsection{MarkingアクションからMarked状態への変換}
\label{subsec:marking_to_marked}

本研究では，目標を特定の状態への到達ではなく，Markingアクション集合 $A^M$ のいずれかの要素が発火することとして定義する．既存のReady Abstraction (RA) の枠組みは状態ベースの目標を想定しているため，アクションベースの目標を状態ベースに変換するためのLTS $E_M$ を導入し，他のコンポーネントの設定を調整する．

合成対象のコンポーネント集合を $\mathcal{E} = \{E_1, \dots, E_n\}$ とし，全コンポーネントのアクション集合の和を $A = \bigcup_{i=1}^n A_{E_i}$ とする．このとき，Markingアクションの発生を状態として保持するMarking判定LTS $E_M = (S_{E_M}, s_{E_M,0}, S^I_{E_M}, S^M_{E_M}, A_{E_M}, A^M_{E_M}, \Delta_{E_M})$ を以下のように定義する：

\begin{itemize}
  \item $S_{E_M} = \{0, 1\}$, $s_{E_M,0} = 0$, $S^I_{E_M} = \emptyset$, $S^M_{E_M} = \{1\}$
  \item $A_{E_M} = A$ （同期のために全アクションをアルファベットに含める）
  \item 遷移関係 $\Delta_{E_M}$：
        \begin{itemize}
          \item 任意の $a \in A^M$ に対し，$(0, a, 1) \in \Delta_{E_M}$ および $(1, a, 1) \in \Delta_{E_M}$
          \item 任意の $a \notin A^M$ に対し，$(0, a, 0) \in \Delta_{E_M}$ および $(1, a, 0) \in \Delta_{E_M}$
        \end{itemize}
\end{itemize}

さらに，並列合成 $E_\parallel = E_1 \parallel \dots \parallel E_n \parallel E_M$ において目標達成の判定を $E_M$ に一任するため，他のすべてのコンポーネント $E_i \in \{E_1, \dots, E_n\}$ について，そのMarked状態集合を $S^M_{E_i} = S_{E_i}$ （全状態をMarkedとする）へ再定義する．

この変換により，合成システム $E_\parallel$ がMarked状態にあることは，$E_M$ が状態 $1$ にあることと等価になる．$E_M$ は直前に実行されたアクションが $A^M$ に属する場合のみ状態 $1$ に遷移するため，このMarked状態を無限回訪問することは，元のシステムにおいてMarkingアクションを無限回発火し続けるNon-blockingな振る舞いと完全に一致する．

\subsection{On-The-Fly探索アルゴリズム}

従来のアプローチでは，まずオートマトンを完全に合成し，その後で制御問題を解く．
しかし，この方法は指数的な状態空間爆発を引き起こす可能性がある．
Ciolekらは，この課題に対し，ヒューリスティック関数に導かれたOn-The-Fly探索により，状態空間の一部のみを探索してDirected Controllerを発見するアルゴリズムを提案した~\cite{DirectedControllerSynthesis}．
ヒューリスティック関数は，各状態から目標までの推定距離を計算することで，有望な探索経路を優先的に選択する手法であり~\cite{Heuristic}，DCSにおいても探索効率の向上に重要な役割を果たす．

On-The-Fly探索は，状態空間全体を事前に構築することなく，初期状態から到達可能な必要な部分のみを段階的に展開しながら制御器を合成する手法である．
この手法は，主に以下の3つのプロセスから構成される．

\begin{enumerate}
  \item \textbf{展開（Expansion）}:
        現在の探索フロンティアから，ヒューリスティック関数（例えばRA）を用いて最も有望な未探索の遷移を選択し，探索グラフに追加する（\textsc{ExpandNext}）．これにより，Marked状態への到達可能性が高い経路を優先的に探索する．
  \item \textbf{伝播（Propagation）}:
        ある状態が\textit{Goals}（勝利状態）または\textit{Errors}（敗北状態）であることが確定した場合，その情報を探索グラフの逆方向（親状態）へ伝播させる（\textsc{PropagateGoal}, \textsc{PropagateError}）．
        状態の分類は以下の論理に基づき決定される：
        \begin{itemize}
          \item \textbf{Goalsへの伝播}：
                ある状態から制御可能な遷移によって少なくとも1つの\textit{Goals}状態へ到達可能であるか，あるいはその状態から発生しうる全ての制御不能な遷移の先が\textit{Goals}である場合，その状態は\textit{Goals}となる．
          \item \textbf{Errorsへの伝播}：
                ある状態から発生しうる全ての制御可能な遷移の先が\textit{Errors}かつ制御不能な遷移によって少なくとも1つの\textit{Errors}状態へ到達可能である場合，その状態は\textit{Errors}となる．
        \end{itemize}
  \item \textbf{閉路検出と判定（Loop Detection）}:
        探索中に新たな閉路が形成された場合，その閉路がNon-Blockingを満たすか否かを判定する．
        Markingアクションを含む閉路などの「勝利閉路」が見つかれば，その閉路上の状態は\textit{Goals}となり，逆にMarkingアクションを含まず脱出不可能な閉路は\textit{Errors}となる．
\end{enumerate}

探索は初期状態が\textit{Goals}または\textit{Errors}に分類されるまで継続される．初期状態が\textit{Goals}に分類された場合，探索グラフから有効な部分グラフを抽出することで制御器が得られる．逆に\textit{Errors}に分類された場合は，制御器の合成は不可能であると結論付けられる．

\begin{algorithm}
  \caption{On-The-Fly探索によるDirected Controller Synthesis}
  \label{alg:dcs}
  \begin{algorithmic}[1]
    \Require{全てのLTSの組 $\bm{E} = (E_1, \ldots, E_n)$，ヒューリスティック関数 $H$}
    \Ensure{Directed Controller $C$ または 合成不可能}

    \Function{DirectedControllerSynthesis}{$\bm{E}, H$}

    \State $\mathit{ES} \gets$初期状態$\bm{s}_0$のみを持つ部分探索グラフ
    \State $\mathit{Goals} \gets \emptyset, \mathit{Errors} \gets \emptyset, \mathit{None} \gets \{\bm{s}_0\}$

    \Statex

    \LComment{探索ループ：初期状態が未分類状態でなくなるまで}
    \While{$\bm{s}_0 \notin (\mathit{Goals} \cup \mathit{Errors})$}
      \State $(\bm{s}, a, \bm{s}') \gets \textsc{ExpandNext}(\mathit{ES}, H)$ \Comment{ヒューリスティックによる次遷移の選択}
      \State $\mathit{ES} \gets \mathit{ES} \cup \{(\bm{s}, a, \bm{s}')\}$ \Comment{探索グラフの更新}

      \Statex
      \If{$\bm{s}' \in \mathit{Errors}$}
        \State $\mathit{Errors} \gets \mathit{Errors} \cup \{\bm{s}'\}$
        \State $\textsc{PropagateError}(\bm{s}')$ \Comment{敗北状態の伝播}
      \ElsIf{$\bm{s}' \in \mathit{Goals}$}
        \State $\mathit{Goals} \gets \mathit{Goals} \cup \{\bm{s}'\}$
        \State $\textsc{PropagateGoal}(\bm{s}')$ \Comment{勝利状態の伝播}
      \ElsIf{$\bm{s}'$ が新しいループを形成する}
        \State $\mathit{Loop} \gets \textsc{GetLoop}(\bm{s}, \bm{s}')$
        \If{$\mathit{Loop}$ が勝利条件を満たす}
          \State $\mathit{newGoals} \gets \textsc{FindNewGoals}(\mathit{Loop})$
          \State $\mathit{Goals} \gets \mathit{Goals} \cup \mathit{newGoals}$
          \State $\textsc{PropagateGoal}(\mathit{newGoals})$
        \Else
          \State $\mathit{newErrors} \gets \textsc{FindNewErrors}(\mathit{Loop})$
          \State $\mathit{Errors} \gets \mathit{Errors} \cup \mathit{newErrors}$
          \State $\textsc{PropagateError}(\mathit{newErrors})$
        \EndIf
      \EndIf
    \EndWhile

    \Statex

    \If{$s_0 \in \mathit{Goals}$}
      \State $C \gets \textsc{ExtractController}(\mathit{ES}, \mathit{Goals})$
      \Return $C$
    \Else
      \Return 合成不可能
    \EndIf

    \EndFunction

  \end{algorithmic}
\end{algorithm}

\section{Ready Abstraction}

Ready Abstraction（RA）~\cite{ReadyAbstraction}は，並列合成構造を活用して，Marked状態への到達に必要なステップ数を多項式時間で推定するヒューリスティック手法である．
各コンポーネントの局所情報のみを用いて距離を推定することで状態空間爆発を回避しつつ，On-The-Fly探索における次遷移選択（\textsc{ExpandNext}）を導く．

RAの基本的な着想は，合成状態 $\bm{s} = (s_{E_1}, s_{E_2}, \ldots, s_{E_n})$ の周辺で局所的に発火可能なアクション（Readyアクション）を集め，それらの間に，あるアクションの実行が別のアクションの実行可能性を高めるという関係を仮想的に張ったグラフ上で最短路を解くことで，目標（Marked状態）までの距離を見積もる点にある．
この手法は，プランニング問題におけるヒューリスティック探索の一般的な枠組み~\cite{Heuristic}を，並列合成されたDESの構造に適合させたものと位置づけられる．
同期制約のため，局所的に発火可能（Ready）であっても合成状態全体では直ちに発火できない場合があるが，RAはこの差を局所到達可能性とグラフ探索に基づいて保守的に見積もる．

\subsection{展開対象のアクションの評価}

\aref{alg:ra_heuristic}は，現在の合成状態 $\bm{s}$ において展開対象のアクション $\hat{a}$ を選ぶことがどれだけ目標に近いかを評価するためのヒューリスティック関数である．
評価は各コンポーネント $E_i$ ごとに $(\mathrm{rank}, d)$ の形で返され，rank は距離推定に用いる目標集合の優先度を表す．

本章で示すRAの記述では，探索中にすでに到達したMarked状態集合 $\bm{S}^M$ を基準にした距離（Rank 0）を優先する．
これは，探索が進むほど既知の到達済み領域へ近づく選択を上位に扱うことで，任意のMarked状態を一様に目指す場合に比べて探索が過度に広がることを避け，探索空間を抑制できるという見込みに基づく．
Rank 0での推定が不可能な場合に限り，任意のMarked状態への距離（Rank 1）を用いる．
どちらも不可能と推定された場合は $(2,\infty)$ を返す．

\begin{algorithm}
  \caption{Ready Abstractionによるヒューリスティック関数}
  \label{alg:ra_heuristic}
  \begin{algorithmic}[1]
    \Require{%
      全てのLTSの組 $\bm{E} = (E_1, E_2, \ldots, E_n)$， \\
      探索到達済みのMarked状態の集合 $\bm{S}^M \subseteq S^M_{E_1} \times S^M_{E_2} \times \cdots \times S^M_{E_n}$， \\
      各LTSにおける状態の組 $\bm{s} = (s_{E_1}, s_{E_2}, \ldots, s_{E_n})$， \\
      展開対象のアクション $\hat{a}$
    }
    \Ensure{%
      各LTSにおける距離の降順の組 $\bm{d} = (\bm{d}_1, \bm{d}_2, \ldots, \bm{d}_n)$ \\
      ただし，$\bm{d}_i \in \{(0, d), (1, d), (2, \infty) \mid d \in \mathbb{N}\}$ \\
      各LTSにおける距離の意味は以下の通り： \\
      $(0, d)$：次にアクション$\hat{a}$を発火して$d$ステップで探索到達済みのMarked状態に到達可能 \\
      $(1, d)$：次にアクション$\hat{a}$を発火して$d$ステップでMarked状態に到達可能 \\
      $(2, \infty)$：Marked状態に到達不可能
    }

    \Function{ReadyAbstractionHeuristic}{$\bm{E}, \bm{S}^M, \bm{s}, \hat{a}$}

    \For{$i = 1, 2, \ldots, n$}
      \State $\mathit{minSteps} \gets \infty$

      \Statex

      \LComment{Rank 0: 探索到達済みのMarked状態への到達可能性確認}
      \ForAll{$(s^*_{E_1}, s^*_{E_2}, \ldots, s^*_{E_n}) \in \bm{S}^M$}
        \State $\mathit{steps} \gets \textsc{EstimateDist}(\bm{s}, \hat{a}, s^*_{E_i})$
        \If{$\mathit{steps} < \mathit{minSteps}$}
          $\mathit{minSteps} \gets \mathit{steps}$
        \EndIf
      \EndFor
      \If{$\mathit{minSteps} \ne \infty$} \Comment{いずれかの探索到達済みのMarked状態に到達可能な場合}
        \State $\bm{d}_{E_i} \gets (0, minSteps)$
        \Continue
      \EndIf

      \Statex

      \LComment{Rank 1: 任意のMarked状態への到達可能性確認}
      \ForAll{$s^*_{E_i} \in S^M_{E_i}$}
        \State $\mathit{steps} \gets \textsc{EstimateDist}(\bm{s}, \hat{a}, s^*_{E_i})$
        \If{$\mathit{steps} < \mathit{minSteps}$}
          $\mathit{minSteps} \gets \mathit{steps}$
        \EndIf
      \EndFor

      \If{$\mathit{minSteps} \ne \infty$} \Comment{いずれかのMarked状態に到達可能な場合}
        \State $\bm{d}_{E_i} \gets (1, minSteps)$
      \Else
        \State $\bm{d}_{E_i} \gets (2, \infty)$
      \EndIf
    \EndFor

    \Statex

    \Return $\textsc{SortDescending}((\bm{d}_{E_1}, \bm{d}_{E_2}, \ldots, \bm{d}_{E_n}))$
    \Comment{距離を辞書式降順でソートして返す}

    \EndFunction
  \end{algorithmic}
\end{algorithm}

\aref{alg:ra_heuristic}の戻り値は各コンポーネントの距離推定の組であるが，実際の探索（\textsc{ExpandNext}）においてアクション $\hat{a}$ を選択する際は，以下の優先順位に従って順位付けを行う：

\begin{enumerate}
  \item \textbf{制御不能アクションの優先}：$\hat{a} \in A^U$ であるアクションを，全ての制御可能アクション $\hat{a} \in A^C$ よりも優先する．
  \item \textbf{辞書式順序による比較}：アクションの属性が同じ（共に制御可能，あるいは共に制御不能）である場合，\aref{alg:ra_heuristic}が返す距離の組 $\bm{d}$ を辞書式に比較し，値が小さい（より目標に近いと推定される）ものを優先する．
\end{enumerate}

制御不能アクションを最優先するのは，環境側で発生しうる全ての振る舞いを早期に探索し，反例（違反状態やデッドロック）を迅速に検出するためである．

\subsection{距離推定の中核}

Ready Abstractionにおける距離推定の手続きを\aref{alg:estimate_dist}に示す．
この関数 $\textsc{EstimateDist}$ は，現在の合成状態 $\bm{s}$，評価対象のアクション $\hat{a}$，および目標状態 $s^*_{E_i}$ を入力とし，推定距離 $d$ を算出する．

本アルゴリズムでは，推定のために以下の2つの補助関数を利用する．

\begin{description}
  \descitem{\textnormal{$\textsc{CalculateDist}(s, a)$}}
  LTS単体において，状態 $s$ からアクション $a$ へ到達するための最短ステップ数．
  この値は探索中頻繁に参照されるため，効率化の観点から，探索開始前にすべての状態とアクションの組について幅優先探索により算出されている．

  \descitem{\textnormal{$\textsc{CalculateGap}(\bm{s}, \hat{a}, a)$}}
  現在の合成状態 $\bm{s}$ において，アクション $\hat{a}$ の実行後に別のアクション $a$ を実行可能にするために必要な最小ステップ数（切り替えコスト）．
  これは動的な状態に依存するため，探索中に都度計算される．
\end{description}

RAは，現在の状態で発火可能なReadyアクション集合 $A^R$ を対象に，そこへ至る遷移コスト（Gap）とその先の局所距離（Dist）の和が最小となる経路を探索する．
これにより，単なる最短距離ではなく，同期のための待機やアクションの切り替えコストを含んだ，より実質的な到達距離を推定している．

\begin{algorithm}
  \caption{Ready Abstractionにおける距離推定関数}
  \label{alg:estimate_dist}
  \begin{algorithmic}[1]
    \Require{%
      現在の状態 $\bm{s} = (s_{E_1}, \ldots, s_{E_n})$， \\
      評価対象のアクション $\hat{a}$， \\
      距離を推定する対象の状態 $s^*_{E_i}$
    }
    \Ensure{推定距離 $d \in \mathbb{N} \cup \{\infty\}$}

    \Function{EstimateDist}{$\bm{s}, \hat{a}, s^*_{E_i}$}

    \If{$\hat{a} \in A_{E_i}$} \Comment{$\hat{a}$ がLTS $E_i$ に存在している場合}
      \State $s'_{E_i} \gets s' \text{ where } (s_{E_i}, \hat{a}, s') \in \Delta_{E_i}$ \Comment{$\hat{a}$ を発火した後の状態}
      \If{$s'_{E_i} = s^*_{E_i}$} \Comment{対象の状態に到達する場合}
        \Return $1$
      \ElsIf{$s'_{E_i} \in S^I_{E_i}$} \Comment{違反状態に到達する場合}
        \Return $\infty$
        \Comment{距離を無限と推定し，Marked状態に到達不可能であることを表す}
      \ElsIf{$s'_{E_i} \ne s_{E_i}$} \Comment{他の状態に遷移する場合}
        \Return $\textsc{CalculateDist}(s'_{E_i}, s^*_{E_i}) + 1$
      \EndIf
    \ElsIf{$s_{E_i} = s^*_{E_i}$} \Comment{$\hat{a}$で遷移が発生せず，すでに対象の状態の場合}
      \Return $1$
    \EndIf

    \Statex

    \LComment{各LTS上で，現在の状態から発火可能なアクションのうち，自己ループでないものの集合}
    \For{$j = 1, 2, \ldots, n$}
      \State $A^R_{E_j} \gets \{a \mid \exists s', (s_{E_j}, a, s') \in \Delta_{E_j}, s' \neq s_{E_j}\}$
    \EndFor
    \State $A^R \gets \bigcup_{j=1}^{n} A^R_{E_j}$ \Comment{Readyアクションの集合}

    \Statex

    \LComment{Gapを加味した最短経路探索}
    \State $d \gets \min_{a \in A^R}\{\textsc{CalculateGap}(\bm{s}, \hat{a}, a) + \textsc{EstimateDist}(\bm{s}, a, s^*_{E_i})\}$
    \LComment{この再帰的な最小値問題は，実装上はダイクストラ法により効率的に解かれる}

    \If{$d = \infty$} \Comment{Readyアクションを用いて距離を推定できない場合}
      \State $d \gets \textsc{CalculateDist}(s_{E_i}, s^*_{E_i}) + 1$
    \EndIf

    \Return $d$

    \EndFunction
  \end{algorithmic}
\end{algorithm}

ここで用いられる \textsc{CalculateGap}$(\hat{a}, a)$ は，アクション間の切り替えのしやすさを表すコストであり，既存研究における定義に従い，あるコンポーネント内でアクション $\hat{a}$ を経て $a$ へ至る最短パスの長さ（から1を引いた値）として計算される．

以上により，RAは局所情報から，次にどのアクションを展開するのが有望かを推定する枠組みを提供する．
On-The-Fly探索側では，これらの推定値を用いて展開順序を制御することで，合成状態空間の全探索を避けつつ，目的を満たす制御器の発見を狙う．

\begin{comment}
\subsection{Markingアクションまでの距離推定}

RAは，Marked状態への到達距離を推定する枠組みとして提案されている．
一方，本研究では目標をMarkingアクションの発火として定式化するため，RAを本研究の目的関数と同じ観点で比較するには，Marked状態ではなくMarkingアクションまでの距離をどのように見積もるかを明示しておく必要がある．
そこで本節では，Markingアクション集合 $A^M$ に対する距離推定手続きとして\textsc{EstimateDistToMarking}を示す．

\textsc{EstimateDistToMarking}は，候補アクション$\hat{a}$がMarkingアクションであれば距離1を返し，そうでなければ，合成状態$\bm{s}$から（同期を無視すれば）状態を変化させ得るアクション集合$A^R$を介して，Gapとその先での推定距離の和の最小値を再帰的に求める．
構造は\aref{alg:estimate_dist}（\textsc{EstimateDist}）と同型であり，終端条件がMarked状態ではなくMarkingアクションになっている点が相違である．

なお，\textsc{EstimateDistToMarking}は，探索到達済みMarked状態集合$\bm{S}^M$を基準とするRank 0の推定が利用できない状況，特に$\bm{S}^M=\emptyset$の場合に用いることを想定している．


\begin{algorithm}
  \caption{Ready AbstractionにおけるMarkingアクションまでの距離推定}
  \begin{algorithmic}[1]
    \Require{%
      現在の状態 $\bm{s} = (s_{E_1}, \ldots, s_{E_n})$， \\
      候補のアクション $\hat{a}$
    }
    \Ensure{推定距離 $d \in \mathbb{N} \cup \{\infty\}$}

    \Function{EstimateDistToMarking}{$\bm{s}, \hat{a}$}

    \If{$\hat{a} \in A^M$}
      \Return $1$
    \EndIf

    \LComment{各LTS上で，現在の状態から発火可能なアクションのうち，自己ループでないものの集合}
    \For{$j = 1, 2, \ldots, n$}
      \State $A^R_{E_j} \gets \{a \mid \exists s', (s_{E_j}, a, s') \in \Delta_{E_j}, s' \neq s_{E_j}\}$
    \EndFor
    \State $A^R \gets \bigcup_{j=1}^{n} A^R_{E_j}$ \Comment{Readyアクションの集合}

    \Return $\min_{a \in A^R \cup A^M}\{\textsc{CalculateGap}(\hat{a}, a) + \textsc{EstimateDistToMarking}(\bm{s}, a)\}$

    \EndFunction
  \end{algorithmic}
\end{algorithm}

以上により，RAは局所情報から，次にどのアクションを展開するのが有望かを推定する枠組みを提供する．
On-The-Fly探索側では，これらの推定値を用いて展開順序を制御することで，合成状態空間の全探索を避けつつ，目的を満たす制御器の発見を狙う．
\end{comment}

\chapter{Ready Abstractionの課題}
\label{chap:ready_abstraction_limitations}

前章で述べたように，Ready Abstraction（RA）は局所的に発火可能なアクション（Readyアクション）間の関係性を利用して，目標までの距離を推定するヒューリスティック手法である．
RAは，コンポーネント間の結合が疎であり，各コンポーネントが比較的自律的に目標へ遷移できるシステムにおいては強力なガイドとなる．

しかし，本研究が対象とするような，Markingアクションの発火に複数のコンポーネントによる厳密な同期が必要となるシステムにおいては，RAの推定精度と計算効率の両面で深刻な課題が生じる．
本章では，RAが抱える構造的な限界について，同期構造の無視による探索効率の低下と，Readyアクション探索に伴う計算コストの増大という2つの観点から分析する．

\section{同期構造に起因する近視眼的な探索}

RAの最大の特徴は，現在の合成状態において直ちに発火可能なアクション（Readyアクション）のみをノードとするグラフ上で距離計算を行う点にある．
この特性は，将来的に発生する同期イベントを適切に評価できないという欠点につながる．

\subsection{同期待ち時間の無視}

Markingアクション $a_m$ が同期アクションである場合，その発火には関与する全てのコンポーネントが $a_m$ を発火可能な状態に到達していなければならない．
しかし，あるコンポーネント $E_i$ が既に $a_m$ の直前状態に到達していても，他のコンポーネント $E_j$ がまだ準備できていなければ，システム全体として $a_m$ は実行できない．

RAの距離推定アルゴリズム（\aref{alg:estimate_dist}）は，現在のReadyアクション集合 $A^R$ を起点として，目標までの最短パスを探索する．
このとき，同期が必要なアクションへのパスは，パートナーの到着を待つための遷移（同期待ち）を含める必要があるため，RAのグラフ上では遠い，あるいは到達困難と判定されやすい．
対照的に，同期を必要とせず単独で進行でき，かつ局所的に目標に近い場所へ遷移できるアクションが存在する場合，RAはその見かけ上の近さを優先して評価する．

RAはこの他者の同期待ちという大域的な制約を軽視し，各コンポーネントが局所的な最短経路を選択し続けるような近視眼的な評価を下すため，結果として合流不可能な経路や，効率の悪い脇道状態を優先的に探索する結果となる．

\subsection{具体的な不適合例：金属加工システム}
\label{subsec:ra_metal_processing_example}

RAが不適切な誘導を行う具体的なシナリオとして，\aref{fig:metal_processing_model}に示す金属加工システムのモデルを用いて説明する．

本システムは，加工プロセスを表す環境モデル（$E_\mathit{env}$）と，工程管理を行う要求モデル（$E_\mathit{req}$）の2つのコンポーネントから構成される．
目標は「出荷」アクションの発火（Markingアクション）である．
なお，説明を簡単にするため，本モデルに含まれる全てのアクションは制御可能（Controllable）であるとする．

環境モデルは，初期状態から「金属準備」を経て待機状態（状態1）へ遷移する．この状態1を起点として，2つの経路が存在する．
1つ目は「溶解」，「成形」，「冷却」を行い，再び待機状態に戻る加工サイクルである．
このサイクルは0回以上実行可能である．
2つ目は「研磨」や「皮膜」を施し，最後に「出荷」して初期状態に戻る仕上げ・出荷工程である．

要求モデルは，製品の品質担保のために「成形」が1度以上発火されることを強制する．
具体的には，初期状態（成形未実施，状態0）において「成形」を経ずに「出荷」アクションが発火された場合，未加工品の出荷とみなされ，違反状態$-1$（図下段の赤色ノード）へ遷移する．
「成形」が発火されると状態1（成形済み）へ遷移し，以降は「出荷」を行っても初期状態に戻るだけであり，違反にはならない．

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[shorten >=1pt, node distance=2.5cm, on grid, auto, >={Stealth}]

    % --- 環境モデル (Environment) ---
    \begin{scope}[yshift=0cm]
      \node[anchor=west] at (-3, 1) {\textbf{環境モデル} $E_\mathit{env}$};

      \node[state, initial, initial text=] (e0) {$0$};
      \node[state] (e1) [right=of e0] {$1$};
      \node[state] (e2) [right=of e1] {$2$};
      \node[state] (e3) [right=of e2] {$3$};
      \node[state] (e4) [below=of e1] {$4$};

      \path[->]
      (e0) edge node {\footnotesize 金属準備} (e1)
      (e1) edge node {\footnotesize 溶解} (e2)
      (e2) edge node {\footnotesize 成形} (e3)
      (e3) edge [bend left=45] node {\footnotesize 冷却} (e1)
      (e1) edge node [swap] {\footnotesize 研磨，皮膜} (e4)
      (e4) edge [bend left=45, orange] node {\footnotesize 出荷} (e0);
    \end{scope}

    % --- 要求モデル (Requirement) ---
    \begin{scope}[yshift=-4.5cm]
      \node[anchor=west] at (-3, 1) {\textbf{要求モデル} $E_\mathit{req}$};

      \node[state, draw=red, fill=red!15] (r-1) {$-1$};
      \node[state, initial, initial text=] (r0) [right=of r-1] {$0$};
      \node[state] (r1) [right=of r0] {$1$};

      \path[->]
      (r0) edge node {\footnotesize 成形} (r1)
      (r1) edge [loop right] node {\footnotesize 成形} ()
      (r0) edge [bend left=45, orange] node {\footnotesize 出荷} (r-1)
      (r1) edge [bend left=45, orange] node {\footnotesize 出荷} (r0);
    \end{scope}

  \end{tikzpicture}
  \caption{金属加工システムの環境モデルと要求モデル}
  \label{fig:metal_processing_model}
\end{figure}

\subsubsection{Ready Abstraction適用のためのMarked状態への変換}

RAは本来，Marked状態への到達を目的とする探索手法である．
一方，本問題の目標は「出荷」アクションの発火であるため，\aref{subsec:marking_to_marked}で述べた変換手法を適用し，アクションベースの目標を状態ベースの目標に置き換える必要がある．

\aref{fig:metal_processing_model_marked}は，変換後のシステム構成を示している．
ここでは，新たなコンポーネントとしてMarking判定モデル $E_M$ を導入している．
$E_M$は，「出荷」アクションが発火された直後のみMarked状態（状態1）に遷移し，それ以外の場合は非Marked状態（状態0）に留まる機能を持つ．
いわば，アクションの発火イベントを状態遷移として表現するためのモデルである．

この変換に伴い，既存の環境モデル $E_\mathit{env}$ および要求モデル $E_\mathit{req}$ においては，違反状態を除くすべての状態をMarked状態（図中の二重丸）として再定義する．
これにより，システム全体の並列合成状態がMarkedとなる（全てのコンポーネントが同時にMarked状態にある）ための条件は，実質的に$E_M$が状態1になること，すなわち直前に出荷アクションが発火したことと等価になる．

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[shorten >=1pt, node distance=2.5cm, on grid, auto, >={Stealth}]

    % --- 環境モデル (Environment) ---
    \begin{scope}[yshift=0cm]
      \node[anchor=west] at (-3, 1) {\textbf{環境モデル} $E_\mathit{env}$};

      \node[state, initial, initial text=, accepting] (e0) {$0$};
      \node[state, accepting] (e1) [right=of e0] {$1$};
      \node[state, accepting] (e2) [right=of e1] {$2$};
      \node[state, accepting] (e3) [right=of e2] {$3$};
      \node[state, accepting] (e4) [below=of e1] {$4$};

      \path[->]
      (e0) edge node {\footnotesize 金属準備} (e1)
      (e1) edge node {\footnotesize 溶解} (e2)
      (e2) edge node {\footnotesize 成形} (e3)
      (e3) edge [bend left=45] node {\footnotesize 冷却} (e1)
      (e1) edge node [swap] {\footnotesize 研磨，皮膜} (e4)
      (e4) edge [bend left=45] node {\footnotesize 出荷} (e0);
    \end{scope}

    % --- 要求モデル (Requirement) ---
    \begin{scope}[yshift=-4.5cm]
      \node[anchor=west] at (-3, 1) {\textbf{要求モデル} $E_\mathit{req}$};

      \node[state, draw=red, fill=red!15] (r-1) {$-1$};
      \node[state, initial, initial text=, accepting] (r0) [right=of r-1] {$0$};
      \node[state, accepting] (r1) [right=of r0] {$1$};

      \path[->]
      (r0) edge node {\footnotesize 成形} (r1)
      (r1) edge [loop right] node {\footnotesize 成形} ()
      (r0) edge [bend left=45] node {\footnotesize 出荷} (r-1)
      (r1) edge [bend left=45] node {\footnotesize 出荷} (r0);
    \end{scope}

    \begin{scope}[yshift=-7.5cm]
      \node[anchor=west] at (-3, 1.2) {\textbf{Marking判定モデル} $E_M$};

      \node[state, initial, initial text=] (m0) {$0$};
      \node[state, accepting] (m1) [right=3.5cm of m0] {$1$};

      \path[->]
      (m0) edge [loop below] node {\footnotesize $A_{E_\mathit{env}} \setminus \{\text{出荷}\}$} ()
      (m1) edge [bend left=20] node {\footnotesize $A_{E_\mathit{env}} \setminus \{\text{出荷}\}$} (m0)
      (m0) edge [bend left=20] node {\footnotesize 出荷} (m1)
      (m1) edge [loop below] node {\footnotesize 出荷} ();
    \end{scope}

  \end{tikzpicture}
  \caption{アクション目標を状態目標へ変換した金属加工システム}
  \label{fig:metal_processing_model_marked}
\end{figure}

\subsubsection{RAによる探索と失敗のプロセス}

前目で述べた変換後の金属加工システム（\aref{fig:metal_processing_model_marked}）に対し，RAを用いたOn-The-Fly探索を適用した場合の具体的な挙動を示す．
本モデルでは，$E_\mathit{env}$ と $E_\mathit{req}$ の全状態がMarkedと設定されているため，探索の主目的は Mark判定モデル $E_M$ を状態1（Marked）に遷移させること，すなわち「出荷」アクションを発火させることになる．

RAを用いた場合でも，最終的には適切な制御器が合成されるが，その過程で生じる非効率な探索挙動について以下に段階的に示す．

\begin{description}
  \descitem{Step 1: 初期状態からの遷移}
  初期状態 $\bm{s}_0 = (0, 0, 0)$ （順に $E_\mathit{env}, E_\mathit{req}, E_M$ の状態）において，発火可能なアクションは金属準備のみである．
  システムはこれを選択し，状態 $\bm{s}_1 = (1, 0, 0)$ へ遷移する．
  このとき，$E_\mathit{env}$ は状態1（分岐点）に進むが，$E_\mathit{req}$ と $E_M$ は金属準備に関与しないため状態0に留まる．

  \descitem{Step 2: RAによるヒューリスティック評価と誤った選択}
  状態 $\bm{s}_1$ において，RAは次に選択すべきアクションを決定する．
  この時点で局所的に発火可能なアクション（Readyアクション）の集合は，$A^R = \{\text{研磨}, \text{皮膜}, \text{溶解}, \text{成形}, \text{出荷}\}$ である．

  まず，環境モデル $E_\mathit{env}$ および要求モデル $E_\mathit{req}$ の評価を行う．
  これらは設定により全状態がMarkedであるため，現在の状態が既に目標であるとみなされる．したがって，これらのコンポーネントにおける距離推定値は $1$ となり，アクション選択の差別化要因とならない．

  したがって，評価の差が生じるのは Mark判定モデル $E_M$ における推定である．
  $E_M$ がMarked状態（状態1）へ遷移するためには，同期アクションである「出荷」の発火が不可欠である．
  RAは，展開対象のアクション $\hat{a}$ から「出荷」へのGap（遷移コスト）と，その先の $E_M$ における距離（Dist）の和として値を算出する．

  \begin{description}
    \descitem{選択肢A：「研磨」または「皮膜」}
    環境モデル $E_\mathit{env}$ において，「研磨」または「皮膜」から「出荷」へのGapは $1$ である．
    一方，$E_M$ において「出荷」発火後の状態はMarked状態そのものであるため，その距離（Dist）は $1$ である．
    よって，推定距離は $d = 1 + 1 = 2$ と算出される．

    \descitem{選択肢B：「溶解」}
    環境モデル $E_\mathit{env}$ において，「溶解」から「成形」「冷却」を経て「出荷」に至る最小のGapは $3$ である．
    $E_M$ における距離（Dist）は同様に $1$ である．
    よって，推定距離は $d = 3 + 1 = 4$ と算出される．
  \end{description}

  RAはこの推定値に基づき，距離の小さい（$2 < 4$）「研磨」および「皮膜」を優先すべき有望なアクションと判断する．
  その結果，アルゴリズムは正解ルートである「溶解」を後回しにし，まずは見かけ上のコストが低い「研磨」を選択して状態 $\bm{s}_2 = (4, 0, 0)$ への遷移を行う．

  \descitem{Step 3: 経路の行き詰まりと繰り返される不要な探索}
  遷移後の状態 $\bm{s}_2 = (4, 0, 0)$ において，環境モデル上では出荷が可能である．
  しかし，要求モデル $E_\mathit{req}$ は依然として状態0（成形未実施）にある．
  この状態で出荷を発火すると，$E_\mathit{req}$ は違反状態（$-1$）へ遷移してしまうため，DCSの安全性制約によりこの遷移は禁止される．
  他に有効なアクションも存在しないため，この経路は探索の行き詰まりとなる．

  この結果，探索アルゴリズムはこの経路を破棄し，分岐点である状態 $\bm{s}_1$ までバックトラックを行う．
  しかし，RAのヒューリスティック評価では，残る選択肢である「皮膜」も「溶解」よりコストが低いと判定されている．
  そのため，アルゴリズムは「溶解」を選ぶ前に，もう一方の選択肢である「皮膜」の探索へ移行する．
  「皮膜」ルートも同様に同期待機ができず行き詰まりとなるため，再びバックトラックが発生する．

  このように，RAの誘導により2つの不要な経路を探索し尽くした後に，ようやく次善の選択肢であった「溶解」ルートの探索が開始される．
\end{description}

以上のプロセスにより，RAを用いた探索では，同期（$E_\mathit{req}$ の状態進行）の必要性を見抜けずに，局所的に目標アクション「出荷」へ近づきやすい経路を優先して探索する．
大規模なシステムにおいては，このような不要な探索とバックトラックが頻発し，計算リソースを著しく浪費する原因となる．

\section{Readyアクション探索による計算コストの増大}

RAのもう一つの課題は，ヒューリスティック値の計算自体のオーバーヘッドである．
前章の\aref{alg:estimate_dist}（\textsc{EstimateDist}）に示した通り，RAは距離を算出するために以下の処理を行う．

$$
  d \gets \min_{a \in A^R}\{\textsc{CalculateGap}(\bm{s}, \hat{a}, a) + \textsc{EstimateDist}(\bm{s}, a, s^*_{E_i})\}
$$

この式は，現在の合成状態における全てのReadyアクション $A^R$ に対して，遷移コスト（Gap）と再帰的な距離推定を行い，その最小値を求めることを意味している．
これは実質的に，探索の1ステップごとに，Readyアクションをノードとするグラフ上でダイクストラ法に近い最短経路探索を行っているに等しい．

システム規模が大きくなり，並列動作するコンポーネント数が増加すると，Readyアクション集合 $A^R$ のサイズは増大する．
DCSのOn-The-Fly探索では，数十万の状態を探索することが珍しくない．その全ての遷移において，この重い計算処理が走ることは，合成時間全体に対して無視できないペナルティとなる．

特に，前節で述べたように同期待ちが発生している状況では，有効なパスが見つからずに $A^R$ 全体を探索し尽くす最悪ケースの計算が発生しやすくなる．
すなわち，RAは探索中に迷いやすいだけでなく，その計算処理自体も重いという二重の課題を抱えていると言える．

\section{本章のまとめ}

本章では，Markingアクションを目標とする離散制御器合成において，従来のReady Abstractionが抱える課題を分析した．

第一の課題は同期の無視である．RAは局所的な最短経路を優先するため，同期のための準備動作よりも，単独で進行可能な近道を過剰評価する．これにより，パートナーの到着を待てずに脇道へ逸れる探索（不要な探索）が発生する．

第二の課題は計算コストである．RAは距離推定のためにReadyアクショングラフ上の探索を都度行うため，1ステップあたりの計算負荷が高く，大規模なシステムにおいて合成時間のボトルネックとなる．

これらの課題は，RAが動的なReady情報とその探索に依存しすぎていることに起因する．
次章では，これらの問題を解決するために，静的な構造情報である同期アクションまでの局所距離を活用し，計算コストを抑えつつ同期を強力に指向する新たな手法「Pre-Marking Direction」を提案する．

\chapter{Pre-Marking Direction}
\label{chap:pre_marking_direction}

本章では，前章で指摘したReady Abstraction（RA）の課題を解決するため，新たなヒューリスティック手法であるPre-Marking Direction（PMD）を提案する．
PMDは，目標アクションの発火に不可欠な同期イベントに着目し，複雑なReadyアクショングラフの探索を行わずに，静的な構造情報のみを用いて効率的な探索を実現する手法である．

\section{Pre-Markingアクション}

本節では，提案手法の核となる概念であるPre-Markingアクション（PMA）を定義する．
前章で述べたように，RAの主な課題は同期構造の無視にある．
複数のコンポーネントが同期してMarkingアクションを発火する必要がある場合，すべてのコンポーネントが準備完了状態になるまでMarkingアクションは発火できない．
したがって，探索の指針とすべきシステム全体のボトルネックは，目標への到達に最も時間を要するコンポーネントによって決定される．

複数のMarkingアクションが存在する場合，Non-Blocking性はそれらのうちいずれか一つへの到達が可能であれば満たされる．
したがって，特定の目標への到達にのみ必須となるアクションは，別経路による回避が可能であるため，システム全体のボトルネックとはみなせない．
ゆえに，本研究ではすべてのMarkingアクションへの到達において共通して不可避なアクションのみをPre-Markingアクションと定義する．

\subsection{PMAの定義}

Pre-Markingアクションは，LTSの構造に基づいて静的に定義される属性である．
あるLTS $E_i = (S_E, s_{E,0}, A_E, A^M_E, \Delta_E)$ において，初期状態 $s_{E,0}$ から始まり，ある特定のMarkingアクション $a_m \in A^M_E$ の発火をもって終了する有限トレースの集合を $T_{s_{E,0} \to a_m}$ とする．

$$
  T_{s_{E,0} \to a_m} = \{ t \in T_{E} \mid t = s_0, a_0, \dots, s_j, a_j, \ s_0 = s_{E,0} \land a_j = a_m \}
$$

このとき，初期状態から $a_m$ に到達するために不可避なアクション集合 $A^\mathit{Required}_{s_{E,0} \to a_m}$ は以下のように定義される．

$$
  A^\mathit{Required}_{s_{E,0} \to a_m} = \{ a \in A_{E} \setminus \{a_m\} \mid \forall t \in T_{s_{E,0} \to a_m}, a \in A_t \}
$$

ここで，$A_t$ はトレース $t$ に含まれるアクションの集合を表す．
$E$ におけるPre-Markingアクションの集合 $A^P_{E}$ は，すべてのMarkingアクションに対する $A^\mathit{Required}$ の積集合として定義される．

\begin{definition}[Pre-Markingアクション]
  アクション $a \in A_{E}$ が以下の条件を満たすとき，$a$ はPre-Markingアクションである．
  $$
    a \in \bigcap_{a_m \in A^M_{E}} A^\mathit{Required}_{s_{E,0} \to a_m}
  $$
\end{definition}

この定義により，PMAは目標がいかなる形で達成されるとしても，回避することのできない構造上の通過点であることが保証される．

実際の探索において，各状態 $s \in S_{E}$ は，その時点において未発火であるPMAの集合を保持する．
状態 $s$ における未発火PMA集合 $A^P_s$ は，大域的に定義された $A^P_{E}$ のうち，状態 $s$ からMarkingアクションへ到達するために今後必ず発火しなければならないアクションの集合である．
なお，初期状態 $s_{E,0}$ においては，未発火のPMA集合は大域的な定義と一致するため，$A^P_{s_{E,0}} = A^P_{E}$ が成立する．
PMDはこの $A^P_s$ を用いることで，その状態が目標達成に対して不可避な手順をあとどれだけ残しているかを定量化する．

\subsection{PMAの抽出アルゴリズム}

PMAの抽出および各状態への割り当ては，探索前の静的解析によって行われる．
本手法では，後述する距離推定のために算出が必要となる，各状態から各アクションへの最短ステップ数の情報を活用し，効率的な候補の絞り込みと逆方向探索を組み合わせた2段階のアルゴリズムを採用している．

\subsubsection{最短パス情報を用いた候補特定}

第一段階では，Pre-Markingアクションとなり得る候補集合 $A^{\mathit{MP}}_{E}$ を特定する．
PMDではヒューリスティック計算のために，各状態から各アクションへの最短ステップ数を事前に算出する．
真に回避不能なアクション（PMA）は，初期状態から目標へ至るすべてのパスに含まれるため，最短パス上にも必ず存在する．
この性質を利用し，初期状態から各Markingアクションへの最短パス上に存在するアクションの積集合をとることで，PMAの候補を効率的に絞り込む．

具体的には，各Markingアクション $a_m \in A^M_E$ に対し，初期状態から $a_m$ に至る最短パスを一つ選択し，それに含まれるアクション集合を取得する．
そして，すべての $a_m$ についてこれらの積集合を計算し，これを候補集合 $A^{\mathit{MP}}_{E}$ とする．
この操作は，既存の距離計算結果を再利用するため，追加の探索コストを低く抑えることが可能である．

\subsubsection{逆伝播による判定と状態への割り当て}

第二段階では，候補アクション $a \in A^{\mathit{MP}}_{E}$ が真にPMAであるか，および具体的にどの状態において未発火であるかを判定する．
これを状態ごとに順方向に探索して判定すると計算コストが高くなるため，本手法ではMarkingアクション側からの逆伝播による一括判定を行う．

ある候補アクション $a$ について，以下の手順で判定を行う．
まず，Markingアクションを直ちに発火可能な状態集合を起点とし，遷移を逆方向に辿りながら到達可能な状態集合 $S^*$ を探索する．
この際，アクション $a$ による遷移は通行止めとみなして探索を行わない．
この逆探索によって到達できた状態群 $S^*$ は，アクション $a$ を経由せずにMarkingアクションの発火可能状態へ到達できる状態である．すなわち，これらの状態において $a$ は回避可能，あるいは既に通過済みであるため，未発火のPMAには該当しない．

探索の結果，初期状態 $s_{E,0}$ が $S^*$ に含まれない場合，初期状態から $a$ を回避して目標へ到達する経路が存在しないことを意味する．
この場合，アクション $a$ はシステム全体のPre-Markingアクションとして確定される．
そして，逆探索で到達できなかった状態集合（$S_E \setminus S^*$）に対して，$a$ を未発火PMAとして割り当てる．
このアルゴリズムを\aref{alg:pma_extraction}に示す．

\begin{algorithm}
  \caption{PMA抽出および割り当てアルゴリズム}
  \label{alg:pma_extraction}
  \begin{algorithmic}[1]
    \Require{LTS $E$}
    \Ensure{各状態 $s$ における未発火PMA集合 $M^P_E: S_{E} \to 2^{A_{E}}$}

    \LComment{Step 1: 最短パス情報による候補特定}
    \State $A^{\mathit{MP}}_{E} \gets A_{E}$
    \ForAll{$a_m \in A^M_E$}
      \LComment{最短トレースに含まれるアクション集合との積集合で更新}
      \State $t \gets \operatorname*{argmin}_{t \in T_{s_{E,0} \to a_m}} |t|$
      \State $A^{\mathit{MP}}_{E} \gets A^{\mathit{MP}}_{E} \cap A_t$
    \EndFor

    \Statex
    \LComment{Step 2: 逆伝播による状態への割り当て}
    \ForAll{$s \in S_E$}
      $M^P_E(s) \gets \emptyset$ \Comment{全状態で空集合に初期化}
    \EndFor
    \For{$a \in A^{\mathit{MP}}_E$}
      \LComment{Markingアクションを直ちに発火可能な状態集合}
      \State $S^* \gets \{ s \in S_E \mid \exists a_m \in A^M_E, \exists s', (s, a_m, s') \in \Delta_E \}$
      \State $S^*_{\mathit{prev}} \gets \emptyset$

      \While{$S^*_\mathit{prev} \neq S^*$}
        \State $S^*_\mathit{prev} \gets S^*$
        \ForAll{$s \in S^*_\mathit{prev}$}
          \LComment{$s$ へ遷移可能な親状態 $s'$ を探索（逆伝播）}
          \ForAll{$(s', a', s) \in \Delta_E$}
            \If{$a' \neq a$}
              \State $S^* \gets S^* \cup \{s'\}$
            \EndIf
          \EndFor
        \EndFor
      \EndWhile

      \LComment{初期状態から回避不能である（真のPMAである）場合のみ割り当て}
      \If{$s_{E,0} \notin S^*$}
        \For{$s \in S_{E} \setminus S^*$}
          \State $M^P_E(s) \gets M^P_E(s) \cup \{a\}$
        \EndFor
      \EndIf

    \EndFor

    \Statex
    \Return $M^P_E$
  \end{algorithmic}
\end{algorithm}

\section{Pre-Marking Directionによる評価}

Pre-Marking Direction（PMD）は，展開対象となるアクション $\hat{a}$ の有望さを，そのアクションを実行した結果生じる遷移先の状態 $\bm{s}'$ に基づいて評価する．
この評価計算においては，各LTSの静的構造解析により事前に算出された最短距離関数 $\textsc{CalculateDist}$ が用いられる．
RAが探索ステップごとにReadyアクショングラフ上の動的な最短経路探索を必要とするのに対し，PMDは事前計算された距離関数の参照と単純な比較演算によって評価値を算出するため，探索時における計算負荷を大幅に低減している．

具体的な評価手順を\aref{alg:pmd_heuristic}に示す．
本手法では，まずアクション $\hat{a}$ を実行した後の状態 $\bm{s}'$ を導出し，その時点で未発火であるPMAの集合 $A^P_{\bm{s}'}$ を特定する．
これは，その遷移を選んだ場合に依然として回避できない必須タスクの残存量を表す．

続いて，各コンポーネント $E_i$ について，自身の目標であるMarkingアクション，およびシステム全体で必要とされる未発火PMA群への到達距離を評価する．
ここで，各コンポーネントの推定距離 $d_{E_i}$ は，自身のMarkingアクションへの最短距離と，自身が関与すべき未発火PMAへの最短距離に$1$を加えた値のうち，より大きな値として算出される．
この加算処理は，PMAが目標達成のための通過点として定義されており，その発火後もMarkingアクションに至るまでに少なくとも1ステップの遷移を要するという構造的制約を反映したものである．
この最大値をとる操作により，たとえ自身の局所的な目標が近くても，遠方にある同期アクションの発火に参加しなければならない場合，その移動と待機がシステム全体の進行を律速する要因となることを数理的に表現している．

算出された各コンポーネントの距離 $d_{E_i}$ は降順にソートされ，辞書式順序による比較に用いられる．
これにより，システム内で最も遅延しているボトルネックを優先的に解消する遷移が選択されることになる．

\begin{algorithm}
  \caption{Pre-Marking Directionによるヒューリスティック関数}
  \label{alg:pmd_heuristic}
  \begin{algorithmic}[1]
    \Require{%
      全てのLTSの組 $\bm{E} = (E_1, E_2, \ldots, E_n)$， \\
      現在の状態 $\bm{s} = (s_{E_1}, s_{E_2}, \ldots, s_{E_n})$， \\
      展開対象のアクション $\hat{a}$
    }
    \Ensure{%
      各LTSにおける距離の降順の組 $\bm{d} = (d_1, d_2, \ldots, d_n)$ \\
      ただし，$d_i \in \mathbb{N} \cup \{\infty\}$
    }

    \Function{PreMarkingDirectionHeuristic}{$\bm{E}, \bm{s}, \hat{a}$}

    \If{$\hat{a} \in A^M$}
      \Return $(0, 0, \ldots, 0)$ \Comment{Markingアクションの場合，距離0（最優先）を返す}
    \EndIf

    \Statex
    \LComment{Step 1: アクション$\hat{a}$実行後の次状態 $\bm{s}'$ を導出}
    \For{$i = 1, \ldots, n$}
      \If{$\hat{a} \in A_{E_i}$}
        \State $s'_{E_i} \gets s' \text{ where } (s_{E_i}, \hat{a}, s') \in \Delta_{E_i}$
      \Else
        \State $s'_{E_i} \gets s_{E_i}$
      \EndIf
    \EndFor
    \State $\bm{s}' \gets (s'_{E_1}, s'_{E_2}, \ldots, s'_{E_n})$

    \Statex
    \LComment{Step 2: 次状態 $\bm{s}'$ における未発火PMA集合の特定}
    \State $A^P_{\bm{s}'} \gets \emptyset$
    \For{$i = 1, \ldots, n$}
      \State $A^P_{\bm{s}'} \gets A^P_{\bm{s}'} \cup M^P_{E_i}(s'_{E_i})$
    \EndFor

    \Statex
    \LComment{Step 3: 各コンポーネントのボトルネック距離推定}
    \For{$i = 1, \ldots, n$}
      \State $d_{E_i} \gets 1$

      \LComment{自身のMarkingアクションへの最短距離で更新}
      \If{$A^M_{E_i} \neq \emptyset$}
        \State $\mathit{minSteps} \gets \min_{a_m \in A^M_{E_i}} \textsc{CalculateDist}(s'_{E_i}, a_m)$
        \State $d_{E_i} \gets \mathit{minSteps}$
      \EndIf

      \LComment{未発火のPMAへの距離によって更新}
      \If{$A^P_{\bm{s}'} \cap A_{E_i} \neq \emptyset$}
        \State $\mathit{maxSteps} \gets \max_{a_p \in A^P_{\bm{s}'} \cap A_{E_i}} \textsc{CalculateDist}(s'_{E_i}, a_p) + 1$
        \State $d_{E_i} \gets \max(d_{E_i}, \mathit{maxSteps})$
      \EndIf
    \EndFor

    \Statex
    \Return $\textsc{SortDescending}((d_{E_1}, d_{E_2}, \ldots, d_{E_n}))$
    \Comment{距離を降順でソートして返す}

    \EndFunction
  \end{algorithmic}
\end{algorithm}

\section{探索挙動の改善例：金属加工システム}

本節では，\aref{subsec:ra_metal_processing_example}で述べた金属加工システムの例題に対し，提案手法であるPMDを適用した場合の探索挙動を示す．
RAが陥った局所解への迷走を，PMDがいかにして回避し，同期に不可欠なアクションを見据えた適切な探索を行うかについて詳述する．

\subsection{Pre-Markingアクションの抽出結果}

探索に先立ち，PMDは各LTSの構造解析を行い，Pre-Markingアクション（PMA）の抽出を行う．
本システムにおいて抽出されるPMAは以下の通りである．

まず，環境モデル $E_\mathit{env}$ においては，初期状態から目標アクション「出荷」へ至るすべての経路において，最初のアクションである「金属準備」が必ず実行される．
したがって，「金属準備」は $E_\mathit{env}$ におけるPMAとして抽出される．
なお，「成形」などの加工アクションは，$E_\mathit{env}$ 単体で見ると「研磨」ルートによる回避が可能であるため，環境モデルのPMAとはならない．

次に，要求モデル $E_\mathit{req}$ においては，初期状態から「出荷」へ至る適法なトレースにおいて，アクション「成形」は必ず一度は発火されなければならない．
「成形」を回避して「出荷」を行う経路は，違反状態へ遷移する経路のみであるため，「成形」は $E_\mathit{req}$ におけるPMAとして正しく抽出される．

この結果，探索開始時の初期状態において，システム全体の未発火PMA集合は $\{\text{金属準備}, \text{成形}\}$ となる．

\subsection{分岐点におけるヒューリスティック評価の比較}

RAが誤った選択を行った分岐点である状態 $\bm{s}_1 = (1, 0, 0)$ におけるPMDの挙動を追跡する．
この状態に至る遷移で「金属準備」は既に実行されているため，ここでの課題は残るPMAである「成形」をいかに効率よく消化するかにある．

この状態において展開可能なアクションは「研磨」，「皮膜」，「溶解」の3つである．
なお，要求モデル $E_\mathit{req}$ は，これらいずれのアクションによっても状態遷移せず初期状態（状態0）に留まる．そのため，$E_\mathit{req}$ 側での評価値はすべての候補で一定となり，選択の差異要因とはならない．
したがって，以下では環境モデル $E_\mathit{env}$ 側の遷移と評価値に焦点を当てて比較を行う．

PMDは展開可能な各アクション $\hat{a}$ を選択した後の次状態 $\bm{s}'$ を導出し，その時点での未発火PMAへの距離を考慮して以下の式で距離 $d_{E_\mathit{env}}$ を算出する．
$$
  d_{E_\mathit{env}} = \max(\textsc{CalculateDist}(s'_{E_\mathit{env}}, \text{出荷}), \quad \textsc{CalculateDist}(s'_{E_\mathit{env}}, \text{成形}) + 1)
$$

\begin{description}
  \descitem{選択肢A：「研磨」または「皮膜」}
  これらのアクションを選択した場合，環境モデル $E_\mathit{env}$ は状態4へ遷移する．
  この遷移後の状態においてもPMA「成形」は未発火のままであるため，PMDはそこへの距離を計算に含める．
  \begin{description}
    \item[目標（出荷）への距離]
          直後の遷移で「出荷」が可能であるため，距離は $1$ である．
    \item[未発火PMA（成形）への距離]
          状態4から「成形」へ到達するためには，一度「出荷」を行って初期状態へ戻り，再度「金属準備」「溶解」を経る必要がある．この最短パス（出荷 $\to$ 金属準備 $\to$ 溶解 $\to$ 成形）の長さは $4$ である．
  \end{description}
  したがって，評価値は $d_{E_\mathit{env}} = \max(1, 4 + 1) = 5$ と算出される．

  \descitem{選択肢B：「溶解」}
  このアクションを選択した場合，環境モデル $E_\mathit{env}$ は状態2へ遷移する．
  同様にPMA「成形」は未発火であるが，状態が変化したことでそこへの距離が短縮される．
  \begin{description}
    \item[目標（出荷）への距離]
          状態2から「出荷」へ至るには，「成形」「冷却」を経て待機状態に戻り，そこから「研磨」等を経由する必要がある．この最短パス（成形 $\to$ 冷却 $\to$ 研磨 $\to$ 出荷）の長さは $4$ である．
    \item[未発火PMA（成形）への距離]
          直後の遷移で「成形」が可能であるため，距離は $1$ である．
  \end{description}
  したがって，評価値は $d_{E_\mathit{env}} = \max(4, 1 + 1) = 4$ と算出される．
\end{description}

\subsection{探索の結果}

算出された推定距離を比較すると，「研磨・皮膜」の評価値 $5$ に対し，「溶解」の評価値は $4$ となり，より小さい値を示す．
PMDは，見かけ上は目標（出荷）に近い「研磨」ルートに対し，未発火PMA（成形）への到達が困難になる（初期状態への手戻りが必要になる）という構造的理由からペナルティを与え，逆に目標へは遠回りでもPMAを確実に消化できる「溶解」ルートを正しく推奨する．

結果として，探索アルゴリズムはバックトラックを発生させることなく，初手から正解ルートである「溶解」$\to$「成形」$\to$「冷却」$\to$「出荷」の経路を選択する．
これにより，RAで発生していた不要な探索空間の展開が完全に抑制され，最短ステップでの解の発見が実現される．

\section{評価実験}

\todo{複数のシナリオにおいて，PMD・RA・BFSの探索状態数と計算時間を比較し，あわせて各問題でのPMA抽出数も記載する．結果として，PMAが抽出された問題ではPMDがRAを大幅に上回り，逆にPMAがない場合はRAが有利あるいは同等となる傾向を示す記述を行う．（注：現在数値を再計測中だが，傾向は変わらないため構成確認用として一旦旧データを用いて記述する）}

\subsection{実験設定}

\subsection{実験結果}

\section{考察}

本実験の結果は，提案手法であるPMDの有効性がPre-Markingアクション（PMA）の抽出可否に強く依存することを示している．

PMAが抽出された問題において，PMDはRAと比較して探索効率を大幅に向上させた．
この要因として，PMAがシステム全体のボトルネックとなる同期イベントを捉え，必須アクションを含む経路を優先的に探索できたことが挙げられる．
また，探索空間の削減率が限定的であった場合でも，計算時間の短縮が見られたケースが存在する．
これは，RAが各探索ステップにおいてReadyアクショングラフ上の動的な最短経路探索を必要とするのに対し，PMDは事前計算済みの静的な距離表を参照するのみであり，1状態あたりの計算負荷が低く抑えられたことに起因する．
すなわち，PMDは探索方向の的確な示唆とヒューリスティック計算の軽量性という二つの側面から高速化に寄与していると言える．

一方，PMAが抽出されなかった問題においては，PMDの探索性能はRAを下回る結果となった．
PMAが存在しない場合，PMDの距離推定は各コンポーネントにおけるMarkingアクションまでの単純な静的最短距離に依存することになる．
この指標は，コンポーネント間の同期による待ち時間やデッドロックの可能性を考慮できないため，Readyアクション間の遷移コストを評価できるRAと比較して推定精度が劣る．
その結果，同期制約によって本来は進行不可能な方向や，目標から遠ざかる方向を有望と誤認して探索を行い，RAであれば回避できた不要な探索枝を展開してしまう傾向が見られた．
このように，PMAという強力な指針を欠いた状態でのPMDは，RAよりも不正確な探索を行うだけでなく，時間およびメモリ消費量の増大を招くリスクがあることが明らかとなった．

以上のことから，PMDは常にRAより優れているわけではなく，PMAという構造的特徴が存在する場合に特化した手法であると結論付けられる．
この特性は，対象問題の構造に応じて適切なアルゴリズムを選択する必要性を示唆している．

\section{RAとの動的切り替え戦略}

\todo{PMA抽出にかかる計算コストのテーブルを提示し，それが探索全体の時間に比べて無視できるほど軽量であることを示す．このデータに基づき，合成開始時にまず静的解析（PMA抽出）を実行し，有効なPMAが得られた場合のみPMDを適用し，そうでない場合はRAを選択するという「動的切り替え戦略」について論じる．}

\chapter{関連研究}
\label{chap:related_works}

\todo{以下の3点について触れ，本研究の立ち位置を明確にする．(1) 離散制御器合成（DCS）における状態空間爆発への対処手法の変遷，(2) 本研究の直接的な比較対象であるReady Abstraction（RA）の理論的背景，(3) 近年の機械学習を用いたヒューリスティック手法との対比．}

\chapter{結論}
\label{chap:conclusion}

\section{本論文のまとめ}

\todo{本論文で提案したPMDの総括を行う．特に，同期構造に着目した静的解析が，特定の構造を持つ問題に対して劇的な探索効率化を実現した点をまとめる．}

\section{将来研究}

本研究では，PMDの導入によりヒューリスティック値の計算コストを大幅に削減し，同期ボトルネックを持つ問題における探索効率を改善した．
しかし，実験を通じて，探索済み状態数が増大するにつれて，ヒューリスティック計算以外の処理に起因する探索速度の鈍化が確認された．
これは，現在のOn-The-Fly探索アルゴリズムにおいて，既訪問状態の照合や新規状態の保存といった管理コストが，探索空間の規模に対してスケーラブルでない可能性を示唆している．

したがって，今後の課題として，On-The-Fly探索アルゴリズムそのものの改良が挙げられる．
具体的には，状態保存に用いるデータ構造をより効率的なものへ刷新することや，探索の進行に伴う管理オーバーヘッドを削減するようアルゴリズムを見直すことが求められる．
これにより，PMDの軽量性を活かしつつ，さらに大規模なシステムに対しても高速な制御器合成が可能になると考えられる．

\appendix

\backmatter

\chapter{謝辞}

\bibliographystyle{jplain}
\bibliography{references}

\end{document}
